[{"content":"探索一下 C++ 的容器 vector 的内存布局，也算是解答我自己的一些疑虑咯\n头图是从网上搜的，尝试寻找出处，未果。很可惜。选曲尝试选择了一首听着比较清淡的曲子 泪苔，感觉比较符合头图清新淡雅的神社氛围。希望你喜欢。\n先介绍一下 vector 的基本情况咯 vector 是由 C++ 标准库提供的一个容器模板类。这里不打算仔细介绍什么是容器，模板，什么是类，我们直接指出：vector 的作用就是一个更好用的数组。“类”是说明它自己带了一些好用的函数，称为“方法”，“模板”就是说它需要接受一个类型作为参数才能成为一个完整的类型，就像数组必须说明是什么东西的数组一样。最后“容器”就是说它是一类经过了特殊优化的模板类，和别的容器一起共用着一些方法与成员，且有一类公共的算法可以用在它们上面。\n和传统的数组相比，vector有这样的几个特点：首先它符合 RAII (Resource Allocation Is Initialization) 的要求，即自动管理内存，离开作用域时自动销毁，而传统的数组则不是很满足 RAII 的条件；其次就是 vector 是动态大小的，在使用时不需要在编译期就了解这个东西的大小，程序会根据需求自动分配内存。虽然后者在 C 中也能实现，比如指针+ malloc 或者指针+ new 的组合，然而这样的组合需要直接面对自己创建的裸指针 (Raw Pointer)，一个不小心就很容易造成内存泄漏，所以使用时要特别注意。最后就是，相比起数组这样较基础的数据类型，使用 vector 的内建函数（方法）可以避免自己造一些轮子，会比较方便。\n即便 vector 看起来这么好，其实还是有人会担心 vector 会引入额外的运行开销。特别是，有人可能会怀疑：我使用数组或者指针+malloc或者指针+new 得到的内存空间我是明确知道时连续的，那 vector 呢？它经过这样的包装之后，还拥有连续内存空间吗？这篇文章就是打算探讨这个问题。\nvector 为什么“可能”会比较低效？ 我们这里不打算介绍什么复杂的内容，比如什么 allocator 或者内存调度机制。我们只对“指针+malloc”、“指针+new”方法以及vector方法是怎么获取可用内存空间的方法进行简单说明。\n不过在进入具体的内存分配过程介绍之前，我们希望能先介绍几个概念：\n堆与栈 我们写好的程序在运行时，需要同系统进行交互，借由多种系统调用完成任务。而在程序运行的过程中需要的内存空间则也是由系统进行分配的。一般我们将系统分配的内存空间划分为两块，一块叫堆，而另一块儿叫栈。请注意这里的堆栈并不能直接对应数据结构，请仅将其看作内存空间的称呼。\n程序运行时，系统会将调用的函数一个一个压入调用栈中，栈空间内实行先进后出（也是栈这一称呼的来源），连带着函数需要的变量也是一样压入栈内的。然而，栈实际上相对比较小，如果在栈内存放了过多的资源导致栈内空间不足，程序则会出现所谓的栈溢出 (Stack Overflow)。不过好消息是，系统并不会傻傻地将任何东西都放在宝贵的栈空间内，在存储大量内容时，可以把这些内容存储在堆中。\n堆和栈都是由系统负责内存分配的，区别在于，栈是严格执行先进后出的，且空间有限，只负责函数调用等，资源会被自动回收；而堆则不同，堆相比栈而言会比较大，里面的资源不需要什么先进后出，然而在程序不再用到里面存储的资源时，系统也不会自动回收它们，取用这些内存资源的方式也是需要通过指针进行读取或写入的。所以相比栈空间，堆空间的运用更需要一些技巧，如果使用比较传统的方式的话。有句话很好地形容了堆：垃圾堆。如果能很好地管理这里的内容，那样就会很好用，否则就会让系统东留一块儿垃圾西留一块儿垃圾，最后变成垃圾堆。所以C/C++编程的一大技巧就是使用好堆上的空间。\n那么，我们应该如何，按照上面所述的方法，进行堆上的内存管理呢？\nmalloc 的内存分配方法 传统的指针+malloc方法大概是这样工作的：首先声明一个指针，它不指向什么具体的内存地址（空指针），然后再通过 malloc 中传入的参数来决定从这个指针开始要给它多大的连续空间（一个内存段），最后让这个指针指向这个内存段的头部，从而完成内存分配。这样的方法最大的特点是它不需要编译时就确定好需要多大的内存，而是通过 malloc “动态地” 分配一段内存，然后交给这个指针进行管理。在 C 语言写的程序中，基本都是这么进行运行期间的内存分配的。\n这样的内存分配方法，在 C 语言兴起的时候，是非常伟大的。然而这个方法存在着很多的问题：首先就是指针操作的复杂性。使用 malloc 时必须留意管理内存资源的指针。在内存不再被使用时必须调用 free 函数来释放资源，且在 free 之后就不能再次调用这个资源来。很多程序运行崩溃，都是由指针造成的，或者是忘记删除已经不需要的资源，或者是引用了空指针或者悬垂指针。另外就是使用 malloc 分配的内存实际上也没有那么动态：如果你声明了 100 字节的内存，那就一定而且只有 100 字节的连续内存可以用：如果你实际上用不到 100 字节，那多余的空间会被浪费，不过这样还好；而当你用了超过 100 个字节的数据，却尝试将它们放在 100 个字节的内存段中时，多出来的部分会直接被截断，也就是说多出来的部分就消失了。最后，很致命的一点是，malloc 是一个很不智能的函数。它没有类型（返回 void*）,不调用构造函数，且必须要手动计算好分配的字节数，然后传给它。这实在是一个坏消息。而即便你注意了资源的声明与使用，使用裸指针管理资源的过程也比较繁琐：你需要使用一些诸如 memcpy 这样的函数来管理内存，这些函数操作非常精细，它会要求操作的字节数量。有机会在程序运行的时候分配内存，这很好，但也许会显得有点太麻烦了。\n所以，我更愿意称使用 malloc 进行内存管理更适合 “高级用户”。一般而言，除非有很明确的需求，否则不会考虑使用老式的 malloc 进行内存分配，特别是在我们讨论的 C++ 语境下。那么 new 又如何呢？\nnew 的内存分配方法 相比于 malloc，new 更加智能，更加符合C++的思路。它会自动调用构造函数，不需要手动计算内存量（编译器会帮你计算好），且它是强类型的，它分配的内存空间会有一个明确的类型，而不是 void* 这样模棱两可的东西。然而，这里的“智能”，也只有这种程度了。究其原因，还是因为使用裸指针的原因。由于使用指针，就必须在不再使用资源时手动 delete 掉它（malloc 使用 free 释放，new 使用 delete 释放）。仅此一点就使 new 也不是一个特别理想的方法。它解决了一些 malloc 的痛点，但是没有解决使用裸指针带来的最根本的问题。\n也许有朋友会讲：你提到的是裸指针，而我记得 C++ 标准 在 C++11 时引入了智能指针。它是符合 RAII 规则的裸指针的包装，也就是说在不使用时可以自动销毁来释放资源。为什么不使用智能指针解决这些问题呢？\n没错，智能指针的引入确实能有效改善这个问题，如果需要使用指针进行操作时，换用智能指针确实是一种很好的方法。但是我们只是希望拿一块内存存储数组那样的东西，使用智能指针也许有点太重量级了。也许有人中意智能指针以及使用指针方式来进行内存管理，不过这里就不多介绍智能指针了。那既然 malloc 和 new 都不是非常令人满意的答案，vector 就能解决这些问题吗？\nvector 的内存分配方法 我们首先给出肯定的回复：Yes, vector 是 “我需要一块我不知道内存大小的连续内存段” 的非常好的解决方案。实际上也许 vector 会比想象中的更好用。vector 首先是符合 RAII 的，这使得我们不需要特别关注声明的资源：这些资源在离开其作用域时就自动被销毁了。不用再担心内存泄漏，也不用担心空指针之类。另外 vector 虽然实际上是将资源放在堆上的，对 vector 的操作实际上就像是在栈上操作它一样，对它的操作要比指针操作之类要直观的多。最后，使用 vector 不用担心空间不足：当 vector 内的空间不足以容纳新的东西时，vector 会自动增加其容量，来容纳这些新的东西。这个操作在编程侧是近乎无感的：你可以直接把 vector 当做一个无限容量的容器，你要做的事情就是往里装就 OK 了。使用 vector 是很符合直觉的，给代码作者的心智负担也比较小。毕竟，封装地这么好，你只管往里 push 就好了，不用操心什么多余的问题，vector 会帮你处理好的。\n也许有人会担心：vector 就一点问题都没有？很可惜， vector 也是需要正确使用的，否则就是会很低效。这一点主要体现在 vector 的自动扩容上。vector 的扩容机制是这样的：如果容量不够，就在当前容量上乘2（或1.5，取决于具体实现）来容纳新东西。乍一听没什么问题，而实际上扩容是一个很复杂也很慢的过程。我们下面会更深入地聊聊这个问题。另外，vector 的内存真的是连续的吗？可以通过什么方法来看到其内存布局吗？我们后面也会尝试使用程序来把内存地址打印到屏幕上，看看是个什么样子。最后，当你很明确自己需要的就是固定长度的内存区域时，vector 自动增长内存空间的做法可能就不合适了。这时你也许会更想使用数组的现代包装 std::array，而非 vector。\n最后，vector 实际上也提供了和 C 的裸指针相容的对象，通过调用 vector::data() 方法即可获得 vector 内存段对应的裸指针。这样一来，需要精细操作或者与老 API 做兼容时也很方便。\n连续的内存空间很重要吗？ 上面我们一直强调“连续的内存空间”，也许有人会好奇，连续的内存空间很重要吗？答案是肯定的：连续的内存空间可以有效提高内存寻址速度，从而提高访问和读写的速度。事实上，有连续内存空间，自然也就有非连续的内存空间。如果一个内存段是连续的，那么就意味着从内存段头部开始，需要取用第5个元素就只需要令头指针向右（或者某个方向，取决于你）偏移4个元素，就可以取到这个元素了。典型的拥有连续内存结构的数据结构有传统的数组，以及我们这里介绍的 vector。而非连续内存结构的数据结构里，非常有代表性的一个就是链表。使用链表上的第5个元素需要先从头节点向后寻找第一个节点，找到之后再跳转到第二个，不断进行这样的跳转直到找到第五个元素。使用链表的好处是链表可以极大程度利用内存空间，因为不受连续的大段内存空间的条件约束，代价便是寻址速度相比数组或 vector 会慢很多。\n另一个角度讲，vector 可能会低效的原因也在于此。由于 vector 需要保证内存是连续的，当它遇到内存不足时，便需要做下面的事：\n在内存中寻找一块新的地址，这个地址有一段连续的足够大的内存来存放老数据以及即将到来的新数据； 把老数据复制到新的地址下； 把新数据添加到老数据的后面。 这个过程最耗时的部分是第三步。设想这样一个情况，操作系统在给程序分配内存时分配地非常零散，且希望最最高效地利用内存，以至于内存空间内部只有长度为 1, 2, 4, 8, 16, 32 这6段长度的内存，它们的地址相隔甚远，且你拥有的一个 vector 目前只保存了长度为1的数据（也就被系统分配到长度为1的地址下）。现在你打算向里面补充新数据，比如，你要往里面添加31个新数据，但是这个过程中需要做一些特别的判断，以至于编译器不能帮你做优化，直接分配给你32位长度的内存。\n现在，在你向后补充第一个元素时，vector 会尝试寻找长度大于2的一个内存空间，它找到了第三块内存（长度为4）；你又向后补充了一个元素，此时 vector 发现内存不够，但是直接扩张大小也可以，此时就不需要寻址，直接声明后面的两位内存被使用即可；你又打算向后补充三位数据。这时 vector 发现内存又不够了，它寻址到第四块内存（长度为8），然后把第三块内存中的数据一个个复制到第四块内存中，然后再把新的三位数据补充到后面。\n发现问题了吗？vector 的机制让编译器不太愿意把本就很大的内存空间直接交给 vector。当你要往 vector 里填充大量数据时，让它这样自己一点点增长长度的做法会非常耗时。好消息是，我们可以通过 vector::reserve 提前告诉 vector 我们需要大概多少的内存，以便编译器一开始就找好一个够大的地方。而且这样的机制也算是强有力地说明了 vector 具有连续内存结构。\n在？看看内存结构 下面我们就来尝试用代码打印出 vector 里元素的内存地址吧。我们向一个 vector 中填充5个元素，每次填入时检查 vector 的状态：\n1#include \u0026lt;vector\u0026gt; 2#include \u0026lt;iostream\u0026gt; 3 4int main() { 5 std::vector\u0026lt;int\u0026gt; v; 6 7 for (int i = 0; i \u0026lt; 5; ++i) 8 // We use \u0026#34;push_back\u0026#34; push an element to the back of a vector 9 v.push_back(i); 10 std::cout \u0026lt;\u0026lt; \u0026#34;Added: \u0026#34; \u0026lt;\u0026lt; i 11 \u0026lt;\u0026lt; \u0026#34;, Size: \u0026#34; \u0026lt;\u0026lt; v.size() 12 \u0026lt;\u0026lt; \u0026#34;, Capacity: \u0026#34; \u0026lt;\u0026lt; v.capacity() 13 \u0026lt;\u0026lt; \u0026#34;, Address of first element: \u0026#34; \u0026lt;\u0026lt; \u0026amp;v[0] \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; 14 } 15 16 // Check contiguity 17 std::cout \u0026lt;\u0026lt; \u0026#34;Contiguous memory check:\\n\u0026#34;; 18 for (size_t i = 0; i \u0026lt; v.size(); ++i) 19 std::cout \u0026lt;\u0026lt; \u0026#34;Address of v[\u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;] = \u0026#34; \u0026lt;\u0026lt; \u0026amp;v[i] \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; 20 21 return 0; 22} 得到的结果如下：\n1Added: 0, Size: 1, Capacity: 1, Address of first element: 0x56041b4592b0 2Added: 1, Size: 2, Capacity: 2, Address of first element: 0x56041b4596e0 3Added: 2, Size: 3, Capacity: 4, Address of first element: 0x56041b4592b0 4Added: 3, Size: 4, Capacity: 4, Address of first element: 0x56041b4592b0 5Added: 4, Size: 5, Capacity: 8, Address of first element: 0x56041b459700 6Contiguous memory check: 7Address of v[0] = 0x56041b459700 8Address of v[1] = 0x56041b459704 9Address of v[2] = 0x56041b459708 10Address of v[3] = 0x56041b45970c 11Address of v[4] = 0x56041b459710 可以看到，在添加元素时，vector 的 size 指示 vector 有多少的元素，而 capacity 指示了 vector 还有多少的空间。当空间不足时，vector 的空间会扩大一倍来容纳新的元素，同时头元素的位置也会发生变化。而在元素填入结束后，通过检查地址可以发现这些元素在地址上是连续的（一个 int 的大小是4，注意到使用了16进制所以 8 后面是 c 也就是 12，c 后面就进一位因为达到了16）。\n这是一个很简单的小例子，但是用来说明 vector 的内存结构应该已经足够。\n做个 Benchmark 看看 也许一个简单的 Benchmark 可以展示一下 vector 和传统的数组相比效率如何。下面我们初始化一个 vector 和一个数组，它们有同样的大小，并且执行累加操作，最后记录累加的用时。\n1#include \u0026lt;iostream\u0026gt; 2#include \u0026lt;vector\u0026gt; 3#include \u0026lt;ctime\u0026gt; 4 5const int SIZE = 10000000; 6 7int main() { 8 std::vector\u0026lt;int\u0026gt; vec(SIZE, 1); 9 int* arr = new int[SIZE]; 10 for (int i = 0; i \u0026lt; SIZE; ++i) 11 arr[i] = 1; 12 13 // Benchmark vector 14 clock_t start_vec = clock(); 15 long long sum_vec = 0; 16 for (int i = 0; i \u0026lt; SIZE; ++i) 17 sum_vec += vec[i]; 18 clock_t end_vec = clock(); 19 20 // Benchmark array 21 clock_t start_arr = clock(); 22 long long sum_arr = 0; 23 for (int i = 0; i \u0026lt; SIZE; ++i) 24 sum_arr += arr[i]; 25 clock_t end_arr = clock(); 26 27 std::cout \u0026lt;\u0026lt; \u0026#34;Vector sum: \u0026#34; \u0026lt;\u0026lt; sum_vec 28 \u0026lt;\u0026lt; \u0026#34;, Time: \u0026#34; \u0026lt;\u0026lt; (end_vec - start_vec) \u0026lt;\u0026lt; \u0026#34; ticks\\n\u0026#34;; 29 30 std::cout \u0026lt;\u0026lt; \u0026#34;Array sum: \u0026#34; \u0026lt;\u0026lt; sum_arr 31 \u0026lt;\u0026lt; \u0026#34;, Time: \u0026#34; \u0026lt;\u0026lt; (end_arr - start_arr) \u0026lt;\u0026lt; \u0026#34; ticks\\n\u0026#34;; 32 33 // Don\u0026#39;t forget to delete[] the array! 34 delete[] arr; 35 return 0; 36} 我们先不开启优化并尝试运行几次，看看结果：\n1\u0026gt; g++ test.cpp -o test \u0026amp;\u0026amp; ./test 2Vector sum: 10000000, Time: 21530 ticks 3Array sum: 10000000, Time: 16693 ticks 4\u0026gt; ./test 5Vector sum: 10000000, Time: 21059 ticks 6Array sum: 10000000, Time: 16560 ticks 7\u0026gt; ./test 8Vector sum: 10000000, Time: 20729 ticks 9Array sum: 10000000, Time: 15812 ticks 我们再开启 O3 优化然后看看结果：\n1\u0026gt; g++ test.cpp -o test -O3 \u0026amp;\u0026amp; ./test 2Vector sum: 10000000, Time: 2684 ticks 3Array sum: 10000000, Time: 2122 ticks 4\u0026gt; ./test 5Vector sum: 10000000, Time: 4091 ticks 6Array sum: 10000000, Time: 3686 ticks 7\u0026gt; ./test 8Vector sum: 10000000, Time: 3205 ticks 9Array sum: 10000000, Time: 2813 ticks 看来不开启优化的时候，两个方法的差距还是比较明显的，而当开启优化之后，两种方法的差距并不大。然而，使用 vector 最大的优势在于心智负担小，不用担心奇怪的内存问题，而且如果使用 vector::at 方法还能自动进行边界检查，在遇到越界问题时会抛出异常，避免程序以奇怪的，错误的方式运行。\n总结 希望这篇小短文能帮助你了解 vector 的特点，或者打消你对 vector 性能的顾虑。vector 是用来说明 C++ Zero-overhead principle（零成本抽象原则）的一个很好的例子。vector 提供了一个动态数组的抽象，它会以最低成本来实现这个东西的特性，避免引入过多额外的性能开销，让调用者可以放心使用，不必担忧性能问题。对零成本抽象感兴趣可以查看 CppReference的介绍，里面介绍了这一原则的具体情况。\n当然，每次使用新的特性，总是会引入一点点的开销。或许你会考虑，辛苦一下自己，让程序能再跑快点。这本身没什么问题，但是要指出的是，警惕提前优化。如果 vector 并不是制约程序运行效率的关键部分（也就是所谓的性能瓶颈），那么就先不要管它。当程序遇到了这个瓶颈，且只能通过优化数据结构才能提高性能时，再考虑把 vector 修改为别的容器或者数据类型，这样做也许会更实际一些。\n当然，如果这个小短文有什么问题，请直接指出来。本人也不是科班出身，写这篇笔记纯粹是记录一下学习过程。欢迎交流讨论。欢迎大佬拷打，动作轻一些就更好了。\n那么最后，一如既往，祝您身心健康。\n","date":"2025-05-27T09:53:29+08:00","image":"https://a-moment096.github.io/p/c-vector-%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/Bamboo_Reimu_hu_82d2119aa7ad8f64.jpg","permalink":"https://a-moment096.github.io/p/c-vector-%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/","title":"C++ Vector 的内存布局"},{"content":"之前在虚拟机上面装的 Arch Linux 根本不过瘾（搞笑，你根本就没更完(❌)），这次就把自己的小轻薄改成 Arch 好了。顺带，也记录一下实体机上安装可能会遇到的坑？\n头图出自 R Sound Design 的新曲 《アリス？》，一首很轻快的 V曲~\n很可惜 网易云/QQ音乐 都暂时没有这首歌，所以只能劳驾移步B站欣赏了。一旦有更新就会贴在这里的\nB站投稿\n引子：我好急，怎么耗电这么大 亲爱的笔记本：\n插电如面，自从我们相逢已有一年有余。上次见面，仿佛还是上次。传统派的我那时我刚刚给你刷上 Windows 10 系统，因为 Windows 11 的审美实在是在狠狠强碱我的眼睛。我们一路克服了艰难险阻，安装了各种乱七八糟的驱动，最后终于是让你成功跑了起来。虽然你的内存不大，硬盘不多，CPU 一般，显卡集成，但你要相信我，我心里面是有你的。\n然而，你身上的 Windows 10 虽然让我倍感熟悉，你的耗电量实在是高得吓人。我接受不了一旦不插电就几乎是和时间赛跑的工作流。我将这一切归咎于可恶的微软，可恶的 Windows 10。这不是你的错，但是我还是想告诉你：你马上就会搭载一个新的系统。她轻便灵巧的同时，又大胆火辣，相信你一定会和她打成一片的。\nLove, A Moment\n美丽的五一假期，不折腾点狠活儿实在是说不过去。看着越来越不顺眼的 Windows 10 笔记本，以及我的心逐渐被 Linux（特指 Arch Linux）所俘获，我决定：干掉 Windows 10, 彻底迎接 Arch Linux。想必有了之前安装 Arch Linux 的经验，这次的安装之旅肯定是一马平川了。开始吧。\n准备：资料备份以及准备启动盘 首先肯定是先把电脑上已有的资料都备份好。其实说实话没太多文件，主要是两个没打完的 Gal 吧（心虚），因为大部分的文件都其实已经搞到台式机上面了。一开始是想着把这些文件放在一块精心规划的小硬盘上，安装的时候不格式化就行了，但是感觉还是有点点点点危险，所以干脆还是挪到另一台机器上，把这台小本的硬盘全部格式化了得了。不过也许我应该考虑更加智能的备份方案？算了，以后再考虑（挖坑）。\n其次就是准备启动盘。本来这次想要换一种安装媒介来着，比如光盘？（没错我有光盘刻录机，为了听 CD 买的 ()），结果还是嫌麻烦，放弃了。给虚拟机安装的时候不是已经有了镜像了吗？为什么不直接用呢？至于为什么没有下载最新的（最新的就是昨天刚出的，5月1日版本），是因为我刚准备下载的时候看到最上面一行小字：\nSo, why not?\n镜像依旧是用 rufus 烧录到陪伴了我6+年的小U盘上，什么格式化之类的 rufus 会自动帮我搞好的。中间有个小插曲好像是 rufus 不太支持最新的 syslinux 版本，需要额外下载两个小库。无所谓（）我选择相信。\n到这里，基本上就已经准备好安装工作了。相信根据这些东西，来个老手估计三下五除二就安装好整个系统了。当然，我是新手，还是一步步来吧。这大概也是这篇（以及上一篇）文章的目的：记录自己安装系统时蠢蠢的样子。\n开始：启动安装引导咯~ 先进安装引导再说吧 激动的心，颤抖的手，插入U盘后从U盘启动会不会有？\n太坏了，secure boot 没关，没有。上网搜索我的笔记本的 BIOS 设置方法，Redmi Book 14 需要开机后按下 F2 进入 BIOS，然后在启动设置里 先设置管理员密码 之后才能设置是否关闭安全启动。有一点点脱裤子放屁的感觉……算了。总之就是进来了，进到安装引导了。这下真是激动的心，颤抖的手了。\n（由于屏幕反光，就不拍屏了，其实和上次的屏幕一模一样咯）\n这次就得格外小心了：这可不是虚拟机。虽然说搞砸了也能重来（电脑上没什么别的重要文件了，打算全部格式化），但是一想到是实体机，还是有一些些的紧张。\n其实这篇文章是在我进来安装引导之后才开始动笔写的。一开始没打算写来着，不过鉴于好久没有更新博客了，还是水一篇吧（）\n还是先进行前期验证和网络配置 这次由于有上次安装的记录，所以其实可以直接参考以前写的那个东西。感谢代码高亮，我立马就敲下了 localectl list-keymaps。然而：没什么卵用。Bro，你就用的是美式键盘呀！？还列出来看个der呀……算了，不管了。不过验证启动模式也许还是有必要的？依旧，cat /sys/firmware/efi/fw_platform_size，结果是64。这个应该是说我的启动模式的系统是64位的吧？\n随后是验证网络。这步我其实是有点心虚来着，会不会这个安装引导不支持我的电脑网卡？害怕。但还是先试一试吧。\n从结果来看，我有一个 lo，virtual loopback interface，不管；一个 wlan0，看来是认出我的无线网卡了，好耶。然而它的 state 是 DOWN，emmm……\n（找找办法……）\n太愚蠢了，DOWN不就是说我没连上网嘛…… 不过根据 ArchWiki，还是先用 rfkill 命令检查我的无线网卡是不是被 block 了（屏蔽？也许？），好消息是没有；接着就使用 iwctl 工具进行联网。这个步骤我感觉有一点点繁琐，先要在交互界面使用 device list 列出设备，很幸运我这里是直接 wlan0 powered on 状态，这里的 wlan0 就是我的设备名了；接着就用 station wlan0 scan 扫描可用网络，然后用 station wlan0 get-networks 列出可用网络。这里有个很神奇的点：能连上我的校园网吗？用 station wlan0 connect CSU-WIFI 试试。这里 CSU-WIFI 就是我们的校园网了。好消息是成功了，不知道怎么做到的。本身链接我们学校校园网是需要使用一个网页进行验证的，不过也许是因为我在 Windows 系统上刚刚连过一次网络，所以成功重连上了？不清楚，不过也算可喜可贺。最后在用 exit 退出 iwctl 的交互界面后再 ip link 一下检查是否连上：没问题。绿色的 UP 真好看，诶嘿。\n动态IP应该是自动配置的（ArchWiki讲是 out of box），所以不管。也许后面我会想搞个静态的？唉，不懂网络真头痛呀。不管不管。直接 ping archlinux.org 试试。\n烂了，没有数据返回。烂完了。\n（找找办法x2……）\n顺从。又不是没有别的 WIFI 能用。直接连上办公室 WIFI好了。当然，这里也贴一下我参考了的连接校园网的方法的博文：链接1 以及 链接2。\n最后网络这里还有要设置一下系统时间。用 timedatectl 就可以。 感谢 zsh 和这些工具带上的自动补全，timedatectl --help 一下，跟着感觉走，最后就得到了 timedatectl set-timezone Asia/Shanghai 了。相当简单。\n再见，我的（旧）文件们 又到了每次装系统最喜欢也最提心吊胆的磁盘分区了。总有一种破后而立的感觉，感觉在磁盘格式化之后，这台电脑就变成全新的了诶。还是一样，fdisk -l 列一下可用分区。一下出来了一堆呀，删了删了，全部删了。\n又看到一次我的硬盘大小，只有 476.94 GiB，Sad。不过，轻薄本，出差顺带干活用的，无所谓了吧？后面再考虑加容量之类的吧，也许还可以考虑直接换台新本（好奢侈（））。\n开始分区吧，直接 fdisk /dev/nvme0n1 进入交互模式 （这里我的硬盘只有一个，就是在 fdisk -l 里列出的 /dev/nvme0n1，所以就把它传入参数就好）。由于硬盘太小，我也对文件管理没有什么特别多的想法，干脆就是一个 SWAP 一个 / 好了。至于分区表，依旧选用 GPT 分区表。貌似 GPT 的功能更加强大？已经完全超越了老旧的 MBR？其实按理来说我应该先多了解一下这些东西再下判断来着，不过这里就还是先相信互联网吧（）\n这里搞了个大乌龙：我不小心把启动盘 /dev/sda 给分区了。有一说一，挺愚蠢的……目前先这么搞吧，安装引导也没断，后面不碰它应该就没问题，吧？下次还是要注意：根据 ArchWiki 上的指导，实际上应该先将分区表进行备份才对，命令是 sfdisk -d /dev/sda \u0026gt; sda.dump（这里 /dev/sda 是要备份分区表的硬盘）。下次一定注意，唉。\n接下来就是使用 mkfs 等进行文件系统格式化了。这里很多人推荐 Btrfs，所谓的 B Tree File System（我一开始以为是 Better File System 来着），因为它貌似是支持自动压缩和别的一些高级功能，还有快照之类，很方便个人用户使用。这次就不用传统的 ext4 了，尝尝鲜。使用命令 mkfs.btrfs /dev/nvme0n1p1 就可以把第一个分区格式化为 Btrfs 格式了。我还留了一个分区作为 Swap 使用，大小设置为了8G。要创建 Swap 分区只需要 mkswap /dev/nvme0n1p2 即可。\n分好了区，就需要挂载文件系统了。用 mount /dev/nvme0n1p1 /mnt 就可以。Swap 则使用 swapon /dev/nvme0n1p2 就行了。这样一来，我们就在硬盘上做好了准备，马上就要把 Arch Linux 安装在这个临时挂载于 /mnt 的主硬盘了。\n安装：冲刺！冲刺！冲刺！ Arch Linux 的灵魂之一也许就是 pacman 包管理器了。安装 Arch Linux 实际上也是使用 Pacman 进行的。因此首先就是对 Pacman 进行必要的配置。\n首先还是要选择镜像，可选的镜像站放在了 /etc/pacman.d/mirrorlist 里。这里直接借鉴上次安装的经验好了，使用 reflector --latest 10 --sort rate 来排出最快的10个服务器。结果出来之后可以考虑在这条命令的后面加上 --save /etc/pacman.d/mirrorlist 来保存下来。当然，在这之前（吸取刚刚的教训）我把原文件复制了一份作为备份。\n下来就是安装必要的包，命令为 pacstrap -K /mnt base linux linux-firmware。这里的 -K 是指在目标处生成一空的 密钥环。（至于密钥环是什么，对不起，我不知道。后面会学的（））\n经过漫长的等待，我的安装它：报错了。先是安装的特别慢，可能是因为源的问题吧，我还是尝试了 reflector --country China --age 12 --sort rate 这个命令获取了国内的镜像源；后面是变快了，但是突然又报 error: GPGME error: No data，不管我怎么操作 pacman，都没有用。我估计是密钥环之类的东西坏掉了吧，看来是前面对U盘瞎JB分区导致的。这下只能关机拔掉U盘，重新烧录，格式化电脑硬盘然后重新安装。好在这次安装地很快，这个插曲也算是过去了吧。\n现在安装的应该是一些最最基础的软件包。为了安装好后有一些别的功能能用（比如联网），还是需要再安装一些别的软件包。这里我计划是安装 vim ，dhcpcd 以及 networkmanager。不过这些就等到之后 chroot 后再搞吧。\n(安装中……)\n我们就当这个傻孩子搞了一通之后算是安装好了吧，其实中间应该还有一些插曲，然而他安装好之后真的一路冲刺，就安装完了抱回宿舍继续折腾了。等他再想起来写这个博客的时候已经过了10天了。原谅他吧，好多细节他也记不清了。\n这下好了，安装成功咧，下面怎么装修好呢？\n装修：还是先试试 KDE吧，顺带处理一下输入法、字体、网络的坑 后面的内容都是这个傻孩子回忆出来的，很多都不对劲了（也许），请谨慎参考\n不知道，先看看 KDE Plasma 直接照搬上次安装的 KDE Plasma 的流程了。安装的东西，设置的玩意儿，几乎一模一样。可能区别是 loacle 的设置和上次相比更复杂一些？记不太清楚了。主要要处理的问题就是，每次使用 man 的时候，都会报 locale 的设置错误问题。解决方法也很简单：照着 ArchWiki 的 Installation Guide 的地区设置那里，再重新搞一次。剩下的什么设置 Taskbar 呀设置 Terminal 什么的，基本都没什么变化。\nKDE Plasma 很不错的一点就是，它几乎就是开箱即用的，除了两个很重要但是没有强制安装的东西：文件管理器和终端模拟器。理论上讲，应该是用同属 KDE 的 Dolphin 和 Konsole 的，这样能获得最好的体验（也许），然而在体验过 Konsole 略显（真的只是略显）老旧的 UI 之后，我还是选择了使用 kitty。它能原生支持查看图片，算是一个杀手锏级别的功能了吧，其次就是它自带多标签的功能，分栏也很方便，用着挺顺手的。至于文件管理器，目前还没有什么想法，先用着 Dolphin 好了。\n输入法：还是使用小企鹅（fcitx5）以及中州韵（Rime） 其实应该直接说“同上”或者什么的，因为实际上最后的效果和之前在虚拟机上安装的过程是一样的，除了最后我没有导入在 Winodws 上已经配置好的配置文件，仅此而已。然而这个过程还是感觉有一点坑呀，特别是不停地纠结输入法设置到底在哪里之类的问题的时候。实际上，根据 fcitx5 的文档，在使用 Wayland 的时候，直接按照教程设置变量之后重启电脑，就可以在输入法那里看到效果了。（也许不需要重启，只需要登出后重新登录就可以？）\n实际上默认的中州韵已经挺好用了。然而问题是，它的默认输入是中文，然而在 Linux 的命令行里几乎很少用到中文。每次的误输入都能让人燃气无名怒火，解决方案也很简单：把英文输入法放在首选。这里不是说让中州韵的英文成为首选，而是再装一个默认的英文输入法，并且把它放在首位。实际上我在 Winodws 上也是这么设置的。日用挺舒服。\n网络：科学上网不容易呀 在孜孜不倦的努力以及不厌其烦的打扰 AI 下，我成功找到了在我的小破本上科学上网的方法。这里不多讲，但是核心只有一个：使用 TUN 模式。启用 TUN 之后，一切都对了，全对！感谢 AI，感谢 DeepSeek，感谢 ChatGPT！伟大，无需多言。\n字体：照着教程开抄 之前在虚拟机上进行安装的时候实际上没太注意字体的问题。这次因为是日常自用，还是留意了一下，毕竟每天看着奇形怪状的汉字真的很别扭。字体的设置基本就是参考 这篇博文，谢谢你，大佬。不过也要注意，读的时候（或者，抄的时候）还是要仔细一些，有一些设置实际上不是最好的设置，可以用出现在底下的更好的配置替代。也算是挡住了一些些伸手党？也许？\n指纹：呜呜呜呜呜怎么硬件还能不开源呀 我的笔记本最让我自豪的一点就是她有非常好用的指纹识别。这个本来应该没什么要紧的，但是想到之后就很像折腾一下。特别是回回输入密码，真的有点累。虽然这个本是我自己用，里面也没啥东西，但是还是不太想无密码裸奔。而如果有了指纹，一切都变得熟悉了。啊，那该是多么美妙呀。\n直到我花了两个小时多把指纹识别都配置的差不多了的时候，我才发现，愚蠢的小米旗下的 Redmi Book 14 使用的指纹识别模块是闭源的，也没有相关的逆向工程尝试，现在没有任何驱动能启用它。\n泪就这样拉了出来。特别是愚蠢的 Firefox 还始终坚持认为我的笔记本是带了可用的指纹识别的，想生成个 Github 的 token 都不行，非得要我按指纹。我按个大头鬼。\n唉。\n收尾：又是一篇流水账，但是还是做一些总结 感觉这篇没写什么正经东西，又是纯粹地做了一些记录，然后就是磨磨叽叽自说自话了。鉴于此，我决定总结一下一路遇到的主要的坑在哪里，以及安装的大致流程，做一个 quick reference。\nQuick Reference: Installation 以下是从最初的准备工作到得到可用系统的过程：\n准备启动盘，备份，barabara 加载系统，从启动盘启动，进入 shell，执行基本检查（系统架构，键盘设置，网络验证，时区设置……） 磁盘分区（重要）并进行格式化，挂载文件系统 检测 pacman 镜像速度并选择，安装必要包（base, linux, linux-firmware） chroot 进挂载的文件系统，安装必要工具（网络管理，文本编辑器，pager，man-page） 设置 bootloader（重要且坑），需要仔细阅读文档 尝试重启并用 bootloader 启动，进入 tty1 Quick Reference: Customization 以下是得到我目前使用的环境的部分配置过程：\n安装好，保证能正确启动 Arch Linux 用 nmcli con up 启动网络（后面发现可以用 nmtui），保证网络畅通 添加 archlinuxcn 源 执行更新，安装软件包。我安装了 vi, sudo, git, eza, zsh, nvim, kitty, firefox 等基础工具 安装 oh-my-zsh 与 oh-my-posh，导入已有配置，添加常用别名如 l, la, l., ls. 等 安装窗口管理器，这里一开始使用 KDE plasma 作为 “起码能用” 的桌面环境，以及套件 dolphin 作文文件管理器 安装中文输入法 fcitx5-im 以及 fcitx5-rime，进行必要配置（XDG 配置等） 更改 localectl 以便正常使用 man 安装 yay 以及尝试科学上网 遇到的坑： 下面是花费时间比较多的部分，这里列举一下：\n分盘搞错盘了，本来内存是 nvme 结果分到 sda 了； 分盘的时候没想清楚到底该怎么分，瞎分最后还得重来 没有检查镜像速度导致龟速下载（唉，Arch Linux，必须依赖网络，可惜） umount 的时候没有 umount 干净导致烂掉 mount 的时候没有检查是否正确 mount 到挂载点 忘记安装网络管理器，编辑器等等 没有正确设置 bootloader (一定要读完 bootloader 的 ArchWiki 词条！) 没有搞好 localectl 和 local 安装 fcitx5 之后不重启（记得感觉配好之后就重启试试） 希望这些总结的东西会帮到你吧，让这篇文章不是那么水。\n后记：我一定是对 Linux 有什么奇怪的幻想 亲爱的 Arch Linux 笔记本：\n终于，BTW, I USE ARCH!!! 谢谢你和我走过的一路。自从安装了 Arch Linux，你真的跑的飞快。我还没有回过神来，你就已经启动了。KISS 的原则，pacman 与 AUR 达成的简洁与丰富的平衡，滚动发行带来的刺激，这一切都太令人兴奋了。先进的 Arch Linux 已经完全地超越了老旧的 Windows！ 然而，也许我还是对你有太多的误会。装上 Arch Linux 的你没有变得更加省电，反而似乎更加费电了？我希望这是我没有搞好电池方案配置的锅，但是为什么你不能帮我搞好呢？我懂，我们 Linux 是讲究过生日先从办养鸡场和农场开始的，但是为什么呢？还有，为什么搞不定闭源驱动呢？不能上兼容层吗？说起来就气，怎么你的配置文件还是能变得和 Windows 一样杂乱不堪？怎么软件包随处大小便的时候你还是不管管？道理我都懂，但是系统管理员也不能每天都被埋在这些东西里面吧？还有呀……\n-- 此处省略牢骚 2000 字 -- 但是，你懂的，你可是 Linux，对吧？你已经是一个成熟的操作系统了，应该学会自己面对这些问题了，对吧？ Yours, A Moment\n谢谢你能看到这里。看完这一大堆废话，说实话也挺累的。如果这些整活儿的内容让你能开心一下，那就太好了。最后，一如既往，就祝您身心健康吧。\n","date":"2025-05-02T16:12:04+08:00","image":"https://a-moment096.github.io/p/%E5%AE%89%E8%A3%85-arch-linux%E4%BD%86%E6%98%AF%E7%AC%94%E8%AE%B0%E6%9C%AC%E7%89%A9%E7%90%86%E6%9C%BA/imgs/Alice_hu_249b529adb41c85.png","permalink":"https://a-moment096.github.io/p/%E5%AE%89%E8%A3%85-arch-linux%E4%BD%86%E6%98%AF%E7%AC%94%E8%AE%B0%E6%9C%AC%E7%89%A9%E7%90%86%E6%9C%BA/","title":"安装 Arch Linux，但是笔记本物理机"},{"content":"看了好多证明蛇引理的视频，我也来试试~ 蛇年到了，重在参与嘛\n头图出自 ぬくぬくにぎりめし 太太， 为 稲葉曇 所作的 ポストシェルター (Post Shelter)的曲绘。支持正版，就只有30秒试听了（）\n写在最前 本命年到啦~！作为一个代数爱好者（自称，其实是名词党），最近在B站看到了很多的关于怎么证明蛇引理（Snake Lemma）的视频，比如这个视频。以前在自学代数的时候也遇到过这么个引理，但是看到这个部分的时候已经人快晕了（大概就是看完这个之后就抛弃了那本书吧，Algebra: Chapter 0），所以几乎等于没学过。这次看到这么多关于蛇引理的视频，自然是学习一下，这里也做一个记录吧。在本文中你将看到：\n你在说些什么？ 这么简单的前置竟然也要？ 你这里跳步了吧？ 就算我证的不好，我证的很搞笑也不行吗？ 之类的高血压时刻。为了您的身心健康，如果你打算认真了解蛇引理的话，我还是不建议你深究这篇文章。当然，如果你是找乐子的话，我希望这篇文章能带给大家笑容。这篇文章的面向读者应该对最基础的代数有了解，比如集合啊，函数啊之类的，如果会线性代数就更好了，别的东西会中途提到，毕竟是名词党写的文章，当然起点会很低的吧（笑）。话不多说，开始吧。\n$$ \\gdef\\Ker{\\operatorname{Ker}} \\gdef\\Coker{\\operatorname{Coker}} \\gdef\\Img{\\operatorname{Im}} $$简单（？）介绍 蛇引理究竟是什么呢？这是一个代数学定理，简单来讲，它做的事情和很多代数学定理一样：从已有的两个东西来创造出新的东西。比如，如果我们有一个集合以及集合上的等价类/等价关系，我们就可以构建出来一个商集；给定一个群以及它的正规子群，我们就可以构建出商群；把两个空间 $\\mathbb{R}$ 叉乘起来（笛卡尔积），我们就得到了 $\\mathbb{R}^2$。\n那么蛇引理是针对什么样的代数对象呢？这里就要尝试引入我们的第一个概念：正合列 (Exact Sequence)\n正合列，但是先别急 正合列，同调代数中的重要对象，是由链复型添以特殊的条件而产生的。链复型又是什么？链复型是一系列的交换群或者模通过同态连接起来，且相邻两个同态的复合为0。\n也许你要说：天哪你在说什么鬼东西，这都是啥啥啥呀。既然我们假定读者只拥有最基础的代数知识，我们就从最基础的开始介绍吧。名词党最喜欢的名词介绍环节，启动！\n群，交换群 上面说链复型是由交换群或者模带上同态构成的，为了简单，我们就不介绍模 (Module) 了，专注于交换群。\n但是模是什么？我要看口牙！如果有人讲模之类的话，可以认为就是一个差一点的线性空间，它就差在标量不再是数域中的元素了，而是环 (Ring) ，一种乘法可能没有逆元的神奇代数结构，里面的元素。这里指出，环想要变成域（有的地方管域叫体，英文都是 Field）的话只需要让环满足交换律，并且它的每个非 0 元素都有乘法逆元就好了。 那么交换群，或者从头来讲，群，又是什么呢？有人会讲：群就是对称！有对称，就有群！挺好的，但是对称这种几何元素偏偏要符号化成群元素，这一步我倒是走了蛮久的。我们速通嘛，就说简单一点，尽可能地不丧失严谨性吧。群 (Group)，最为代数学中几乎是最基础的代数结构，和其余的许许多多数不清的代数结构类似，遵循这样的特点：\n从集合而来。它的 “底下” 一定是一个集合。这样我们就可以讨论这个代数对象中的元素了。 它的内部有一个或者多个 “运算”。我们可以想象我们早已熟悉的乘法。既然是运算，我们对这么个东西有这样的要求： 首先运算是两个元素同时参与的。相乘的总是（起码）两个数。注意不一定非得是不一样的数哦。 两个元素经过运算之后应该得到一个元素。两个数相乘之后给出的也是一个数字。 这点不太明显，但是我们的运算总是应该从这个集合来，到这个集合里去。比如 $1\\times 1\\neq\\mathrm{苹果}$。 这样就可以有一个（很基础的一些）代数结构啦。而我们的群，也正是这样的一个代数结构。不过它还有这样的特点：\n群的运算必须要是可以结合的。这意味着如果 $abc \\neq (ab)c \\neq a(bc)$，那它就不是群。（天啊真的有这样的神经结构吗） 群的运算不需要是交换的。其实不交换的东西很常见，例如我们要先穿袜子再穿鞋，这肯定和光脚穿鞋后再套个袜子是不一样的啦。学过线性代数的朋友应该更有体会：矩阵乘法是不交换的。 群得有单位元。何谓单位元？这不是元素吗？这里的单位元是和运算强相关的，说的就是群里的任何元素和这个单位元做运算之后一定得到的是它们自己。 群中元素都得有逆元。没错，这里逆元的概念也是和运算相关的。所谓 “逆”，就是要把一个元素 “逆转” 回单位元。可以想象单位元就是某个出发的位置，每个元素都代表着某个让你移动的方式。而某个元素对应的逆元，就像你移动之后让你移动回原点的移动方式。能走出去，也得能走回来。就是这样。 其实上面的这些内容，经过一些整理的话就可以变成比较严格的群的定义了。然而严格定义谁都能查，这里也就偷个懒啦~ 这里指的指出的是，群上的运算我们一般就叫它乘法。而且在代数的语境下，很多运算我们都叫它乘法！所以在讨论代数结构中的乘法时要注意上下文哦~\n所以群的对称意义究竟在哪？ 我们讲，集合中的元素位置其实是无所谓的，比如集合 $\\{1,2\\}$ 和集合 $\\{2,1\\}$ 是一模一样的。那么，群的对称的意义，就在于群中的元素有两重含义：集合内的一个小不点，以及代表了如何操作这个集合的一个符号。\n我们提到过，群的运算是需要满足上面一大堆条件的。这些条件指向了这样的一个神奇的结果：两个群中的元素相乘，我们可以有意识地将其中一个元素作为操作方式，将另一个元素看作群中茫茫多（或者很少，也许）元素中的某个元素。而这样的运算结果又是群中的某一个元素。\n然后我们再想象这样一副图景：桌子上有一副扑克牌，每一张都分开放，放的很整齐。现在你尝试把这些扑克牌重新排列，这个排列方式取决于你开始重排前看到的第一张牌。在重新排列时，你肯定需要一张一张地取，取到之后会根据你看到的第一张牌来思考应该把它放在哪里，最后你就把它放在了对应的位置。在重复54遍 “取-看-放” 的过程之后，你会惊奇地发现：天哪，竟然又得到了一副扑克牌（？）\n你可能觉得这个发现很无聊，但是这就是对称：在某种操作下又回到自身了。你也许会说：不！位置变了！但是还记得吗？集合中元素位置是无关紧要的。我们这里其实就是在讲群对自身的作用。那么群可以对别的集合进行作用吗？当然！只要某个作用方式满足群的条件，也就是说如果你先做了一个操作，又做了另一个操作（这样就操作两次了，对应群中的两个元素相乘）这俩操作实际上也是你可取操作的一种（群中元素运算后依旧在群里），以及别的条条框框，那么实际上你就是在对这个集合进行着群作用。\n群中蕴含的对称，不在于群自己，而在于它能操作的对象。笨笨的我花了好久才明白这个道理 QAQ。\n太棒了！群是什么，已经狠狠地理解了！那么交换群？诶！交换群一定是运算能满足交换律了吧！\n是的，答案就是这么简单，且无聊。交换群 (Commutative Group，又称阿贝尔群 Abelian group，为了纪念伟大的挪威代数学家阿贝尔)，就是能交换 (Commutativity) 的群 (Group)。你也许会对交换群感到失望，但是代数岂是如此无聊之物！？这一切的原因，其实是：我们还没有引入同态 (Homomorphism)。\n交换群和普通群还是有区别的吧？ 当给一个普通的群赋予交换性时，它身上所多出来的性质远不止交换性这一条。交换性赋予群的不止表面看起来的两个元素可以交换，更重要的是，给交换群内的结构更加严格的限制。比如后面会提到的，交换群的子群全都是正规子群，因此对于任何一个交换群的子群，都可以用来被模除掉而形成一个子群。\n交换群太特殊了，以至于人们给它划定了一个特别的范畴：阿贝尔范畴（Abelian Category）。事实上，交换群甚至子集就是一个模（也就是我们在介绍蛇引理时一开始所提到的那个代数结构）。然而我们这里不计划过多地介绍交换群有多么特别，而是将目光放在交换群上面所定义的运算。更具体地说，是交换群上面定义的运算的符号，以及相关的记号。\n我们前面提到，群里定义的运算被称为 “乘法”。这是个很有趣的名字：为什么我们叫它乘法？我们熟悉的乘法，比如在 $\\mathbb{R}$ 上的乘法，也就是实数乘法，或者在线性代数里我们知道的矩阵乘法，和这里的 “群乘法” 之间有什么样的关系呢？我们指出：实数在作为集合的条件下，赋予我们已经熟悉的乘法后，得到的就是一个群；而线性代数中的矩阵乘法，在将所有的 $n\\times{n}$ 方阵看作一个集合时，赋予矩阵乘法后也能形成一个群。\n然而实数乘法和矩阵乘法是有区别的：实数乘法满足交换律，而一般的矩阵乘法并不满足交换律。因此，实数乘法实际上构成了交换群。不过由此我们也可以看到，无论是否满足交换律，我们经常给这样满足若干条件的运算起一个 “乘法” 的名字。这也是群运算一般被称为 “乘法” 的原因。\n但是，不论是实数，还是矩阵，甚至所整数集合、向量等等，它们都有这样的一个运算，我们更加熟悉，且常常称之为 “加法”。这些运算和乘法相比有什么样的特点呢？它们中的一些，在不谈所谓 “交换律” 时，其实和乘法是类似的。然而，在考虑矩阵的加法和乘法时，区别立马就显现了出来：矩阵的加法是满足交换律的，而乘法不满足交换律。那么我们就这样规定：一般群（或者不满足交换律的群）的运算就称为乘法，而交换群上的运算则称为加法。从记号上来看，我们这里做一个小表格，方便更直接的对比。\n项目 一般群 交换群 运算 乘法 加法 记号 ab a+b 左陪集 aH a+H 单位元 1 0 交换律 不满足 满足 这里要提出的是，上面的区别在不考虑交换性的情况下，仅仅是记号的区别。事实上，如果你愿意，完全也可以使用乘法记号，不过这就需要在文中特别标注出来就是了。\n最后，这里引出这样一个观点：抽象代数，如研究群、环、域、模的代数结构性质的这些内容，在理解这些代数结构的过程中，最好的例子有两个：一是整数极其衍生结构；二是线性空间以及其上面的矩阵。当然，只是私货而已，如果有什么问题还请见谅。\n同态，同构，等价关系 首先，代数中［Homo-］的词头其实很常见（？）。这是代表着两个东西之间一定有什么相同的地方。而同态，正是指出了两个代数结构之间相同之处的东西。请注意这里用到的是 代数结构 而非 群 或者 交换群。同态广泛地存在于代数学中，到处都是同态。那么同态是什么呢？其实你早就见过了。对于 集合 这个最基础的代数结构而言，同态就是 函数，或者说 映射1。既然函数是对于集合而言特殊的同态，那么对于群而言，特殊的同态是什么呢？很可惜，没有一个特别的名字，或者大家就直接叫群同态了。然而群同态确实是有其特殊之处的。我们稍后再细讲这种特殊点在哪，以及何来的“同”一字。\n回忆我们很熟悉的集合上的函数，它有这样的特点：\n函数必须要有定义域，它是一个 集合，且这个集合里的每个元素都能被函数处理（作用）。不能说有个定义域的元素不能被函数吃掉，那就礼崩乐坏了。函数是不会剩饭的。 函数必须要有陪域。他也是一个 集合。请注意这里不是说不是值域，而是陪域。值域是函数能吐出来的东西组成的集合，而陪域则是函数吐出来的东西一定会存在的集合。所以，很自然的，会有一些陪域上的元素不会有任何定义域上的元素去对应。 定义域中的每个元素 能且只能 对应陪域上的一个元素，而陪域上的元素可以有0个，1个或者很多个定义域上的元素对应。这就像投篮，球可以投不中，可以一个球一个框，也可以很多球进一个大框里，但是不能一个球同时进两个框。 判断两个函数是否相等（没错，函数作为数学对象是可以判断是否与另一个相等的）的铁则是：定义域相同，陪域相同，定义域上的每个元素通过两个函数作用后得到的结果总是一样的。也就是说，要检测函数的三个要素都是一样的。表达式也许会骗人，但 函数的定义 永远是诚实的。 天啊我怎么又讲了一遍函数是什么？原因是：函数，作为同态的一个例子，自然就包括了同态的许多特点。然而同态还有一个重要的特性，也是被冠以 “同” 字的原因：同态必须保持结构！我们没有在集合中看到这样的特点，是因为集合里什么结构都没有。也许有人说：集合里的元素都是有名字的呀？什么 1 啊 2 啊的，这不就有结构那样的东西了嘛。这里要明确的是：集合里这些看似特殊的元素，它们的特殊性全都源自于我们为了能区分它们所给的，甚至就是为了能数清楚这些元素，不至于把它们搞混。So，集合真的很单纯，它上面的结构都是后面赋予的。当然，你也可以说 “没有结构” 也是一种结构，因为 函数不会把集合变成别的什么不是集合的东西，保持了 “没有结构” 的特点（结构）。\n哦，好，但是说了一圈，到底怎么保持结构？群同态到底是什么样的？观察上面函数的特点，我们提炼一下：\n同态要有来有去，且来去都是同一类东西，不能来去之后东西不一样了。这说明 同态不会给对象添加或删去任何结构。\n就是说，群同态只能连接两个群。或者，一个群上如果作用了一个群同态，那么它就必须给出一个群。这点对于其他所有的代数结构都是一样的。\n还是一头雾水？是不是觉得随便哪个集合上的函数都能在集合变身成函数后也跟着变成同态？没关系，就群同态而言，我们其实可以写出群同态需要满足的特点（多亏了运算的存在）。\n设有两个群 $G$ 和 $H$，它们之间有个从 $G$ 到 $H$ 的群同态 $\\varphi$。我们记群 $G$ 的运算为 $\\times_G$，记群 $H$ 的运算为 $\\times_H$，群 $G$ 中有俩元素 $g_1$ 和 $g_2$。这样一来，由于 $\\varphi$ 是群同态，有：\n$$\\varphi(g_1 \\times_G g_2) = \\varphi(g_1) \\times_H \\varphi(g_2)$$ 而且它有一个很神奇且重要的特点：群同态只能把一个群的单位元映射到另一个群的单位元。这点乍看很神奇甚至不可思议，但是经过简单的证明就可以得到这样的结论了。这也是为了保持群的结构而对群同态做出的一个很强的限制。这也说明了，代数结构越是复杂，同态的限制就会越大。\n最后我们讲一种特殊的同态（或者态射，我们这里不区分两者，后面在范畴部分会做出说明），它需要有一个态射作为基础。我们设有这样的一个态射 $f:\\\\,A\\to B$，且在 $A$ 中有一个保持原有 $A$ 结构的子结构 $A'$，在集合层次上则为包含关系。此时我们就可以定义所谓的 限制 （Restrict），就是把定义域从 $A$ 换到了其子结构 $A'$ 上而已。它的记号为：$f|:\\\\, A'\\to B$。\n我们接下来介绍同构 (Isomorphism)。它在集合函数中的对应就是所谓的一一对应函数了。回忆所谓的单射和满射，单射说一个萝卜一个坑，满射说值域就是陪域。而同时满足这两个条件的话，这个函数就是一一对应的函数啦。我们立刻使用一些新词来讲这些事情，因为函数（映射）是集合间的同态嘛。\n同态中有单态 (Monomorphism)，也有满态 (Epimorphism)。而同时满足这两点的，即为所谓的同构了。它们的要求和集合函数是一模一样的。然而还有别的定义方法，使用态射的逆（啊没错它们都是态射但是这就留到范畴论再说吧）即可定义同态的单或满。回忆之前学过的逆函数这一存在，一个函数的逆函数再作用到函数的话就会变成恒同映射（把一个元素映射到它自己）。这是一种双边逆，更常见的情况则是一个态射只有左逆或者只有右逆。我们称有左逆的态射为单态，有右逆的态射为满态，有双边逆的则为同构。这个我们不证，有兴趣可以挑一些例子看看。请把重点放在 “能不能找到原来的元素” 以及 “如果能找到原来的元素，那么一定会如何”，并注意函数的复合是从右到左的。\n这里顺带提出原像（Inverse image）的概念。原像是和某一个陪域中的元素，以及一个态射相关的。它本身是一个集合，记录了所经过该态射后能得到该陪域中元素的所有定义域中的元素。它的记号以及形式化的表达是：若存在一态射 $f\\vcentcolon\\space A\\to B$ 以及 $b\\in B$，则 $b$ 在 $f$ 下的原像记为 $f^{-1}$，定义为：\n$$ f^{-1}\\vcentcolon=\\left\\{\\space a \\space \\vert\\space\\forall a \\in A, f(a) = b\\space\\right\\}. $$那么这样一来，单态则是所有陪域上元素的原像只能是空的或者只能有一个元素的态射，而满态则是所有陪域上的元素都有非空原像的态射。利用这个概念，同构还可以定义为所有陪域上元素的原像有且只有唯一一个元素的态射。\n同构从字面意思来理解，是 “保持结构” 的映射。可是之前还说同态是保持结构的映射，这两个区别在哪里？事实上，同构比同态要求高多了。同构要求的是 “构造完全相同”，而同态则只要求 “是同一类东西，不会多结构，也不会丢结构”，却可以修改这个结构。比如，同态可以让一个大群变成一个小群，搞得里面的每个元素以前有更丰富的运算结果，结果到了小群里好多元素被捏在一起了，这些丰富的结果也就没了。而同构会很严格地将一个群变成另一个大小一模一样的群，它们结构的丰富程度或者精细程度是一模一样的。在只关心群这个整体以及它怎么与其他群发生转变，完全不关心群内部元素有什么特别之处时，我们可以说，同构的两个群，它们在同构意义下可以被视作是相同的。顺带一提，集合的同构就是映射到元素个数相同（集合的势相等）的另一个集合。这也是个大坑，感兴趣可以搜 Schröder–Bernstein 定理或者伯恩斯坦定理。\n对于群而言，群的同态会把群的一个或几个元素捏在一起形成新群的一个元素。同态是创造新群的一个重要方式。但是假如我们考虑 把几个元素捏在一起形成一个新的元素 实际上意味着 对原来的群中的元素进行分类，那我们就会形成很有趣的结构，商群 (Quotient Group)。我们不会深入这部分，但是这个思想是极其重要的，因此我们需要介绍另一个概念：等价关系与等价类。\n小学数学，甚至幼儿园数学，经常会遇到这样的题目：把一堆苹果分成若干份，每份有几个苹果；把苹果平均分成若干份，最后剩下几个苹果。这样的题目是为了让孩子熟悉除法，而我们这里则要指出，这就是除法，或者所谓的 “商” 所代表的含义。而我们在分苹果时所做的事情，就是在对苹果分类。\n我们要如何进行分类呢？特别是对一堆苹果而言，分成堆时我们做了什么？也许我们有某个标准，也许就是简单的 “我乐意”，但分成堆的过程中每个苹果最终都有属于自己的一堆。假如我们要分成三堆，那么我们完全有理由将三堆起不同的名字，比如：科比，牢大，曼巴。这样一来，每个苹果就都有了一个属性，一个标签。而苹果之间有什么关系吗？有的。我们观察同一堆的苹果，如牢大这堆，会发现这样的（显而易见）的特点：\n一个属于牢大的苹果，那么他就属于牢大（？） 如果一个苹果在牢大里，另一个苹果也在牢大里，那么它们俩就都在牢大里，不论进入牢大这堆的顺序 如果苹果A和苹果B都在牢大里，苹果B和苹果C也在牢大里，那么苹果A和苹果C就一定在牢大这里。 不论分类手法如何，不管分类标准怎么样，上面这三条总是成立的。而在分好之后，对任何人都可以只宣称这堆苹果属于哪一堆，不用管它具体怎么样了。有人问这个苹果是哪个，都可以回答这个苹果是从科比或者牢大或者曼巴这堆里取出来的。\n还是一头雾水？上面的例子是想说明这样的一件事：只要你选了，那就会形成一个标准，这个标准内的每个成员都会接受这样的束缚，而这个约束是有 自反性，反身性 和 传递性的。这些性质就刻画了一个 “关系”，称为 等价关系。我们刚刚用分好的类来说明这类关系一定存在，而反过来讲，根据这样的关系，也一定能进行这样的分类。最后分出来的 “每一堆”，我们就称为等价类。\n分类是代数学中另一个极为重要的话题。有一些出色，重要且惊艳的研究正是建立在这样的分类问题上的，比如传说中的 有限单群分类，洋洋洒洒几千字的论文将整个单群分类问题整的明明白白。分类如此重要的原因还在于帮助我们创造新的代数结构，也就是所谓的 商。比如使用同态对群进行划分则会涉及著名的 群同构基本定理，描述了用同态下的等价关系创造出的商群有什么样的信息。\n我们这里先不深入介绍商群，因为它将涉及到子群 (Subgroup)，陪集 (Coset)，正规子群 (Normal subgroup) 等概念，太啰唆了。这里只指出商群的记号为 $G/H$，其中 $G$ 和 $H$ 都是群，且 $H$ 是 $G$ 的正规子群。这个商群的元素是这样的：每个元素都是一个集合，这个集合内是群 $G$ 中的元素，并且这些群 $G$ 中的元素都相互等价，而这个等价关系则由群 $H$ 这样确定：元素 $a$ 和 $b$ 等价由 $a^{-1}b \\in H$ 决定。换句话说，我们根据群 $H$ 制定了元素的分类标准，把分好类后的每个 “元素堆” 作为商群中的每个元素。能分多少堆，商群就有多少个元素。\n要注意的是由于等价关系，商群中每个元素（也就是 $G$ 中元素的集合）里都可以选出唯一的一个 $G$ 中元素来代表。那么既然如此，我们就使用在代表元的头顶加个尖尖的东西来代表这个集合了。比如有一个等价类 $A$ 中有一个元素 $a$，此时我们就可以用这个元素 $a$ 来代表这个等价类 $A$：$\\hat{a} = A$。这个记号还是比较重要的，所以这里提前介绍一下。\n太棒啦！感觉智慧满大脑了~ 但是这么多前置了，和蛇引理有关系吗？还有多少前置需要呢？答案令人振奋呀：还有一节就好了！我们已经明白了同态是什么样的，交换群又是啥，商群里的元素怎么确定，有什么样的特点。我们只需要再看一看最后两个和同态有千丝万缕联系，作为 “群同构基本定理” 中的 C 位的两个特殊的代数对象，核 (Kernel) 与像 (Image)，就可以开始一窥蛇引理的神秘了~。\n核与像 核的概念其实很简单，它高度依赖于同态，本身是一个特殊的集合（我们先看它单纯的集合结构）。它是同态的定义域上所有能被对应到陪域的 零元素 的元素，记号为 $\\Ker$。假设有某个同态 $\\phi$，那么在这个同态下的核就记为 $\\Ker\\phi$。这里的零元素应该是代数结构中普遍存在的单位元，而称为零元素的主要原因是因为对我们即将研究的许多代数结构而言，它们上面的结构实际上是交换的。交换的运算我们会叫它们 加法。而我们熟悉的加法的单位元就是 $0$。\n我们上面只说了核底下依赖的集合是怎样选取的，然而由于同态的性质，核上经常都会有额外的代数结构。这一点很容易确定：对群而言，单位元自己本身就是一个平凡群，其上的唯一运算就是单位元和单位元进行运算之后得到单位元自己。那么既然单位元是一个群，由同态的要求，我们马上就可以得知，群同态的核很自然地就拥有群结构。不但如此，我们在此不加说明地断言：群同态的核总是群的定义域的一个正规子群！而有了正规子群，我们马上就可以讨论定义域的群商去这个同态的核所得到的商群了。事实上，群同构基本定理中就和同态的核关系非常密切，且经常使用核来构造商群。\n对于核而言，我们还想提到这三点：首先核一定是依赖于某个同态的，没有同态是没有办法讨论核的。从它的记号就可以看出，我们选择使用 $\\Ker$ 记录同态的符号而非其定义域，然而也请切记核作为集合而言一定是定义域的子集。\n其次想要提到的是核在 同调代数 （也许也不是？）中的意义：核衡量了同态的性质，告诉了我们一个同态距离单态究竟有多远。这是由于这样的定理：核中的元素只有一个（也就是单位元）当且仅当同态是单态。那么如果核越大，同态距离单态就越远了；核越小，同态就越像单态。\n最后一点也许会复杂一些，我们想提到的是：群同态的核由于一定是正规子群，而正规子群又一定能够被商掉。考虑我们上面提过的构造商结构的过程：被商的集合/结构是作为一个选择方式出现，而这个选择方式就是这个结构中的所有元素都被视为同一个元素。我们进行这样的猜测：这样用核来构造的商群中的元素，每个元素都是一个集合，而这些集合与核是相似的：它们都有同样的大小。幸运的是这样的猜测是成立的。最后也不卖关子了：商群中的元素就是正规子群的陪集，而每个陪集的大小都是相等的。所谓的陪集就是把群里面的子群用某个元素乘一下（移动一下）。这里说 “集” 有两个层面，一是我们不计划赋予它别的结构，他们就作为集合存在于商群；二是我们没法赋予群结构，除了最平凡的那个正规子群。更一般的陪集是没有办法满足单位元要求以及逆元要求的。\n核真的很重要，所以我们聊了许多。不过这主要是由于核与商群之间重要的联系。有了这样的铺垫，我们理解像将会更迅速：像也是一个子群，但不是更特殊的正规子群。\n像我们早就熟悉了，就集合层面而言，就是值域 “更代数”的一个名字。而同样由于同态的存在，像也一定是一个群。但是不同于核，像并不总是正规子群。这真是一个悲伤的故事，我们不能再愉快地构造商群了。也许你之前幻想着，既然核可以衡量同态与单态的距离，是不是像也可以衡量同态与满态的距离呢？因为很显然可以看到，像越大越可能是满态，像与陪域相同那就是满态了。然而很可惜，我们不用这种方式。\n但是我们有三个好消息：第一条是，虽然像不是个正规子群，但是我们依旧可以用像构造商结构！第二条则是，虽然像不能衡量同态的信息，但是它构造的商结构可以！我们还给它一个特别的名字：余核 (Cokernel)。第三条则是，我们其实要研究的是交换群，而对交换群而言，所有的子群都是正规子群的！这样一来，前面讲的商结构也就可以是商群啦。\n子群，商群，陪集，商结构，到底是怎么回事？ 在讲商群时，终究还是无法避免陪集的概念。陪集和商群之间到底是什么样的关系？陪集之间又有什么样的联系？陪集到底是什么样子的东西？商 究竟是什么？我们讲了这么久的子群，正规子群，它们到底都是啥？这里我们斗胆写一写吧。\n先看看子群吧，其实子群的概念很简单：一个群的子群，实际上就是子集加上原群的运算。这样一来，子群的单位元一定就是原群的单位元，而子群的运算就是原群的运算了。这个还是相对比较简单的一个概念，麻烦的是所谓的正规子群。而为了讨论正规子群，必须要讨论所谓的陪集。我们把陪集往后放一放，先讲商群中的元素们：陪集。\n我们已经提到，商群就是对群按照其正规子群的需求进行分类从而得到的一个更小的群。这个更小的群里面是一个个的陪集，我们讲陪集中的元素都是相互等价的，因此，这个更小的群里的元素虽然都是集合，但是完全可以从每个集合中取一个元素来代表这个集合（由于等价关系），这个元素就被称为代表元。所以你可能会见到商群中的元素是用一个个原群中的元素带上标记构成的。但是还请记住，商群中的元素始终都是集合，也就是陪集。\n我们再谈谈陪集。陪集是这样一个集合：它必须依赖一个群里的元素，以及这个群的一个子群。我们记较大的群为 $G$，它的子群为 $H$。那么我们取 $G$ 中的一个元素 $g$ 之后，再和子群 $H$结合一下，就得到了所谓的陪集了。具体是这样的：\n还是先提醒：$H$ 是住在 $G$ 里面的，它们拥有一模一样的运算，所以 $G$ 中的元素是完全可以与 $H$ 中的元素运算的。 我们从群 $G$ 中取出一个元素 $g$。这个元素是任意的，只要在 $G$ 里就好。然后还要把 $H$ 中的元素一个一个地取出来，准备进行运算。我们要取出所有 $H$ 中的元素，不遗漏不重复。 用 $g$ 和 $H$ 中的元素依次进行运算。在做运算时，我们先把 $g$ 放在 $H$ 中元素的左边。最后得到的结果放在一个篮子里（或者框里，也可以）。 最后检查这个框子，我们给它贴上标签：$gH$。这个框就是我们想要的陪集，准确地说是 $H$ 在 $G$ 中元素 $g$ 作用下的 左 陪集。 自此，我们便成功得到了一个左陪集。如果在进行运算时将 $g$ 放在 $H$ 的右边，则称之为右陪集，记号也变为 $Hg$。注意到陪集中的元素一定是在 $G$ 中的元素，我们自然好奇：陪集内元素有什么样的特点呢？我们回顾上面的内容：陪集内元素相互等价，等价关系为 $a^{-1}b \\in H$。我们来看看是怎么回事。我们更多地关注左陪集，右陪集是类似的思路。\n证明：$a^{-1}b \\in H$ 当且仅当 a 与 b 等价，亦即 $aH = bH$。\n首先，$a$ 与 $b$ 都一定属于各自的陪集，因为 $H$ 是一个群，群里有单位元，则陪集 $aH$ 中肯定有 $a$，$bH$ 中也肯定有 $b$。\n既然 $a^{-1}b \\in H$，那肯定就有一个元素 $h$ 就是 $a^{-1}b$。由于乘法逆元的性质，我们给两边左乘 $a$，就有了 $b = ah$。回忆 $H$ 在 $a$ 的左陪集的定义，这就说明了：$b$ 也是 $aH$ 中的元素。\n此时我们想到，既然 $H$ 是一个群，$h$ 在 $H$ 里了，那 $h^{-1}$ 也肯定在里面。我们就给 $b=ah$ 的右边同时乘以 $h^{-1}$，就有得到了：$a=bh^{-1}$。这同时也说明了 $a$ 也是 $bH$ 中的元素。这样一来，我们就证明了 $aH = bH$，因为我们的 $a$, $b$ 是任意选择的 $G$ 中元素，这样的任意性保证了不会选取特殊的点。\n其次，当 $aH = bH$ 时，有这样的情况：$a$ 与 $b$ 相等，则结论自然；若是 $a$ 与 $b$ 不相等，这时由于群乘法的封闭性，一定要有一个 $h$ 满足这样的关系：$ah = b$。现在我们视线移向群 $G$ 后，便可以同时左乘 $a^{-1}$，这时就得到了我们想要的结论。至此，我们证明了这样的选择方式确实是构成了一个等价关系。\n最后我们关注陪集间的关系：左陪集是不一定等于右陪集的。这点如果能恒成立的话，那么这个群 $H$ 就一定是一个正规子群。另外，群 $H$ 的所有左陪集都有同样的大小。这一点的理由是：左乘群 $g$ 中的元素这个动作总是可逆的，再左乘回 $g^{-1}$ 就可以了。这样一来，左乘 $g$ 就实际形成了一个集合间的双射，也就是所谓的同构。它保证了元素个数相同。也正因如此，用左乘 $a$ 定义的 $H \\to aH$ 就保证了 $H$ 与 $aH$ 的元素个数相同了。由于 $g$ 是任意选取的，所以任意的左陪集都有相同个数的元素了。这个结论对右陪集而言也是显而易见的。\n另外我们提一下记号的问题。对于使用乘法记号的群而言，由于我们的子群本身就是一个群，所以一定有一个单位元。而根据左陪集的形态，我们就知道了：每个左陪集中一定有一个元素，这个元素就是子群 $H$ 的单位元乘上我们左陪集所左乘的元素。简单来说，如果有一个左陪集 $gH$，那么这个左陪集里面就一定有一个元素 $g 1_H$。而既然左陪集中每个元素之间都是等价的，我们很自然地就可以使用这个元素来代表这个左陪集。至于记号，我们上面已经介绍了：$\\hat{g}$ 就可以代表 $gH$。诶？那假如我用单位元去左乘以这个子群，得到的就是？没错，就是子群本身形成的陪集。而这个特殊的陪集在我们下面定义的商群乘法下自然就是我们需要的单位元了。\n我们定义正规子群为左陪集等于右陪集的子群。在这个定义下，很明显就可以看出，满足交换律的交换群里没有不正规的子群了，因为很轻易地就得到了左陪集等于右陪集，只需要把交换律下放到陪集内元素的计算过程中即可得到。那么对于交换群/阿贝尔群而言，陪集的记号是什么样的呢？我们很轻易就可以类比出来：既然乘法记号的群是用一个元素左乘子群得到左陪集，那么加法记号的群就用一个元素加上一个子群得到这个子群的陪集即可。同样，我们可以使用这个加上去的元素来代表这个陪集，方法也是在上面戴个小帽子。\n有了正规子群，我们就可以愉快地进行商群的构造了。然而，为什么必须是正规子群呢？不能商去一般的子群吗？答案藏在商群运算的合理性中2。\n为了尝试从普通的子群构造商群，我们取子群的左陪集们然后就可以形成一个集合了。这个集合内的每个元素都是子群的左陪集。现在我们希望给这个集合上面添加运算。由于左陪集的元素是形如 $gH$ 这样的，所以我们自然希望 $g_1H \\cdot g_2H = (g_1g_2)H$，也就是可以直接借用我们在群 $G$ 或 $H$ 中已经有的乘法了。这样定义的乘法满足了群运算的所有性质。然而，定义这个乘法不能靠我们一厢情愿，我们得检查定义的是否合理，即设 $a, a' ,b$ 是满足了 $aH = a' H$ 的任意的 $G$ 中的元素，我们要有 $(aH)(bH) = (ab)H = (a'b)H = (a'H)(bH)$。\n根据陪集定义，我们取任意的 $h_1$, $h_2$ 以及由它们决定的某个 $h_3$，则有 $ah_1bh_2 = a'bh_3$。由于 $aH=a'H$，根据之前的论述，我们指导一定有某个 $h_4$ 满足 $a = a'h_4$。我们带入前面式子，有 $a'h_4h_1bh_2 = a'bh_3$。根据群乘法可逆的条件，有 $h_4h_1bh_2 = bh_3$，我们再把 $h_2$ 的逆乘到等式右边，根据 $H$ 中乘法封闭性，就有：$h_5b=bh_6$。由于我们的 $h_1$，$h_2$ 是任意的，$a$，$b$ 也是任意的，所以 $h_3$ 和 $h_4$ 也不受额外条件的束缚，进而 $h_5$ 与 $h_6$。再回忆我们的左陪集和右陪集的定义，因此我们可以认为：为了满足我们的乘法条件，则必须要有 $Hb = bH$，这正说明了 $H$ 必须是正规的。至此，你应该已经发现：为满足运算的合理性，子群 $H$ 必须是正规子群。\n我们也可以这样理解。取 $G$ 中的任意两个元素 $g_1$与 $g_2$，再取 $H$ 中任意的两个元素 $h_1$ 与 $h_2$，我们要保证 $g_1h_1g_2h_2 = g_1g_2h_3$，其中 $h_3$ 可以是某个由计算过程得到的一个 $H$ 中的元素。要想把 $g_2$ 往左挪过去和 $g_1$ 凑成一对儿的形式，我们必须要让 $g_2$ 和 $h_1$ 存在某种形式的 “交换律”，这样的交换律必须保证 $g_2$ 还是 $g_2$，$h_1$ 则必须还是 $H$ 中的元素。但是，很可惜，这样的 “交换律” 只能存在于真的交换群，或者最低限度的办法：让左陪集等于右陪集，也就是正规子群中。否则这两点无法保证。\n上面这个说明，也是为了指出证明定义合理的重要性。这一点在代数中是十分重要的。而在讨论完陪集和正规子群的重要性后，我们最后要讨论的是：商 到底是什么。\n我们其实已经指出过，商就是所谓的分类。小学学到的 “分堆问题” 就已经是对 商 这个字非常好的诠释了。至于为什么用了 “商” 这个字…… 首先，我不知道；其次，也许可以问商鞅？（什么地狱笑话）\n商结构远不止存在于群或者集合中。商结构几乎存在于任何代数对象里。我们可以对拓扑空间做商结构，就像是把纸/空间缝起来/黏起来一样，这样我们就可以得到各种有趣的拓扑空间，比如甜甜圈（环面）、克莱因瓶、莫比乌斯环带等；我们可以把整数轴折叠起来，这样可以得到一个有限群（还很有可能是循环群）；我们还可以把 $\\mathbb{R}$ 上多项式空间（就是所有以实数作系数的多项式组成的线性空间）商去多项式 $x^2+1$，这样得到的就是我们熟悉的复空间（复述域）。这里我们提出一种理解商空间的方法：把空间的某些点/线/面或者什么东西黏起来。这个 “黏起来” 的动作，实际上就是把某些点看作同一个点，而这样就等于定义了一个等价关系：黏起来后到同一个点的原空间内的点就在同一个等价类里面。\n此时你可以看到，如果你有一种分类方法，并且你可以用什么办法把代数对象里的元素放到不同的几堆儿里，那你就已经可以生成一个商结构了。它最最最最最起码也是一个商集，而要是你分类方法足够好，你得到的商结构就会更好。我们最后提一下商结构的记号，一般有两类表示方法：一是商去一个等价关系，二是商去用这个等价关系生成的等价类。这两种记号一般都是代表着同一个含义的。利用这个等价关系对原代数结构进行划分会得到若干等价类，其中的一个就是商去等价类记号中的那个等价类。\nSo，这就是对这么几个代数学结构的解释了。希望你不要因为这些文字而感到眩晕的同时，得到一些对这些代数结构直观的解释。我们回到主线吧。\n正合列，以及一点点点点范畴论 现在我们已经清楚了什么是交换群，什么是同态，什么是核，像，商群以及余核。是时候看看我们想要研究的结构了：正合列，以及对应的图。下面就是我们要研究的对象，也是一个图的例子：两个整合列所组成的图。\n两个整合列，通过整合列间的同态链接 你可以在图中看到两个虚箭头，这两个虚箭头我们先把它们看成实线的，也就是实际存在的。后面证明蛇引理的时候这两个箭头是可以不存在的（当然也就没有连接着的0了）。 链复型 我们先来说说正合列（Exact Sequence）。上图中的正合列有两个，分别是 $0\\to A \\to B\\to C\\to 0$ 以及 $0\\to A' \\to B'\\to C'\\to 0$。它们中的 $0$, $A$ 等我们称之为 点，实际上是一个个交换群（一般是模，我们这里取交换群即可），而每个箭头都代表着一个同态。这些同态有着特殊的要求，如果这些同态只是一般的同态，那它们就什么都不是。为了使之成为整个列，我们需要先得到所谓的链复型（Chain Complex，上下文明确时可能直接叫复型 Complex）。\n链复型要求使用同态将一系列的数学对象连接起来，通常这些数学对象以及对应同态还会有一定的顺序，且同态之间的复合还要满足特殊的要求。具体而言，链复型要求这样的序列：\n$$\\cdots\\xrightarrow{d_{i+2}} M_{i+1}\\xrightarrow{d_{i+1}} M_i \\xrightarrow{d_i} M_{i-1} \\xrightarrow{d_{i-1}} \\cdots$$满足条件：$d_{i+1}\\circ d_{i} = 0$ 对于所有的 $i$ 都成立。这样的链复型可以被记作 $(M_\\bullet,d_\\bullet)$。这样的定义蕴含了下面的信息：\n交换群的序号从高到低，同态序号也从高到低 对于所有的同态而言，左侧的同态复合上右侧同态得到的是零同态，也就是把所有的元素映射到单位元上（对于交换群，单位元就是0） 由上面一条，如果左侧同态复合右侧同态得到了恒通映射，就说明左侧的同态必须把元素映射到右侧同态的核里面。若不然，则无法达成两次复合后为零同态。 链复型的结构要求每个点都是同一种结构（交换群），且某个点里的任何一个元素沿着链复型移动两次后一定会映射到单位元（后面称零元）上。这样的代数结构是为了方便我们讨论所谓的 同调，也正因如此，链复型是同调代数中最基础也最重要的代数结构之一。\n同调群，正合，正合列 上面提到，正合列是在链复型商加条件得到的，而这个所谓的条件就是 正合 条件。而为了讨论正合，我们还要引入同调群的概念。有了同调群，正合就非常好判断了。\n我们还是用上面的链复型来举例，所谓的同调群是指这样的商结构：\n$$H_n(M_\\bullet) \\vcentcolon= \\Ker d_n/\\Img d_{n+1},$$即一个同态的核与上一个同态的像之间的商群。当链复型的某个点处（即某一个 $n$）的同调群是平凡群（即只有一个元素的群，记作 $0$）时，我们称这个点上是 正合的。而如果每个点都是正合的，我们就叫这个链复型为正合列。表达正合关系也可以不借助同调群，因为同调群等于平凡群就相当于说\n$$\\Ker d_n = \\Img{d_{n+1}},$$从这个角度来看也许更好理解正合是什么样的关系。仅从集合的角度来讲，链复型的要求就是在说 $\\Img d_{n+1}$ 必须在 $\\Ker d_n$ 的里面，它们之间可能有缝隙：$\\Img d_{n+1} \\subseteq \\Ker d_n $；而正合则表示，这两个集合之间是没有缝隙的。这也许也是正合这个字的来源吧。\n最后我们指出，我们上面的那个图片里所给出的两个正合列更为特殊，因为很短，所以叫它 短正合列。不难看到，由 $0$ 出发的态射是单态，到 $0$ 结束的态射则是满的。而又根据正合的条件，可以得到 $f$ 必须是单态（不然 $\\Ker f \\neq 0$），$g$ 则必须是满态（否则 $\\Img g \\neq 0$。\n图与交换图 学代数的时候会遇到许许多多用箭头代表的态射，而我们也常常需要将态射复合起来形成新的态射。有时我们又会发现，一个态射可以通过两种甚至多种不同的态射复合方式得到。单靠语言经常会感到乏力，自然而然地，我们想到用图（Diagram）来绘制出这样的想法，把一些态射按照对应的数学对象连接起来。上面链复型或者正合列的表示实际上已经是一副图了，但是这个图还是比较简单的。而当我们发现一个态射可以通过不同的态射复合方式得到时，我们就可以把它们画出来，这样的图我们称是交换的，这种图我们叫做交换图（Commutative Diagram）。\n以上面的用两个短正合列组成的那个图举例，如果有 $\\beta\\circ f = f'\\circ\\alpha$ 以及 $\\gamma\\circ g = g'\\circ\\beta$，那么它就是一个交换图。我们后面把态射复合时中间的圆圈 $\\circ$ 省略掉。\n一点点的范畴论 我们最后简单地提一嘴范畴论吧。范畴论是从拓扑那里来的，是根据不同的几何结构间精巧的关系而诞生的描述这种关系的语言，但是后来逐渐被大家发现，好像很多数学结构之间也是可以构建出类似关系的。自此，便有数学家开始建立范畴论，用以正式地，形式化地描述不同数学结构它们内部的或之间的关系。\n我们举一些简单的例子，来看看什么是一个 范畴（Category）。一个很简单的例子就是 所有 的集合以及集合之间的 所有 函数们所构成的范畴 $\\mathsf{Set}$ 了（具体某个范畴的记号一般使用无衬线体，根据情况省略部分字母），另一个例子则是所有群以及所有的群之间的同态所构成的范畴 $\\mathsf{Grp}$。可以看到很多都是 “所有的数学对象以及它们之间所有的同态构成的范畴” 这样的形式。这样的范畴还是比较基础且常见的，且根据这样的形式，我们可以很自然地总结出别的一些范畴，比如 $\\mathbb{R}$ 上的所有线性空间以及所有的线性映射构成的范畴 $\\mathsf{Vect_\\mathbb{R}}$，所有的环以及其同态构成的映射构成的范畴 $\\mathsf{Rng}$，等等等等3。\n范畴之间是可以相互联系起来的，这种联系我们也可以像箭头一样写出来，称为函子（Functor）。而函子之间也可以做出联系，称为所谓自然变换（Nature Transformation）。不过好消息是，我们不需要关注这些内容，而只需要关注某一个具体范畴（具体来讲，就是阿贝尔群范畴 $\\mathsf{Ab}$）的内部即可。\n范畴的作用除了给出不同类型的数学对象之间有什么样的联系之外，也给我们提供了一个讨论问题的舞台。我们可以直接讲我们在某个范畴中研究什么样的问题，此时范畴本身就给出了我们要研究内容的重要信息。另外，范畴论给了我们一些用以描述数学对象关系的语言，它们通常可以一针见血地指出数学对象间是什么样的关系，当然也因为过于抽象且过于具有总结性而被戏称为 “抽象废话”。\n最后，借助范畴论中的一些内容，比如交换图，我们可以方便地描述数学对象之间的关系。\n所以什么是范畴呢？ 我们这里引入范畴的原因其实非常地单纯：希望能引入所谓的交换图这一概念。虽然它本身的引入其实用不太上范畴，但是也许是出于我的私心吧，感觉这里引入范畴也能更好地规范我们研究问题的范围。 那么什么是范畴呢？范畴其实就是一系列对象以及它们之间态射所构成的集合体。我们这里引用著名代数学教材，李文威老师的《代数学方法》中对于范畴的定义。\n范畴的定义：\n一个范畴 $\\mathcal{C}$ 是指以下的资料：\n一个集合 $\\mathrm{Ob}(\\mathcal{C})$，其元素称为 $\\mathcal{C}$ 的 对象； 另一个集合 $\\mathrm{Mor}(\\mathcal{C})$，其元素称为 $\\mathcal{C}$ 的 态射。 另外，对上面两个集合之间有这样的要求：\n两集合间有一对映射： $s\\vcentcolon\\space\\mathrm{Mor}(\\mathcal{C}) \\to \\mathrm{Ob}(\\mathcal{C})$ 和 $t\\vcentcolon\\space\\mathrm{Mor}(\\mathcal{C}) \\to \\mathrm{Ob}(\\mathcal{C})$，它们分别指出了态射的来源与目标。 对于态射而言，有这样的要求：\n针对某两个对象 $X,Y\\in\\mathrm{Ob}(\\mathcal{C})$，我们可以从上面这一对映射中得到这两个对象之间的所有态射的集合：$\\mathrm{Hom}_\\mathcal{C}(X,Y)\\vcentcolon=\\space s^{-1}(X)\\cap t^{-1}(Y)$。在明确所指范畴的情况下可简记为 $\\mathrm{Hom}(X,Y)$。这样的集合也被称为 $\\mathrm{Hom-}$ 集； 对于任意的一个对象 $X$，一定存在一个态射 $\\mathrm{id}_ {X} \\in \\mathrm{Hom}_{\\mathcal{C}}(X,X),$ 这个态射被称为 $X$ 到自身的恒等态射； 给定任意的三个对象 $X,Y,Z\\in\\mathrm{Ob}(\\mathcal{C})$，有这样在其 $\\mathrm{Hom-}$ 集之间的映射，称为合成映射，定义为： $$\\begin{align*} \\circ\\vcentcolon\\space\\mathrm{Hom}_\\mathcal{C}(Y,Z) \\times \\mathrm{Hom}_\\mathcal{C}(X,Y)\u0026\\to \\mathrm{Hom}_\\mathcal{C}(X,Z)\\\\ (f,g)\u0026\\mapsto f\\circ g\\\\ \\end{align*}$$ 且当不至于混淆时可以省略中间的 $\\circ$，将 $f\\circ g$ 简记为 $fg$。 最后，对上面的合成映射而言，有这样的两个要求：\n结合律：对于任意的态射 $h,g,f\\in\\mathrm{Mor}(\\mathcal{C})$，如果映射的合成 $f(gh)$ 和 $(fg)h$ 都有定义，那么 $$f(gh) = (fg)h.$$ 对于任意的态射 $f\\in\\mathrm{Hom}_\\mathcal{C}(X,Y)$，其与恒等映射之间的复合满足关系： $$f\\circ\\mathrm{id}_X = f = \\mathrm{id}_Y\\circ f.$$ 那么以上，就是范畴的比较正式的定义。可以看到它还是有依赖一些集合论的内容的，但这只依赖于对象集合和态射集合之间的映射，以及在 $\\mathrm{Hom-}$ 集之间的映射，并不涉及某个具体的代数结构，特别是没有涉及到在集合上添加运算得到的代数结构。我们一般称这样有集合作为 “基底” 的范畴为 具体范畴。另外，由于范畴的定义非常灵活，实际上可以定义出非常抽象的范畴，比如以态射作为对象的范畴。\n最后要指出的是，范畴最关键的应该是态射，而不是范畴内的对象。范畴论以研究对象间的态射来研究范畴的行为。从范畴的定义中也可以看到，众多的要求都是对态射提出的，而非对对象。在使用或研究范畴时，应注意这一点。\n所以，蛇引理到底讲了什么 终于，我们把为了描述蛇引理讲了什么而需要的一些基础内容介绍完了。可以看到，蛇引理还是需要比较多的前置的。下面就是这个所谓的蛇引理了。我们介绍的是建立在两个短正合列所构成的交换图上的简单版本的蛇引理。具体内容如下：\n蛇引理：\n设有如下图所给出的交换图：\n其中第一行和第二行均为正合列，每个点均为阿贝尔群（交换群）。由这样的两个正合列，我们可以构造出下面的正合列： 且当交换图中的虚线箭头成立时，对应的虚线箭头也成立。 这条引理由于构造出的正合列需要像蛇一样从交换图的左上角开始出发一路拐到右下角而得名。真是恰当的名字。由于我们已经知道所谓的余核，所以上面的正合列实际上还可以写成这样更加对称的形式：\n对称？对称在哪？ 我们常常讲 “对称”，对称常常能带来强烈的美感。然而，对称到底是什么？ 我们从小就知道轴对称，稍晚会学到中心对称，旋转对称等等。然而这些对称始终没有一个综合的描述方法，它甚至不像是数学的内容，反而更像是美术的内容。然而，有了群，我们就可以描述这样的对称性了：对称，就是使用一个群对其进行作用后仍然能回到自身的性质。对称就蕴含于群内部。\n然而我们这里打算提到的对称，并不是和群相关的，而是和交换图相关的。从交换图上可以看到，如果把底下的链条用余核来代替，那么这个图就是非常对称的：上面是核构成的链条，下面是余核构成的链条；左下角是一个单态，而右上角则是一个满态。然而我们肯定不能单纯满足于这样的只从图上看到的对称，我们想问这样的问题：余核，它和核的定义区别如此之大，为什么会这么自然地存在于这个图内？它们俩之间究竟有什么样的关系，让最后的这个交换图呈现了这样的形状？或者问得更简单一些：余核，什么是 余？它好像是剩余的意思，但是从英文上来看又完全看不出这样的关系。余 到底是什么？\n我们做一点剧透：因为范畴和交换图，即因为核与余核之间定义的对称性。可能会有人有这样的疑问：核与余核之间的定义的对称性？从形式上来看完全没有任何的对称性呀？我们指出：在范畴论的语言下，两者完全可以使用 泛性质 进行定义。我们后面会提到所谓的泛性质是什么。\n我们观察核的定义：核是对一个同态定义的。比如有这样的（群）同态：$\\varphi \\vcentcolon G\\to H$，那么这个同态 $\\varphi$ 的核就是一些群 $G$ 中的元素所组成的集合，这些集合在同态 $\\varphi$ 的作用下会映射到群 $H$ 的单位元处。或者我们采用原像的写法，$\\Ker \\varphi = \\varphi^{-1} (1_H)$。\n那么我们应该怎么把他改写成使用范畴定义的东西呢？我们抓住范畴论的核心思想：使用态射来研究对象。作为一个同态的核，它在映射之后一定会到单位元上；作为一个群，它一定是同态的定义域的子群。我们可否用这个性质来做文章？答案是肯定的：我们就如此定义，但通过范畴论的语言来描述这个过程。\n我们定义态射 $\\varphi \\vcentcolon G\\to H$ 的核是这样的一个群范畴 $\\mathsf{Grp}$ 中的一个对象 $\\Ker \\varphi$，这个对象到同态 $\\varphi$ 的定义域 $G$ 之间存在一个包含同态\n$$\\begin{align*} \\iota \\vcentcolon \\Ker \\varphi \u0026\\hookrightarrow G\\\\ g \u0026\\mapsto g \\end{align*}$$（我们这里使用带钩箭头标明它是一个单态）；此外，这个对象满足这样的性质：对于任意的同态 $\\alpha\\vcentcolon X\\to G$，只要满足条件\n$$\\varphi\\circ\\alpha = 0,$$（此处 $0$ 代表零映射，或者叫平凡映射（Trivial Map），即将所有的元素都映射到单位元 $1_H$ 上），那么同态 $\\alpha$ 即可被唯一地分解，即对某个 $\\alpha$ 而言，存在唯一的一个同态 $\\overline{\\alpha}\\vcentcolon X\\to \\Ker \\varphi$，满足 $\\alpha = \\iota\\circ\\overline{\\alpha}$。将这些性质使用交换图来描述的话，就是说下面的这个交换图成立：\n核的定义 换句话来说，对于任意满足条件 $\\varphi\\circ\\alpha = 0$ 的态射 $\\alpha \\vcentcolon X \\to G$，它们都一定可以被分解成两个映射，且这个分解方式是固定的：先有一个唯一的映射 $\\overline{\\alpha}$ 将 $X$ 映射到一个群上，然后再从这个群出发，保持原样地通过包含映射 $\\iota$ 映射到原态射的陪域 $G$ 中。而这样的固定且特殊的元素，就是我们要找的映射 $\\varphi$ 的核，也就是 $\\Ker \\varphi$。\n我们观察这样的定义，它实际上确实定义出了我们熟悉的核，只不过是用了更加范畴论的形式，并没有研究元素内部是如何映射的，而是使用了 平凡映射 来包含所有我们需要的信息，再通过唯一分解的方式来确定它的地位。它只是换了一种更加 fancy 的说法而已。\n而接下来，我们就要仿照这样的形式，来定义余核。我们先来观察已有的余核定义，它被定义为同态的陪域模除掉同态的像得到的结构。为此，我们需要先来看看商的泛性质。我们依旧在群范畴内讨论这个问题，但是它很容易就可以推广到其他的结构中。\n从商的构造过程来看，构造商结构时需要取一个等价关系，然后根据这个等价关系进行划分，最后将所有的等价类放在一起，每个等价类作为一个商结构中的一个元素，这就是取商的过程。如果要在范畴论中讨论这个问题，那么就需要从与商相关的态射出发考虑这个问题。首先我们看取商的过程。\n鉴于上面的过程的统一性，我们将这个过程化为一个态射，称之为商映射 (Quotient Map)，记作 $\\pi$。当明确左或右陪的元素时，也可以在这个记号的左下标处记下该元素，如从整数群构造 n 阶循环群的过程，其商映射就可以记为 $\\pi_n\\vcentcolon\\mathbb{Z}\\to\\mathbb{Z} /n\\mathbb{Z}$。有了这样的记号，我们的讨论也会更加便利。\n既然从态射角度出发，我们想观察：假如从群 $G$ 到群 $G'$ 有一个同态 $\\varphi$，而群 $H$ 是 $G$ 中的正规子群（因此可以被模掉）且 $H\\subseteq \\Ker \\varphi$（为了保证商群依旧能映射到 $G'$ 上）。那么，这个同态 $\\varphi$ 与 $G$ 模 $H$ 得到的子群 $G/H$ 之间有什么样的联系呢？我们有这样的定理，同样，可以用交换图来表示：如果有上述条件存在，那么则存在一个唯一的映射 $\\overline{\\varphi}$，使得 $\\varphi = \\overline{\\varphi} \\circ \\pi$，即下面的图交换：\n商的泛性质 怎么理解这个图的交换性呢？当我们把 $G$ 映射到 $G'$ 时，由于该映射的核的限制，必须有和核的元素个数一样多的元素被映射到同一个 $G'$ 中的元素里（考虑我们定义的核，以及商映射的特点）；当将 $G$ 商映射到 $G/H$ 上面时，由于 $\\Ker \\varphi$ 的元素比 $H$ 中的元素数量要多（上面的子集关系），此时从 $G$ 到$G'$ 的同态 $\\varphi$ 对其定义域 $G$ 的 “收缩力度” 是一定不如商映射 $\\pi$ 的。因此，我们一定可以从商映射得到的 $G/H$ 中再做一次映射，从 $G/H$ 重映回 $G'$，使得 $\\varphi$ 最后被表示为 $\\overline{\\varphi}$ 与 $\\pi$ 的复合。也就是说，$\\varphi$ 被分解为了两步：首先，通过正规子群进行分类，由于我们取的正规子群比核小，所以商群内的每个元素必定被映射到同一个元素内;在进行这样的分类后，再进行一次映射，把分好的等价类按照其中元素原有的根据 $\\varphi$ 的映射方式来将这些等价类映射到对应的 $G'$ 中的元素里。由于拉格朗日定理，子群的关系保证了这样分类得到的等价类个数一定是整除态射 $\\varphi$ 的像的，这也就保证了这个同态是良好定义的，并不会出现一个等价类映射到两个 $G'$ 中元素，或者映射到同一 $G'$ 中元素的等价类数目不同这样的情况。\n在理解上面定理的含义后，我们指出：实际上我们可以借助商的这一泛性质来定义商结构和商映射，即：设 $G$ 是一个群，其有一正规子群 $H$，则通过如下两个泛性质即可定义商群 G/H 与商映射 $\\pi$：\n存在一个群 $G/H$ 和一个群同态 $\\pi\\vcentcolon G\\to G/H$，满足 $\\Ker \\pi = H$； 对任意的群 $G'$ 与 群同态 $\\varphi\\vcentcolon G\\to G'$，如果 $H \\subseteq \\Ker \\varphi$，则存在一个唯一的群同态 $\\overline{\\varphi} \\vcentcolon G/H \\to G'$，使得上面的交换图成立。 也许你有疑问：我们不是在看余核是怎么回事吗？你怎么扯到商结构和商映射用泛性质的定义了？正是由于有了商结构的泛性质，我们才能更好地定义我们已经知道的余核。\n这里也不继续卖关子了，为了定义余核，我们需要做的事情只有三件：一，将上面核的泛性质图里的所有箭头转向；二，把 $\\Ker \\varphi$ 换成 $\\Coker \\varphi$，把带钩箭头换成双箭头（代表满态），再把包含映射记号 $\\iota$ 换为商映射记号 $\\pi$；最后，我们再仿照核的定义，来讲所谓的余核是什么的时候，需要将群改为阿贝尔群（交换群）。我们先把表示它泛性质的图画出来；为了方便对照，我们把核对应的泛性质图用另一种形式画出并附上（两种交换图是完全等价的）：\n余核 核 相信到了这一步，你一定会相信所谓的 “对称” 绝非空穴来风。所谓的余核，说得简单点，就是把核的泛性质里的所有箭头都反转后定义出来的东西而已；甚至于对于范畴论而言，所谓的 “余” 就是将某个对象的泛性质里箭头全部反转后出现的对偶。一个著名的范畴论笑话是这么讲的：\nA mathematician is a device for turning coffee into theorems, and a comathematician is a device for turning cotheorems into ffee.\n我们再来看看余核的泛性质。很容易就可以看到余核的交换图的右侧出现了我们熟悉的身影：商结构和商映射的泛性质。通过这个小块我们得以了解到，$\\Coker \\varphi$ 应该具有某种商结构，需要用 $H$ 商去它的一个正规子群。那么它具体应该商去谁呢？注意到两点：\n第一点是，商结构的特点决定了它要商掉的那个正规子群本身是可以作为陪集存在于商群中的。举个简单快速的例子，$A/B$ 这个商群里 $B$ 本身就是一个陪集，是用 $A$ 中单位元 $1_A$ 去陪 $B$ 得到；而这个特殊的陪集，由于用来左陪的元素是 $A$ 中单位元，它在商群 $A/B$ 中一定也是担任单位元的责任；\n另一个点则来自于 $G\\to X$ 必须是平凡映射这一要求。我们根据余核的泛性质，可以轻松地取这样的 $\\beta$，让它就等于 $\\pi$，这样一来 $\\overline{\\beta}$ 就变成了恒等映射，$X$ 也就变成了我们研究的 $\\Coker \\varphi$。那么，从群 $G$ 出发，在映射到 $\\Coker \\varphi$ 时必须到它的单位元上，那么从商映射的特点看，所有的 $G$ 中的元素都必须在经过 $\\varphi$ 映射后出现到 $\\Coker\\varphi$ 商去的那个正规子群里。而满足这样条件的东西只有一个，即 $\\Img \\varphi$，且还有一个要求，就是 $\\Img \\varphi$ 必须是正规的，这就要求 $H$ 是交换群，进而要求整个泛性质中的群都得是交换群。\n如此，我们又成功地从余核的泛性质的定义里拿到了我们熟悉的，用商群定义的那个余核。这也进一步指明了核与余核在范畴论意义下的对偶关系。然而，对于核以及余核而言，它们的定义还可以更加 fancy 一些：我们可以使用极限和余极限来定义核与余核，这里就不过多展开了，毕竟这篇文章不是讲范畴论的，而是为了证明蛇引理的来着（）\n准备证明吧 我们的手牌已经集齐了，现在等待着我们的就是要证明这个引理。这个引理涉及到的阿贝尔群很多，同态也很多。我们需要一步一步地朝着目标前进，否则这个大个家伙是没办法一次搞定的。\n证明思路 从最后的结果来看，我们有这样的几个问题是需要验证的：\n$f|$ 的定义是否合理 $g|$ 的定义是否合理 $\\hat{f'}$ 如何定义，是否良定 $\\hat{g'}$ 如何定义，是否良定 $\\delta$ 如何定义，是否良定 每个点处是否正合 若原交换图虚线箭头成立，得到的正合列是否对应虚线箭头也成立 我们不计划纠结于为什么核与余核在这里出现的如此频繁，只将之作为待证明的结论；也就是说，我们不考虑为什么选择了这样的构造，只考虑证明这个构造为什么是正确的。另外，我们可以发现第1点与第2点是很相似的，同样第3点与第4点也是很相似的。\n在正式开始进行验证之前，我们做一些符号上的约定，以免待会儿晕符号。如果是 $A$，$B$，$C$ 中的元素，我们就用对应的小写字母代表；如果是 $A'$，$B'$，$C'$ 中的元素，我们就在对应小写字母的上面也对应地加上这个 $\\prime$。如果需要从同一个群中取两个元素，为了区分它们，我们会再在右上角添加上 $*$ 来表示。如果是经过了同态/映射的作用，在需要时会加上其属于的群以做提示，而不再用 $\\prime$ 或者别的字母做记号，除非这样的记号是必须的。\n好了，我们开始正式的证明过程吧。\n验证 $f|$ 的定义，然后 $g|$ 我们第一个要验证的是 $f|$ 的定义，或者说仔细考虑怎么样去定义它。从图上可以看到，这个同态是 $f$ 在 $\\Ker \\alpha$ 上的限制，对它的定义的验证则是要验证 $f|$ 是否真的能把 $\\Ker \\alpha$ 映射入 $\\Ker \\beta$ 中，即验证 $\\Img f| \\subseteq \\Ker \\beta$。\n为了验证这件事，我们只需要任意取 $\\Ker \\alpha$ 中的元素，如果这些点在 $f|$ 的映射下都属于 $\\Ker \\beta$，就可以验证这样的包含关系了（这也是子集的定义）。既然如此，我们取 $\\Ker \\alpha$ 中的一个元素 $a$，根据核的性质，既然 $a$ 在 $\\alpha$ 的核内，我们知道 $\\alpha (a) = 0 \\in A'$，再根据同态的性质，群同态只能将单位元/零元映射到单位元/零元上，我们知道 $f' \\alpha (a) = 0 \\in B'$。由于交换图的性质，我们有：$\\beta f (a) = f' \\alpha (a) = 0$。请注意 $\\beta (f(a)) = 0$ 就意味着 $f(a)$ 这一点位于 $\\Ker \\beta$，即 $f(a) \\in \\Ker \\beta$，而这恰恰就是我们要证明的：任意一个 $\\Ker \\alpha$ 中的元素 $a$ 在经过 $f|$ 映射之后，都位于 $\\Ker \\beta$ 中。\n这里有一个点需要指出：为什么我们明明要验证的同态是 $f|$，最后却直接使用了 $f$ 的性质？这是因为：$f|$ 除了更改了定义域的范围之外，所有的信息都得以保留。由于我们任取的 $a$ 满足 $a\\in\\Ker \\alpha \\subseteq A$，所以 $f|$ 对在 $\\Ker\\alpha$ 中语境下的 $a$ 所产生的影响，和 $f$ 对 $A$ 中语境下的 $a$ 产生的影响是一模一样的。这保证了我们可以放心大胆地使用 $f$ 的性质。\n最后我们指出，这里的验证过程没有借助图表交换以及核的性质以外的任何要素，因此这套证明也可以直接照搬到下一个交换块，也就是关于 $g|$ 的定义的验证问题上。这里就不啰嗦了。\n验证 $\\hat{f'}$ 的定义，顺带 $\\hat{g'}$ 接下来要验证的就是 $\\hat{f'}$ 的定义了。我们要验证的东西其实和上面类似，也是 $\\Img \\hat{f'} \\subseteq \\Coker \\beta$。然而我们现在还不知道 $\\hat{f'}$ 具体是怎样的，只知道它的定义域是 $\\Coker \\alpha$。所以我们先来看看 $\\Coker \\alpha$ 里都有什么，再看看 $\\hat{f'}$ 是一个什么样的同态，最后来考虑验证上面所要求的定义。\n$\\operatorname{Coker} \\alpha$ 里是什么样的 由于 $\\Coker \\alpha = A' / \\Img \\alpha$，其中的每个元素都应该是 $\\Img \\alpha$ 这种形式的陪集。\n我们先考察一般的阿贝尔群（交换群）里某个同态的余核是什么样的。对于一般的阿贝尔群 $A$ 以及其上的某个同态 $f\\vcentcolon\\\\,A\\to B$ 而言，这里的等价关系是这样定义的：若 $a,a^* \\in A$ 且 $a - a^* \\in \\Img f$，则认为 $a \\sim a^* $，即 $a$ 与 $a^* $ 等价。这里的减号应该与 $a^* $ 一起理解为 $a^* $ 的逆元。这就形同 $a^{-1}a^* $ 在一般的乘法群中判定元素是否等价时一样。\n与此同时，其他的等价类（陪集），按照加法记号，也应该可以写作这样的形式：$a+\\Img \\alpha$。（假如你没有点开哪些小箭头的话）我们使用代表元的记号来记录这个陪集，即 $\\hat{a} = a+\\Img \\alpha$。我们在余核中定义的运算，则是借助余核所在的群的运算所定义的：直接将代表元按照原群中的运算进行，最后给它带上帽子（找到对应的等价类）。写成符号形式则是：假设有同态 $f: A\\to B$，则这个同态的余核为 $\\Coker f = A/\\Img f \\subseteq A$，再设余核这个群中有两个元素 $\\hat{a}$ 与 $\\hat{a^* }$，则余核中的运算为：$\\hat{a}+_\\mathrm{Coker}\\hat{a^* } = \\widehat{a+_A a^* }$。\n现在一切都明了了。对于我们所要研究的问题而言，$\\Coker \\alpha$ 中的元素，就是一个个等价类，这些等价类用原群的元素作为代表元进行标记，如 $\\hat{0}$, $\\hat{a'}$ 这样。而其运算直接继承自群 $A'$，具体而言，只需要将用来与子群作用的元素相运算，最后再作用回子群即可。\n$\\hat{f'}$ 是什么样的 从交换图上可以看到，$\\hat{f'}$ 是从 $\\Coker \\alpha$ 到 $\\Coker \\beta$ 上的。而在 $\\Coker \\alpha$ 中的元素则是众多的以代表元所代表的等价类。那么，在使用 $\\hat{f'}$ 作用到 $\\Coker \\alpha$ 中的一个元素 $\\hat{a'}$ 后，得到的则应该是位于 $\\Coker \\beta$ 中的一个元素，这个元素应该是形如 $b'+\\Img \\beta$ 这样的等价类，自然也可以被表示为 $\\hat{b'}$。这就是我们需要验证的同态，$\\hat{f'}$，具体在做的事。\n让我们写的更加明确一些：我们要定义的 $\\hat{f'}$ 应该是这样的：\n$$\\begin{align*} \\hat{f'}\\vcentcolon\\space \\Coker \\alpha \u0026 \\to \\Coker \\beta \\\\ a' + \\Img \\alpha \u0026 \\mapsto b' + \\Img \\beta, \\end{align*}$$其中 $a'\\in A'$ 与 $b' \\in B'$ 之间的关系有：$f'(a') = b'$。\n那么就有值得注意的一些问题。两个元素等价时，它们自然属于同一个等价类，但这两个元素本身是可以不同的。假如两个不同但等价的元素在进入等价类后再被商群间的同态所映射，应该会得到一个目标群上的等价类。另外，自然，我们也要验证这个同态的像确实在陪域内。我们开始验证吧。\n开始验证 我们取 $\\Coker \\alpha$ 中的一个元素 $\\hat{a}$，这个元素是一个等价类，等价关系由 $a' - a'^* \\in \\Img \\alpha \\hArr a' \\sim a'^* $ 给出。此时我们就取这个等价类中的这两个元素 $a',\\\\, a'^* \\in A'$。那么，此时这两个元素在经过 $f'$ 作用后得到的就是 $f' (a')$ 以及 $f'(a'^* )$。这两个 $B'$ 中的元素应该依旧会被映射到同一个等价类中，也就是两个元素等价。判断两元素等价的条件则类似于前面的判断条件：$f' (a') - f'(a'^* ) \\in \\Img \\beta$。我们可以看到：由于 $f'$ 是一个同态，同态是保运算的，则 $f' (a') - f'(a'^* ) = f'(a' - a'^* )$。注意到 $a' - a'^* \\in \\Img \\alpha$，由像的性质，我们就一定可以找到一个存在于 $A$ 中的一个元素 $a$，使得 $\\alpha(a) = a' - a'^* $。\n我们理一下思路：我们先选取了两个在 $A'$ 中等价的元素；这两个元素的差，根据等价类划分的规则，必须是属于 $\\alpha$ 的像的，那么就一定有一个对应的 $A$ 中的元素 $a$ 在 $\\alpha$ 的作用下等于这两个 $A'$ 中元素的差。那么这时，我们就可以使用图表交换的性质了：$f'(\\alpha(a)) = \\beta(f(a))$。请注意这个地方：右侧显示 $\\beta(f(a))$ 是属于 $\\beta$ 的像的：$\\beta(f(a)) \\in \\Img \\beta$。这就说明了 $f'(\\alpha(a)) = f'(a' - a'^* ) \\in \\Img \\beta$。这样，我们就得到了我们所需要的：任取两个 $A'$ 中的等价元素，它们最终被映入了 $B'$ 的等价类，因为 $f' (a') - f'(a'^* ) \\in \\Img \\beta$。\n那么这样我们就可以进一步进入到对 $\\hat{f'}$ 的验证：如果 $a'\\in A'$ 且 $a'^* \\in A'$ 且二者等价，就有 $a' + \\Img \\alpha = a'^* + \\Img \\alpha$。我们希望这两个应该相等的等价类在经过 $\\hat{f'}$ 的映射后得到的是同一个 $\\Coker \\beta$ 中的元素。那我们就直接进行运算：\n$$\\begin{align*} \\hat{f'}(a' + \\Img \\alpha) \u0026= f'(a') + \\Img \\beta\\\\ \u0026= f' (a'^* +a'-a'^* ) + \\Img \\beta\\\\ \u0026= f' (a'^* ) + f'(a'-a'^* ) + \\Img \\beta \\\\ \u0026= f' (a'^* )+ \\Img \\beta\\\\ \u0026= \\hat{f'}(a'^* + \\Img \\alpha). \\end{align*}$$我们来解释一下上面的运算过程。第一步是使用了我们上面对函数做出的定义；第二步就是单纯地进行了个加减，不过这里的加减能成立必须利用交换群的性质；第三步则是利用了 $f'$ 作为阿贝尔群同态的定义；第四步则要应用到我们刚刚得到的结论： $f' (a') - f'(a'^* ) \\in \\Img \\beta$；第五步则就是单纯运算回以 $\\hat{f'}$ 表达的形式，完成我们的证明。\n自此，我们证明了：两个任意的 $A'$ 中元素，当它们等价时，会且总是会被 $\\hat{f'}$ 映射到同一个 $\\Img \\beta$ 中的元素。这句话还可以换个说法：我们定义的这个同态，是不依赖于等价类代表元的选取的（我们选了两个代表元，结果一样）；或者简单一些：这个同态是良定的。\n我们完全可以按照相似的逻辑处理 $\\hat{g'}$。这得益于我们上面的定义以及验证没有用到除了交换图提供的信息外的任何额外附加信息。所以我们就不特别定义并验证这个 $\\hat{g'}$ 了，直接借用这里的定义以及验证方法即可。\n如何验证一个同态是良定的 在代数学中，我们常常会尝试给某个数学对象附上一个同态，或者给两个数学对象之间定义同态。然而，这样的过程并不总是顺利的：可能我们定义的东西到实际验证时是有问题的。就我个人的观点而言，这些问题包括但不限于：\n定义域上同一个元素被映射到了不同的陪域中的元素（违反映射的定义）； 不保持对象间的结构（不保运算，不保连续等）； 定义域不对，超出或小于定义域； 超过了陪域的范围， 等等。而我们所说的验证一个同态是良定的，实际上就是在尝试验证上面的这些问题都不会出现。一般而言，后两个问题都不太容易出现，一般的验证过程都是在验证前两个问题是否存在。\n我们先看第一个，这个的验证方法非常地朴实无华，即通过验证两个定义域上相等的元素，它们在经过同态作用之后是否依旧相等。如果是保持相等的，则证明一个元素不会被映射到两个不同的元素上，从而完成第一个问题的验证。这里要提到的是，对于商群这样，元素是陪集这样集合的情况，还有必要验证一个陪集内的元素是否能被从商群出发的同态映射到定义域上的同一个元素中。不过这一点也可以归结为对第二个问题的验证，即同态是否能够保持对象间的结构。\n针对商群这样的结构，如果一个陪集内的元素被映射到了不同的定义域上的元素，那么就证明这样的映射并不能保持商群的元素，即陪集，内部所有元素等价的条件。除了这样的结构性质外，另一个常见的结构即定义好的代数运算，或者说是同态区别于函数的性质。我们也可以说，先对元素做运算再通过同态映射，其结果应该等同于先做完同态的映射，再在陪域内进行运算。这也许可以被称为同态和运算之间的 “交换性”。\n虽然第三和第四个问题一般不会出现，但是在从零开始构造一个同态时，对它们的验证依旧是有必要的。特别是第四条，即对于陪域的验证，我们要求同态的像必须是陪域的子集，否则这个映射就不是良定义的。从上面的一系列验证过程中，我们也能够看到对于这一条件的验证。\n$\\delta$ 的定义与验证 这个 $\\delta$ 的定义算是证明蛇引理过程中的一个难点吧，这也是蛇引理的关键一步，也是 “蛇” 这个字的由来吧。我们应该如何从一个核映射到余核呢？从交换图上来看，是需要从 $C$ 中的子集映射到 $A'$ 上的等价类的。这应该如何是好呢？\n$\\delta$ 应该是什么样的 好消息是：我们对同态 $g$ 以及 $f'$ 是有一些说法的：$g$ 一定是满态，而 $f'$ 则一定是单态。这是根据这两个正合列的性质，或者说是正合列中 $C$ 点与 $A'$ 点的性质而得到的。我们前面也有提到这个结论，这里简单说明一下：由于 $C$ 映射到平凡群的同态一定是一个满态，这个满态的核就一定是 $C$ 本身；由于正合的要求，$g$ 的像就必须是 $C$ 了，也就是 $g$ 是满的；由于 $0$ 到 $A'$ 作为同态必须也只能映射到 $A'$ 中的单位元，所以这个映射的像就只能是那个单位元自己形成的平凡群；由于正合列的性质，$f'$ 的核则只能是这个平凡群，也就是说它是一个单态。\n这两个信息对于 $\\delta$ 的构造是必须的，否则我们没有一个很好的从 $C$ 一路走回 $A'$ 的方法。当然，有了上面的提示，我们很自然想到，这个 $\\delta$ 的构造应该是什么样的。它会从 $C$ 出发，从 $g$ 反着走到 $B$ 点，在经过 $\\beta$ 的映射之后，再通过 $f'$ 反过来到 $A'$ 上。我们来更细致地考察这个映射构造过程的每一步吧。\n$\\delta$ 的具体构造 我们的 $\\delta$ 是从 $\\Ker \\gamma$ 开始的，自然我们就取 $C$ 中的子集 $\\Ker \\gamma$ 里的一个元素 $c$。得益于满态的性质，我们一定是可以在 $B$ 中找到某个元素 $b$，使得 $g(b) = c$ 的。\n注意到我们对 $c$ 的选取，这个 $c$ 是在 $\\Ker \\gamma$ 内的，所以就会有： $\\gamma(g(b)) = 0$。再根据图的交换性，我们就有了 $g'(\\beta(b)) = \\gamma(g(b)) = 0$，也就是说 $\\beta(b) \\in \\Ker g'$。\n这时我们要根据正合列的性质来继续向 $A'$ 推进。由于正合性，我们有 $\\Img f' = \\Ker g'$，因此 $\\beta(b) \\in \\Img f'$，而既然 $\\beta(b)$ 出现在了 $f'$ 的像中，就一定会有一个 $A'$ 中的元素，我们记作 $a'$，一定会在 $f'$ 映射后到我们之前拿到的 $\\beta(b)$ 上。\n最后，由于 $f'$ 是单态，上面说的那个 $a'$ 在此时是唯一确定的。而这个唯一确定的元素在 $A'$ 对应的商群 $\\Coker \\alpha$ 中自然也是属于唯一的一个等价类的。\n我们现在回溯一下这个过程：我们取了 $\\Ker \\gamma$ 中的一个元素 $c$，它一定对应了某个 $B$ 中的 $b$。但要注意的是，因为仅有 $g$ 是满态的要求，这个 $b$ 可能不唯一。接着我们从这个 $b$ 自然地得到了 $\\beta(b)$，而它则有 $A'$ 中存在且唯一的对应元素 $a'$。这个元素，很自然地，在 $\\Coker \\alpha$ 中就有了唯一的等价类。总结下来就是：每个 $\\Ker \\gamma$ 中的元素经过我们上面的映射过程，都是可以得到 $\\Coker \\alpha$ 中的等价类的。\n然而这给了我们一个亟待解决的问题：这个映射链最后是需要组合成一个同态 $\\delta\\vcentcolon\\\\,\\Ker \\gamma \\to \\Coker \\gamma$ 的，而作为一个同态，每个定义域上的元素能且只能对应到陪域上的唯一一个元素。然而从我们刚刚的映射链过程来看，由于 $c$ 在 $B$ 中对应的元素个数是不确定的，虽然每个 $b$ 中元素都能对应到唯一的 $A'$ 中的等价类，但可能所有满足 $g(b) = c$ 的 $b$ 所能对应的 $A'$ 的等价类是不一样的。用更形式化的语言来讲，我们现在要解决，或者要证明的问题就是：\n设存在两个 $B$ 中的元素 $b,\\\\,b^* $，满足 $g(b) = g(b^* )$，求证这两个元素在经过映射链 $\\beta$ 与 $f'$ 的反向作用（我们以后就记这个反向作用为 $(f')^{-1}$ 了，这个记号是合理的，我们后面会提到） 后得到的元素在 $A'$ 中是等价的，其中等价关系由 $a' - a'^* \\in \\Img \\alpha$ 给出。\n如果这个命题得到了验证，那么就说明这条路走得通，一个唯一的 $\\Ker \\gamma$ 中的 $c$，不论它在 $B$ 中对应有多少个元素，最后都会在 $A'$ 里对应到同一个等价类里，也就是在 $\\Coker \\alpha = A'/\\Img \\alpha$ 中有唯一的一个元素与之对应。这样就验证了 $\\delta$ 的定义。\n$\\delta$ 构造的验证 我们开始上面这个命题的证明吧。这里需要注意的第一个问题，同时也是指明了我们应该朝着哪个方向前进的信息，是：我们最后要得到的内容是和 $\\Img \\alpha$ 有关的。为此，我们一定是要用到 $\\alpha$ 这个映射的相关信息的，而这也不可避免地涉及到 $A$ 这个群。因此，我们得想办法先把 $g(b) = g(b^* )$ 这个信息反映到 $A$ 这个群内。\n好消息是，通过同态的性质，我们很容易就可以得到：$g(b-b^* ) = 0$，也就是说 $b-b^* \\in \\Ker g$。我们故技重施，得到 $b-b^* \\in \\Img f$，这让我们可以讨论已有的 $g(b)$，$g(b^* )$ 与 $A$ 中的元素的关系，即我们一定可以找到至少一个 $A$ 中的元素 $a$，使得 $f(a) = b-b^* $。\n我们通过图的交换性可以得知，$\\beta f (a) = \\beta (b-b^* ) = f'\\alpha(a)$。这时我们需要用到关于单态的一个性质。这个性质我们之前也提过，甚至这是关于单态的定义：具有左逆的态射为单态。如此一来，我们给第二个等号的左右两边同时作用上 $f'$ 的左逆。注意到左逆的定义，我们就有了：\n$$(f')^{-1} \\beta (b-b^* ) = (f')^{-1} f'\\alpha(a) = \\alpha(a)$$回忆我们之前所提到的，$(f')^{-1}$ 由于 $f'$ 是单态，所以能唯一地确定 $B'$ 中元素在 $A'$ 中所对应的元素；$\\beta$ 本身就是一个良定的同态，因此，以上这些就说明了这样一个事实：$(f')^{-1} \\beta$ 是一个良定的从 $B$ 到 $A'$ 的同态，且 $(f')^{-1} \\beta (b-b^* )$ 作为 $A'$ 的元素，它同时也是位于 $\\Img \\alpha$ 的。\n那么此时我们再使用 $(f')^{-1} \\beta$ 作为同态的性质，有：\n$$(f')^{-1} \\beta (b-b^* ) = (f')^{-1} \\beta (b)-(f')^{-1} \\beta(b^* ) \\in \\Img \\alpha$$至此，我们对上面进行总结：设有两个 $B$ 中的元素 $b$ 与 $b^* $，它们满足 $g(b) = g(b^* )$，则我们可以在 $A'$ 中找到这样对应的两个元素 $(f')^{-1} \\beta (b)$ 和 $(f')^{-1} \\beta (b^* )$，使得这两个元素在我们已经定义好的等价关系下是等价的。\n如此，我们的这个命题得证。进而，我们就成功地构造出了良定的 $\\delta$：\n$$ \\begin{align*} \\delta\\vcentcolon\\space\\Ker\\gamma\u0026\\to\\Coker\\alpha\\\\ c\u0026\\mapsto (f')^{-1} \\beta (b) + \\Img\\alpha, \\end{align*} $$其中，$c \\in \\Ker \\gamma$ 且 $c = g(b)$。\n一些旁注 我们可以看到，为了构造 $\\delta$，我们必须利用 $g$ 的满态性质以及 $f'$ 的单态性质，还需要利用交换图右侧部分的交换性。而在验证其定义的过程中，我们同样必须利用 $g$ 的满态性质以及 $f'$ 的单态性质（这里 $g$ 的满态性是直接作为命题的前置条件而存在的），然后还需要利用交换图左侧部分的交换性。$\\delta$ 的构造充分利用了我们已有的所有条件，因此算是这个引理证明比较困难的一部分，同时也是关键的部分。而关于前面 $f|$，$\\hat{f'}$ 的构造与验证过程中，都只用到了图的交换性，并没有利用 $g$ 是满态以及 $f'$ 是单态的条件。\n我们再来关注 $\\delta$ 的构造过程。我们从 $\\Ker \\gamma$ 中选择了任意的元素 $c$，它在 $g$ 的诸多原像 $b$ 们由于交换图的交换性质，在经过 $\\beta$ 的映射到达 $B'$ 后都是位于 $\\Img f'$ 上的。由于都在 $\\Img f'$ 上，讨论 $(f')^{-1}$ 自然也是有意义的。\n另外我们结合后面对该定义的验证过程，可以看到这个元素 $c$ 是怎么一步步抵达 $\\Coker \\alpha$ 的：这个元素 $c$ 在 $B$ 中的原像可能包含一个或者多个元素，这些元素经过 $\\beta$ 映射后都存在于 $\\Img f'$ 中，这个过程里可能有些元素映射到了 $B'$ 里的同一个元素上，也有可能并不是这样，不过这里没有关系。接着它们在单射 $(f')^{-1}$ 的影响下，各不相同地映射到 $A'$ 上，最后分类到同一个等价类中（纯符号地讲，其实就是加上了 $\\Img \\alpha$）。\n验证过程说明了，只要都是在 $c\\in\\Ker\\gamma$ 的原像里，注定都是会被分到同一个 $\\Coker\\alpha$ 的等价类里面的。然而，这个分类过程其实是在最后，在得到 $(f')^{-1}\\beta(b)$ 后才完成的。好在，由于左侧块的交换性，在从 $c$ 找 $B$ 中原像的过程中，所有符合条件的 $b$ 之间的等价关系（指最终分类到同一 $\\Coker \\alpha$ 的元素中）早已被确定好了。\n这里再重申一下单态和满态的性质。单态意味着若陪域中的元素的原像要么非空，要么则只有一个元素，同时单态拥有唯一的左逆；满态则意味着陪域中的所有元素的原像都不是空集。我们利用满态原像的性质得出，$\\Ker \\gamma$ 中的元素一定可以在 $B$ 中找到对应元素，而又通过单态的性质得出，在已知 $\\beta(b)$ 存在于 $f'^* $ 的条件下，$A'$ 中有且只有唯一一个元素与之对应，且通过给 $\\beta (b-b^* )$ 作用左逆得出它存在于 $\\alpha$ 的像内。\n$\\operatorname{Ker} \\beta$ 处正合性的证明 前面我们证明了我们要验证的点的 1-5，借此我们成功地将这些核呀余核呀之类的连起来了。然而，要成为正合列，它需要在中间的每个点上都是正合的。现在已经到手的链条是这样的：\n$$\\Ker \\alpha \\xrightarrow{f|} \\Ker \\beta \\xrightarrow{g|} \\Ker \\gamma \\xrightarrow{\\delta}\\Coker \\alpha \\xrightarrow{\\hat{f'}}\\Coker \\beta\\xrightarrow{\\hat{g'}} \\Coker \\gamma $$这条链条的中间一共有 $\\Ker\\beta$，$\\Ker\\gamma$，$\\Coker\\alpha$，$\\Coker\\beta$ 四个点，我们需要分别验证它们两边的态射在它们自身处都是正合的。鉴于 $\\delta$ 所连接的 $\\Ker\\gamma$，$\\Coker\\alpha$ 处的正合性会比较复杂（由于 $\\delta$ 比较复杂），我们先验证 $\\Ker \\beta$ 处的正合性，再验证 $\\Coker \\beta$ 的，最后到剩下的两个。\n为了验证正合性，我们需要验证：$\\Img f| = \\Ker g|$。由于链条上的都是态射，这个等号只需要集合意义上的成立即可在阿贝尔群意义上同样成立，而证明两个集合相等最常用的方法之一便是验证相互包含：$\\Img f| \\subseteq \\Ker g|$ 且 $\\Img f| \\supseteq \\Ker g|$，而为了实现这样的目的，我们会从待验证命题中较小的集合中取点，证明它一定在较大的那个集合中，即可验证这样的子集关系了。\n在我们开始之前，我们把 $\\Ker \\beta$ 所在短链条写出来，方便后面观察：\n$$ \\Ker \\alpha \\xrightarrow{f|} \\Ker \\beta \\xrightarrow{g|} \\Ker \\gamma $$那我们就开始吧，先从 $\\Img f| \\subseteq \\Ker g|$ 开始。\n证明 $\\operatorname{Im} f| \\subseteq \\operatorname{Ker} g|$ 我们就取 $\\Img f|$ 中的一个元素 $b$，根据像的性质，一定有一个 $a\\in \\Ker\\alpha$ 满足 $f|(a) = b$。而 $f|(a)$ 实际上就是 $f$ 在 $\\Ker \\alpha$ 上的一个限制，所以也就有 $f(a) = b$；同时，我们取 $g|(b) = c$，由于 $g|$ 也是 $g$ 在 $\\Ker\\beta$ 上的限制，所以 $g|(b) = g|(f(a)) = g(b) = g(f(a)) = c$。此时，我们考虑原正合列：\n$$A\\xrightarrow{f} B \\xrightarrow{g} C,$$ 我们得到：$f(g(a)) = 0$。由此就得到了 $c = 0$。由于这个结论不依赖于 $b$ 的选取方式，我们就以这种方式得到了 $g|(b) = c = 0$ 恒成立，进而 $b \\in \\Ker g|$。而这，正说明了这样一件事：如果一个 $\\Ker \\beta$ 中的元素 $b$ 在 $\\Img f|$ 里，那么它就一定在 $\\Ker g|$ 中。这就证明了 $\\operatorname{Im} f| \\subseteq \\operatorname{Ker} g|$。\n这个命题的得证完全依赖与原正合列的性质，且通过证明该命题，我们得知上面的短链条已经是一个链复型了。下面我们需要证明的就是另一个方向的包含性，也就是：\n证明 $\\operatorname{Im} f| \\supseteq \\operatorname{Ker} g|$ 我们故伎重施，取 $\\Ker g|$ 中的一个元素，也叫它 $b$ 好了。既然它在 $g|$ 的核中，那么就有 $g|(b) = 0$，我们此时把 $b$ 放到 $B$ 集合中，此时 $g|(b) = g(b) =0$，说明 $b\\in\\Ker g$。而根据原链条的正合性，我们有 $\\Ker g = \\Img f$，因此 $b\\in\\Img f$。\n然而到此依然不能证明 $b\\in\\Img f|$，因为 $\\Img f|$ 是 $\\Img f$ 的子集，无法从一个元素位于更大的集合中来判定它一定在更小的集合里。我们需要更多的信息。然而既然 $b\\in\\Img f$，我们就可以找到 $A$ 中的一个元素 $a$，使得 $f(a) = b$。又因为根据 $b$ 的取法，它在 $g|$ 的定义域 $\\Ker \\beta$ 上，一定就有 $\\beta(b) = \\beta(f(a)) = 0$。此时，我们根据交换图的性质，可以得到 $f'(\\alpha(a)) = \\beta(f(a)) = 0$。\n这样的结果有什么用处呢？回忆 $f'$ 的性质，它是一个单态，因此就一定有左逆 $(f')^{-1}$。我们给上式的左右两边同时左乘（左作用）上 $(f')^{-1}$，就得到：$(f')^{-1}f'(\\alpha(a)) = (f')^{-1}(0) = 0 = \\alpha(a)$。观察最后一个等号，这又说明了 $a \\in \\Ker \\alpha$。\n我们整理一下当前得到的信息，我们有 $\\Ker g|$ 中的一个元素 $b$，它在 $A$ 中有一个对应的元素 $a$，我们又得到了这个元素 $a\\in\\Ker\\alpha$。请注意 $f|$ 的定义域正是 $\\Ker\\alpha$。这就说明了：$b$ 在 $A$ 中对应的元素一定也在 $\\Ker\\alpha$ 里，也就是 $b\\in\\Img f|$。同样，由于 $b$ 的选取不依赖于任何的额外条件，我们就证明了 $\\operatorname{Im} f| \\supseteq \\operatorname{Ker} g|$。至此，联合上一小节的结论，我们得出结论：该短链在 $\\Ker\\beta$ 处正合。\n一点注解 可以看到，前半部分的证明非常简单，直接借助原正合列性质即可，这样直接就证明了这个链条是一个链复型；而后面为了证明正合性的部分则需要使用到 $f'$ 是单态的条件。也许我们在证明 $\\Coker \\beta$ 处的正合性时，也会遇到这样的特点？我们直接开始吧。\n$\\operatorname{Coker} \\beta$ 处正合性的证明 和上面一样，我们证明这样的正合性，会以对应映射的像与核相互包含为切入点进行。这次我们还是先证明这个短链：\n$$ \\Coker \\alpha \\xrightarrow{\\hat{f'}} \\Coker \\beta \\xrightarrow{\\hat{g'}} \\Coker \\gamma $$是一个链复型（$\\Img \\hat{f'} \\subseteq \\Ker \\hat{g'}$），再证明在中间的 $\\Coker \\beta$ 处是正合的（$\\Img \\hat{f'} \\supseteq \\Ker \\hat{g'}$）。\n证明 $\\operatorname{Im} \\hat{f'} \\subseteq \\operatorname{Ker} \\hat{g'}$ 照旧我们选择 $\\Img \\hat{f'}$ 中的一个元素，由于 $\\Img \\hat{f'} \\subseteq \\Coker \\beta$，这个元素将会是等价类 $\\hat{b'} = b' + \\Img \\beta$。我们想要证明，在前面这个条件下的任何 $\\hat{b'}$ 都会被 $\\hat{g'}$ 映射到 $\\hat{0} \\in \\Coker \\gamma$ 上。既然 $\\hat{b'}\\in\\Img\\hat{f'}$，我们就可以取到 $\\Coker \\alpha$ 中的一个元素 $\\hat{a'}$，使得 $\\hat{f'}(\\hat{a'}) = \\hat{b'}$。\n此时，请回忆我们是如何定义 $\\hat{f'}$ 的：我们直接借助了原有的同态 $f'$，使得具有了这样的性质：\n$$\\hat{f'}(\\hat{a'}) = \\hat{f'}(a'+\\Img \\alpha) = f'(a') + \\Img \\beta = b'+\\Img \\beta = \\hat{b'} = \\widehat{f'(a)}.$$带着这条性质，我们观察到：若是对 $\\hat{b'}$ 作用上 $\\hat{g'}$，就有：\n$$\\hat{g'}(\\hat{b'}) = \\hat{g'}(\\hat{f'}(\\hat{a'})) = \\hat{g'}(\\widehat{f'(a')}) = \\widehat{g'(f'(a'))} = \\hat{0},$$其中，第一个等式是我们一开始取到的 $\\hat{f'}(\\hat{a'}) = \\hat{b'}$，第二个等式是利用了我们上面给出的 $\\hat{f'}$ 的性质，而第三个等式则是同样，再次利用 $\\hat{g'}$ 它与 $\\hat{f'}$ 同样的性质（因为定义是类似的）。最后，第四个等式则利用了原正合列的性质，有 $g'(f'(a')) = 0$。由此，我们再一次地，像上面证明 $\\Ker \\beta$ 处正合的第一部分一样，证明了 $\\Coker \\beta$ 处正合的第一部分：无论 $\\hat{b}$ 如何取，只要它位于 $\\Img \\hat{f'}$ 中，就一定位于 $\\Ker \\hat{g'}$ 中。\n证明 $\\operatorname{Im} \\hat{f'} \\supseteq \\operatorname{Ker} \\hat{g'}$ 下来我们就证明 $\\Coker \\beta$ 处正合的第二部分。我们希望能从 $\\Ker \\hat{g'}$ 中取到的元素能够以某种方式放到 $B'$ 中去，然后借助原正合列的性质去取得在 $A'$ 中或者 $\\Coker \\alpha$ 中的一些结论。 因此依旧，我们取 $\\hat{b'} \\in \\Ker \\hat{g'} \\subseteq \\Coker \\beta$。由于 $\\hat{b'}$ 在 $\\hat{g'}$ 的核中，我们有 $\\hat{g'}(\\hat{b'}) = \\hat{0}$。我们把这个运算拆开，有\n$$\\begin{align*} \\hat{g'}(\\hat{b'}) \u0026= \\hat{g'}(b' + \\Img \\beta) \\\\ \u0026= g'(b') + \\Img \\gamma\\\\ \u0026= \\hat{0} = \\Img \\gamma, \\end{align*}$$ 由此可以得知，$g'(b') \\in \\Img \\gamma$。然而，这和我们之前所做到的并不一样：$g'(b')$ 只是位于 $\\Img \\gamma$ 中，它并不等于 $0$。不过，我们依旧可以借助这个条件。\n从 $g'(b') \\in \\Img \\gamma$ 条件中可以得知，一定有一个 $c \\in C$ 使得 $\\gamma(c) = g'(b')$。而此时，又由于 $g$ 是满射，我们知道一定有一个 $b \\in B$ 使得 $g(b) = c$。把它们组合起来，就有了： $\\gamma(g(b)) = g'(b')$，此时根据交换图的性质，就有了 $g'(b') = \\gamma(c) = g'(\\beta(b))$。我们现在把最右边这项移项到最左边，就有了 $g'(b'-\\beta(b)) = 0$。\n通过上面的方式，我们成功构造出了一个位于 $g'$ 的核中的元素。因此，直接借助短链\n$$A'\\xrightarrow{f'} B' \\xrightarrow{g'} C'$$是正合的这一条件，就有：$b'-\\beta(b) \\in \\Ker g' = \\Img f'$。\n我们现在再看看这个新构造出的，位于 $\\Img f'$ 中的这个元素的等价类是什么样的。我们把 $\\hat{b'}$ 写成 $b' + \\Img \\beta$ 的形式，此时又由于 $\\beta(b)$ 自然就在 $\\Img \\beta$ 中： $\\beta(b) \\in \\Img \\beta$，我们就有 $b'+\\Img \\beta = b' - \\beta(b) + \\Img \\beta$。这意味这我们新构造出的这个更好的元素，它与我们一开始选择的 $b'$ 是等价的，都可以作为 $\\hat{b'}$ 的代表元。\n现在我们现在想知道的是，对于等价类 $\\hat{b'} = b'-\\beta(b) + \\Img \\beta$，是否一定存在 $\\Coker \\alpha$ 中的某个等价类，使得它在 $\\hat{f'}$ 的作用下就是我们已有的 $\\hat{b'}$。为此，我们回到刚刚构造出的，位于 $\\Img f'$ 中的这个元素 $b'-\\beta(b)$。既然在 $f'$ 的像内，就一定有一个或者几个元素 $a' $ 满足 $f'(a' ) = b'-\\beta(b)$。我们知道，$a'$ 在 $A'$ 中的等价类是 $\\hat{a'} = a'+\\Img \\alpha$。而该等价类经过 $\\hat{f'}$ 的作用后得到的结果是：\n$$ \\hat{f'}(a'+\\Img\\alpha) = f'(a') + \\Img\\beta = b'-\\beta(b) + \\Img\\beta = b'+\\Img\\beta. $$好，我们现在总结我们已有的信息。我们从一个任意的 $\\Coker \\beta$ 中的元素 $\\hat{b'}$ 出发，构建出了一个位于 $\\Ker g'$ 中的元素 $b'-\\beta(b)$，其中 $b$ 是直接根据 $b'$ 确定的。这个新的元素所处的等价类就是我们之前挑选的等价类。另外，我们从构造的元素出发，得到了若干个位于 $A'$ 中的元素 $a'$。它所在的等价类则是 $\\hat{a'}\\in\\Coker \\alpha$。现在，我们可以注意到：我们只挑出来了一个 $\\hat{b'}$，剩下的所有的东西都是由它以及它相关的量决定的。也就是说，$\\hat{b'}$ 决定了这些 $\\hat{a'}$。而经过上面式子的验证，有 $\\hat{f'}(\\hat{a'}) = \\hat{b'}$。这就说明了：任取一个位于 $\\hat{g'}$ 的核内的元素，我们都能确定出一些 $\\hat{a'}$，它们全都是满足 $\\hat{f'}(\\hat{a'}) = \\hat{b'}$ 的。\n这就证明了我们想要的结论：任意一个 $\\hat{g'}$ 的核内的元素都是 $\\Coker \\alpha$ 中元素的像，也就是 $\\operatorname{Im} \\hat{f'} \\supseteq \\operatorname{Ker} \\hat{g'}$。再结合上一节证明的内容，我们就证明了这个链条在 $\\operatorname{Coker} \\beta$ 处是正合的。\nCallback 可以看到，对于 $\\operatorname{Coker} \\beta$ 处正合性的证明，是和 $\\operatorname{Ker} \\beta$ 处正合性的证明很类似的。不过我个人感觉，后面证明的这个，相比于 $\\operatorname{Ker} \\beta$ 处正合性的证明是要难一些的。这可能是因为需要手动构造一个 $b'-\\beta(b)$ 来满足应用正合性的条件，以及对余核的性质的不熟悉吧。总之，顺利地证明了。而下面要证明的，就和我们自己构造出的 $\\delta$ 相关了。\n$\\operatorname{Ker} \\gamma$ 处正合性的证明 接下来我们尝试证明短链\n$$\\Ker\\beta\\xrightarrow{g|}\\Ker\\gamma\\xrightarrow{\\delta}\\Coker\\alpha $$在中间一点处的正合性。我们依旧采取原来的策略。\n证明 $\\operatorname{Im} g| \\subseteq \\operatorname{Ker} \\delta$ 照旧取一个 $\\Img g|$ 中的元素 $c\\in C$，我们希望能证明 $\\delta(c) = \\hat{0}$ 恒成立，这样一来自然就有 $\\Img g| \\subseteq \\Ker \\delta$ 了。\n既然 $c\\in\\Img g|$，就会有一个元素 $b\\in \\Ker\\beta$ 使得 $g|(b) = c$。又由于这个 $b$ 是在 $\\beta$ 的核中的，因此 $\\beta(b) = 0$。此时我们再作用上 $(f')^{-1}$，由于 $f'$ 是单态，所以把 $0\\in B'$ 作用上它的左逆只能得到唯一的元素 $0\\in A'$，而这对应的 $\\Coker \\alpha$ 中作为元素等价类正是 $\\hat{0}$。\n注意到我们上面的步骤，实际上就是在对 $c$ 作用 $\\delta$。因此，我们得到了我们想要的结论：$\\delta(c) = \\hat{0} \\in \\Coker \\alpha$，也就证明了本命题。\n证明 $\\operatorname{Im} g| \\supseteq \\operatorname{Ker} \\delta$ 我们还是取 $c\\in \\Ker \\delta$。因此，$\\delta(c) = \\hat{0} = 0 + \\Img \\alpha$。我们回顾 $\\delta$ 的构造，或者说从 $c\\in\\Ker\\gamma$ 出发抵达 $\\Coker \\alpha$ 的过程，如果 $\\delta(c) = \\Img \\alpha$，那么 $c$ 就一定会经理这样的过程：它首先在 $B$ 中找到原像中的元素 $b$ 们，然后把这些元素打包被 $\\beta$ 映射到 $B'$ 上，此时由于我们的构造，所有的 $\\beta(b) \\in \\Img f'$。此时就一定有许多对应的 $a' \\in A'$ 满足 $f'(a') = \\beta(b)$。最后由于 $\\delta(c) = \\hat{0} = \\Img \\alpha$，必须要有 $a' \\in \\Img\\alpha$ （注意，不是 $a' = 0$，因为只需属于 $\\Img \\alpha$ 即可满足条件）。\n经过上面的过程，我们得到了这样和原条件等价的条件，即必须至少有一个 $a'\\in\\Img\\alpha$，它由 $f'(a') = \\beta(b)$ 确定，而 $\\beta(b)$ 中的 $b$ 则从 $c$ 的原像中找到。\n因此，我们先关注这个集众多条件于一身的 $a'$，由于其处在 $\\alpha$ 的像内，就一定有 $a\\in A$ 使得 $\\alpha(a) = a'$。此时我们从 $a$ 出发，利用交换图的性质，就有 $f'(\\alpha(a)) = \\beta(f(a))$。注意到我们 $a'$ 上的两个条件，将它们带入这个关系，就得到 $f'(\\alpha(a)) = f'(a') = \\beta(b) = \\beta(f(a))$。\n我们关注最后一个等号，它说明了这样的问题：$\\beta(b) = \\beta(f(a))$，则有 $\\beta(b-f(a)) = 0$，也就是 $b-f(a)$ 是属于 $\\Ker \\beta$ 的。回顾这个元素的构造过程，$b$ 是任意一个在 $c$ 的原像中的元素，这里的 $a$ 是根据 $a'$ 任意选取的在原像内的元素，$a'$ 又是 $\\beta(b)$ 在其原像内任意选取的元素。我们看到，$b$ 和 $a$ 都是除了利用 $c\\in\\Ker\\gamma$ 和交换图性质以外任意选取的符合条件的元素，如果对它作用 $g|$ 之后能够回到 $c$，就说明这样的一件事：$c$ 的原像内元素不管怎么选，总会以某些形式回到 $\\Ker\\beta$，进而映射到 $g|$ 的原像内。\n幸运的是，这很好验证：$g|(b-f(a)) = g(b-f(a)) = g(b) - g(f(a)) = g(b) = c$。第一个等号来自 $g|$ 的定义，当将之放入 $B$ 中考虑是就可以使用 $g$ 替代；第二个等号来自 $g$ 是同态的保运算性质；第三个等号来自链复型的要求；而最后一个等号就是我们一开始选取 $b$ 的方式。这正是说明了我们前面讲的：$c$ 原像中的 $b$，会以 $b-f(a)$（其中 $a$ 也是由 $c$ 间接决定的）的形式出现在 $\\Ker\\beta$ 里，最后被 $g|$ 映射回 $c$，而这就证明了任何一个 $\\Ker\\gamma$ 中的元素，其都是 $\\Img g|$ 中的元素，也就证明了本命题。再结合上一条命题的证明，我们成功得到了这条链条在 $\\Ker\\gamma$ 上的正合性。\n一点绕过的弯路 第二个命题的证明其实没有特别顺利。这主要是因为对 $\\delta$ 构造的理解不够导致的，或者说太过希望 $\\delta$ 有一个好的显式表达而造成的。在取到 $a' = \\alpha(a)$ 的时候，我希望直接得到 $b$ 是一定属于 $\\Ker\\beta$ 的结论，虽然感觉上会有和之前类似的从 $b$ 出发构造的属于 $\\Ker\\beta$ 的元素一样的桥段，但由于依赖 $\\delta$ 的显示表达，我卡在了 $(f')^{-1}$ 只是左逆而非右逆这一点上。因为如果按照我之前的思路，就一定要遇到 $f'((f')^{-1}(\\beta(b)))$ 这样的元素。而由于 $(f')^{-1}$ 并非右逆，这个式子是无法约化到 $\\beta(b)$ 上的。\n可以看到，最后解决这个问题的方法，是直接采用 $\\delta$ 在构造过程中的表现，在从 $B'$ 至 $A'$ 的过程中选择使用 $\\beta(b)$ 一定在 $f'$ 的像中的条件，从而绕过了这个问题。虽然说用形式化的思路，比如限定这里 $f'$ 的范围，从而让做出一些限定条件的 $f'$ 成为同构来解决这个问题，但这始终不是个很好的方案。\n另外，就是 $b$ 一定属于 $\\Ker\\beta$ 的错觉。实际上，$b$ 可以不在 $\\Ker\\beta$ 中，只需要 $b$ 和某个经过 $g|$ 映射后等于 $0$ 的东西结合之后位于 $\\Ker\\beta$ 即可。当然我们现在知道，这个东西就是从 $c$ 一路确定下来的 $f(a)$ 了。\n好了，我们开始准备证明蛇引理主体的最后一部分吧：$\\Coker\\alpha$ 处的正合性。\n$\\operatorname{Coker} \\alpha$ 处正合性的证明。 我们不多废话，还是先证明 $\\Img \\delta \\subseteq \\Ker \\hat{f'}$，后证明 $\\Img \\delta \\supseteq \\Ker \\hat{f'}$。对应的短链是：\n$$\\Ker \\gamma \\xrightarrow{\\delta} \\Coker \\alpha \\xrightarrow{\\hat{f'}} \\Coker \\beta$$证明 $\\operatorname{Im} \\delta \\subseteq \\operatorname{Ker} \\hat{f'}$ 取 $\\Img \\delta$ 中的元素 $\\hat{a'} \\in \\Coker\\alpha$，通过证明 $\\hat{f'}(\\hat{a'}) = \\hat{0} = \\Img \\beta \\in \\Coker\\beta$ 即可证明本命题。由于 $\\hat{f'}$ 的定义，我们有 $\\hat{f'}(\\hat{a'}) = \\widehat{f'(a')} = f'(a') + \\Img \\beta = 0 + \\Img \\beta$，也就是说只需要证明 $f'(a') \\in \\Img \\beta$，我们就能证明本命题。由于 $\\hat{a'}\\in\\Img\\delta$，一定有一个 $\\Ker\\gamma$ 中的元素 $c$ 满足 $\\delta(c) = \\hat{a'}$。\n我们这时使用 $\\delta$ 的定义：若 $\\delta(c) = \\hat{a'}$，就说明一定有一个 $b\\in B$，这个 $b$ 在 $c$ 的原像中，而且 $\\beta(b) = f'(a')$。啊，这不就是我们要的结论吗？既然 $f'(a') = \\beta(b)$ 了，那自然 $f'(a')$ 就在 $\\beta$ 的像里面了呀。就这样，我们证明了这个命题。\n证明 $\\operatorname{Im} \\delta \\supseteq \\operatorname{Ker} \\hat{f'}$ 还是一样，取 $\\Ker \\hat{f'}$ 中的元素 $\\hat{a'} \\in \\Coker\\alpha$。既然在 $\\Ker\\hat{f'}$ 里，我们就有 $\\hat{f'}(\\hat{a'}) = \\hat{0} = \\Img \\beta \\in \\Coker\\beta$（我们是不是刚刚见过这句，那就快进吧），进而 $f'(a') \\in \\Img \\beta \\subseteq B'$。那么，既然是在 $\\Img \\beta$ 中的，我们就取所有满足 $\\beta(b) = f'(a')$ 的 $b\\in B$。此时我们用交换图右侧的交换性，给这个式子左右两边左作用上 $g'$，就得到\n$$0 = g'(f'(a')) = g'(\\beta(b)) = \\gamma(g(b)),$$其中第一个等号来自交换图下面的链复型的性质，第二个等号就是作用 $g'$ 的结果，第三个等号则是交换图的性质。观察这个式子的左右两端，不难根据核的定义得到结论：只要是满足条件的 $b$，$g(b)$ 就全都在 $\\Ker \\gamma$ 中。\n到这里其实已经证明完了，因为我们仅从 $\\hat{a'}\\in\\Ker\\hat{f'}$ 出发，仅利用交换图就得到了所有满足条件的 $b$，证明了它们全都会在 $g$ 的作用下进入到 $\\Ker\\gamma$ 里，也就是说，$\\hat{a'}$ 确定了且一定对应到了 $\\Ker\\gamma$ 中的某些元素。这就说明了 $\\Img \\delta \\supseteq \\Ker \\hat{f'}$。\n我们写详细点，多写几步，那么让 $g(b) = c$，根据 $\\delta$ 的定义（或者作用过程），对 $c$ 作用上 $\\delta$ 后，将会先有若干个满足 $g(b) = c$ 的 $b$，紧接着这些 $b$ 将被 $\\beta$ 映射到 $B'$ 里，最后从 $A'$ 里找到对应的原像，用它们生成一个等价类。而由于我们上面的过程，最后找到的 $A'$ 中的元素所生成的等价类，就是我们一开始的 $\\hat{a'}$。这就说明 $\\delta(c) = \\hat{a'}$。 由于 $\\hat{a'}$ 是我们随意取的在 $\\Ker\\hat{f'}$ 中的元素，都能得到 $\\delta(c) = \\hat{a'}$，因此 $\\hat{a'}$ 确实就存在于 $\\Img \\delta$ 里。\n至此，我们证明了该命题，并结合上一个证明的命题，一起证明了链条在 $\\Coker \\alpha$ 处是正合的。\n虚线箭头的相关证明 其实上面已经证明完了蛇引理的主体部分。下来我们将证明最后的两个命题：若交换图中的上下两个链条都是短正合列（也就是有 $0\\to A$ 和 $C' \\to 0$ 成立），那么在从该交换图中得到的正合列的头尾就可以补上 $0\\to\\Ker\\alpha$ 以及 $\\Coker\\gamma\\to 0$，使得 $\\Ker\\alpha$ 以及 $\\Coker\\gamma$ 处正合。\n我们还是先证第一个，也就是从 $0\\to A$ 的存在可以得到 $0\\to\\Ker\\alpha$ 且 $\\Ker\\alpha$ 处正合。\n证明 $\\operatorname{Ker}\\alpha$ 处的正合性 若有 $0\\to A$，则根据正合列的性质（或者直接看交换图下面的那个链条），我们就有 $f$ 也是个单态。因此，对 $f$ 做出在 $\\Ker\\alpha$ 上的限制得到的 $f|$ 并不会改变它是单态的事实（只缩小了定义域）。此时，由于 $f|$ 是单态，它的核根据单态的性质，就一定是一个平凡群。\n此时我们补上 $0\\to\\Ker\\alpha$，由于它一定是单态，它的像只能是平凡群。这自然地就证明了链条在 $\\Ker\\alpha$ 处是正合的。\n证明 $\\operatorname{Coker}\\gamma$ 处的正合性 如果有 $C'\\to 0$，则根据正合列的性质，我们知道 $g'$ 就必须是满态，这也就意味着 $\\Img g' = C'$。\n我们来看我们定义出的 $\\hat{g'}\\vcentcolon\\space\\Coker\\beta\\to\\Coker\\gamma$，任取它的定义域上的一个元素 $\\hat{b'} = b'+\\Img\\beta$，经过 $\\hat{g'}$ 映射后得到的 $\\Coker\\gamma$ 中对应的元素则是 $g'(b') + \\Img\\gamma$。然而由于 $\\Img g' = C'$，这说明 $g'(b')$ 会随着所有对 $\\hat{b'}$ 的选取而跑遍任何一个这里的 $C'$ 中的元素，进而使 $\\hat{g'}$ 也是一个满态。自此，我们就可以给 $\\Coker\\gamma$ 的右端补上 $\\Coker\\gamma\\to 0$ 的同时保持其正合性，因为补上的映射的核正是 $\\Coker\\gamma$。\n证完串起来 至此，我们完全证明了前面列出的所有结论，进而证明了蛇引理。简单盘点我们证明过的东西，我们做了这些事：\n构造了五个阿贝尔群间的同态，一一验证了它们的定义是 OK 的； 对四个点上的正合性做出证明，具体是先向前得到前一个同态的像在后一个的核内，再证明后一个的核再前一个的像内，从而得到正合 对得到的正合列在交换图上下链条都是短正合列的情况做出补充。 这里有几个值得一提的点。首先，我们在一开始就得到了 $f|$ 和 $g|$ 的定义，它貌似是直接给出的，但应该是由我们自己定义的，即便定义好之后也是同样的形式。由于阿贝尔群同态的核天生就是其定义域上的阿贝尔子群，除了使用原同态在核上的限制来定义以外，并没有什么更好的定义方法了。\n另外，我们尝试给定义的 $\\delta$ 一个具体的表达式，然而这个做法其实可能并不好（我们也应该已经看到了，$(f')^{-1}$ 可能会造成一些问题）。这个同态可以被称作 连接同态，是蛇引理中连接上下两个正合列的的很重要的一个同态。\n然后，就余核来看，如果对它的一些性质更加熟悉，可能证明过程会更加简单。不过我们也在证明过程中看到了关于它的一些性质，这里就不再赘述，只提一点，就是余核内的单位元（零元）代表的不是简单的 $0$，而是一个等价类。我们还可以看到核与余核之间的一些微妙的联系。然而这里就不过多讨论这些了，这些更多是属于范畴论的内容。从范畴的角度来看，它们的区别就是用来定义的交换图内的箭头方向不一样而已。\n还有就是，我们对正合性做出验证时，并没有按照从左向右的顺序，而是先验证了处于交换图中间位置对应的点的正合性，再验证了两边的。这也许是受到了我所看的视频的影响吧。我想在这里做出另一个推荐的证明顺序，即从链条的左边开始，先证明这个链条是一个链复型，再证明它的正合性。从上面的证明过程来看，其实证明它是链复型的过程非常简单，难点则是那个反包含的证明。当然，我暂时也不计划再证明一次，这次写的很多了，就这样吧。\n此外，基础版本的蛇引理不包含最后的两个同态，就是 $0\\to A$ 和 $C'\\to 0$。另一个角度来讲，为了从交换图中得到一条正合列，我们只需要这些最低限度的条件。不过，蛇引理还可以继续拓展下去，不过就不叫蛇引理了。\n最后，我们要指出，我们这里做证明的方法，就是所谓的追图（Diagram Chasing）。这种方法从交换图的某个点内的元素为起点，沿着交换图中的态射移动，最终 “追” 到我们需要的元素为止，从而证明某个结论。追图是同调代数中重要的证明方法，其中最基础的一个证明例子便是这里的蛇引理。不过，这里的证明确实较为冗长，如果借助更高级更复杂的数学工具/技巧，比如范畴论，那么证明应该会更加简短一些，形式也更精简一些，不过可能很难看懂，我也不会这些（）\n证毕后的一点感想 一开始动工的时候，我是没想到竟然能写这么多的。也许是因为我太罗嗦了吧，前面讲了很多的前置，也不知道讲清楚没有，而后面证明过程的很多话又都是套话；又或者我觉得写详细一些，易懂一些，可能会比较好，所以就把证明过程中我的一些想法以及口头的一些表达揉进去了。个人而言我还是挺喜欢思考这些东西并把思考过程写下来的。我也有想过把这篇拆成几个部分，不过目前先写在一起吧。即便看完这么多也需要好久好久。\n可以看到里面有一些可以点开的隐藏了的内容，有许多还没有写好，标记着 “Under Construction~”。这些内容应该会在某天我心血来潮之后再次补好吧（补档：我写好了！）。不过也有可能会删掉，或者直接拆分出来？我也不好现在就下判断。另外我还计划在这篇文章的后面，也就是在证明结束后，再补一个不那么啰嗦的证明过程。这样的话，已经有代数基础的朋友也许就可以直接跳到精简版的来看？emmm不过既然已经有代数基础了，想必来看这篇也就是图一乐了。还是希望能嘴下留情~ 作为一个普通的数学爱好者，能证完这个我感觉还挺有成就感的啦。\n不过必须承认的是，写的过程中我还是回头修改了不少表述不太合适的部分，以及这篇证明是离不开网络上的众多优秀资料的帮助的。感谢互联网，互联网万岁！~\n最后，祝您身心健康，生活愉快~\n我其实挺纠结应该说 函数 还是 映射 的。函数我认为用以指代给集合上每个点指派一个数字的东西更合适，更符合我心目中对函数的想象。而映射又太广泛了，因为很多地方代数结构之间不会一板一眼地讲 “同态”，而是直接就说映射了。思来想去，还是函数更合适，毕竟接触最多，接受程度也最广泛。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这里所谓的合理性，在一般数学教材中称为良定义，而一个定义是合理的也被称为良定的。很奇怪的说法……良定……\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n有数学家表示应区别含幺环范畴 $\\mathsf{Ring}$ 与不含幺的环范畴 $\\mathsf{Rng}$，我觉得环应该含有乘法幺元，且应该省略元音字母 $\\mathsf{i}$，所以写成这样。请根据上下文确定环范畴具体是什么样的含义。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-02-27T00:00:00+08:00","image":"https://a-moment096.github.io/p/%E8%9B%87%E5%B9%B4snake-lemma/Post%20Shelter-Inaba%20Kumori_hu_8a9044463642d801.png","permalink":"https://a-moment096.github.io/p/%E8%9B%87%E5%B9%B4snake-lemma/","title":"蛇年，Snake Lemma！"},{"content":"记录一下目前使用到的两个相场模型，包括它们的推导，假设和缺陷\n头图出自 かとうれい 太太， 为 Mikito P 所作的 少女レイ 的曲绘\n简介 目前在做的 U-Nb 体系不连续析出的模拟，里面用到了这两个演化方程。之前一直没有仔细思考过这两个演化方程到底是什么来头，为什么这个体系适合使用这两个方程，导致现在想大概修改一下它们也无从下手。这里就作为笔记记录下这两个方程的推导方法，优缺点，以及我个人的一些看法吧。\n多相场模型 模型介绍 多相场模型（或者说是界面场模型，差不多吧）是适用于非保守场的演化方程，来自于 I. Steinbach 和 F. Pezzolla 的文章。它的形式为：\n$$ \\frac{\\partial \\phi_\\alpha}{\\partial t} = -\\frac{1}{\\tilde{N}}\\sum_{\\beta \\neq \\alpha} \\tilde{L}_{\\alpha\\beta}\\left(\\frac{\\delta }{\\delta \\phi_\\alpha} - \\frac{\\delta }{\\delta \\phi_\\beta} \\right)F, $$这里的 $F$ 是自由能泛函，$\\tilde{N}$ 是有效序参量的个数，$\\tilde{L}_{\\alpha\\beta}$ 是有效序参量里两相之间的界面移动参数，而括号内的差则是表示一种算符，即\n$$ \\left(\\frac{\\delta }{\\delta \\phi_\\beta} - \\frac{\\delta }{\\delta \\phi_\\alpha} \\right)F = \\frac{\\delta F}{\\delta \\phi_\\beta} - \\frac{\\delta F}{\\delta \\phi_\\alpha}. $$简单来说，这篇文章考虑了使用界面场来描述不同相之间的界面并且演化，而非使用相自身的序参量作为演化参量。虽然最后还是会落到使用相自身的序参量来演化，但是界面场的思想融入到来这个演化模型中。最主要的改进应该是在考虑界面场的同时，考虑每个点处的有效序参量，也就是不为 0 的相的序参量，这样一来还可以简化计算（虽然实际计算过程中也可以只用传统的所有相的计算就是了）。\n平心而论，这篇文章写的逻辑结构并不是非常清晰，公式推导过程更是灾难，甚至符号都有一些问题，但是谁让这个模型好用呢？那就不多讲废话了，直接开始推导这个方程吧。要注意的是，这里的推导过程和作者的推导过程略有出入，同时也参考了 Q. Huang et al 的这篇文章。\n模型推导 对多相问题而言，我们引入一个约束：每个点上的所有序参量之和为一常数 1。即：\n$$ \\sum_{\\alpha = 1}^{N} \\phi_\\alpha = 1, $$由于对时间求导的线性性，又有：\n$$ \\sum_{\\alpha = 1}^{N} \\frac{\\partial \\phi_\\alpha}{\\partial t} = 0. $$设我们现在已经有一个自由能泛函 $F[\\{\\phi\\},\\{\\nabla\\phi\\}]$，其形式为：\n$$ F[\\{\\phi\\},\\{\\nabla\\phi\\}] = \\int_\\Omega f\\left(\\{\\phi\\},\\{\\nabla\\phi\\}\\right) \\,\\mathrm{d}\\omega, $$即我们写出了其能量密度形式。我们现在希望能把上面引入的约束进一步引入这个能量泛函内，因此我们使用 Lagrange 乘数法，引入 Lagrange 乘数 $\\lambda$ 到自由能密度中，则有：\n$$ \\begin{aligned} l \\left(\\left\\{\\phi \\right\\},\\left\\{\\nabla\\phi \\right\\}, \\lambda\\right) \u0026 = f\\left(\\left\\{\\phi \\right\\},\\left\\{\\nabla\\phi \\right\\}\\right) - \\lambda\\left( \\sum_{\\alpha = 1}^{N} \\phi_\\alpha - 1 \\right); \\\\ \\mathcal{L}\\left[\\left\\{\\phi \\right\\},\\left\\{\\nabla\\phi \\right\\}, \\lambda\\right] \u0026= \\int_\\Omega l \\,\\mathrm{d}\\omega. \\end{aligned} $$然后我们令 $\\mathcal{L}$ 对 $\\phi_\\alpha$ 做变分，得到：\n$$ \\begin{aligned} \\frac{\\delta \\mathcal{L}}{\\delta \\phi_\\alpha} \u0026 = \\frac{\\partial l}{\\partial \\phi_\\alpha} - \\nabla \\cdot \\frac{\\partial l}{\\partial \\nabla \\phi_\\alpha} \\\\ \u0026 = \\frac{\\partial f}{\\partial \\phi_\\alpha} - \\nabla \\cdot \\frac{\\partial f}{\\partial \\nabla \\phi_\\alpha} - \\lambda \\\\ \u0026 = \\frac{\\delta F}{\\delta \\phi_\\alpha} - \\lambda . \\end{aligned} $$此时我们应用所谓的 “Relaxation Ansatz”，即这个变分导数值为 $\\phi_\\alpha$ 的演化速率，即：\n$$ \\begin{aligned} \\frac{\\partial \\phi_\\alpha}{\\partial t} \u0026= -\\frac{\\delta \\mathcal{L}}{\\delta \\phi_\\alpha}\\\\ \u0026= -\\frac{\\delta F}{\\delta \\phi_\\alpha} + \\lambda \\end{aligned} $$则根据上面的约束条件，我们能解出 $\\lambda$ 为：\n$$ \\lambda = \\frac{1}{N} \\sum_{\\alpha = 1}^{N} \\frac{\\delta F}{\\delta \\phi_\\alpha} $$此时将 $\\lambda$ 带入应用 “Relaxation Ansatz” 后的变分结果中，得到：\n$$ \\begin{aligned} \\frac{\\partial \\phi_\\alpha}{\\partial t} \u0026= -\\frac{\\delta F}{\\delta \\phi_\\alpha} + \\frac{1}{N} \\sum_{\\beta = 1}^{N} \\frac{\\delta F}{\\delta \\phi_\\beta} \\\\ \u0026= -\\frac{N-1}{N} \\frac{\\delta F}{\\delta \\phi_\\alpha} + \\frac{1}{N} \\sum_{\\beta = 1}^{N} \\frac{\\delta F}{\\delta \\phi_\\beta} - \\frac{\\delta F}{\\delta \\phi_\\alpha} \\\\ \u0026= -\\frac{N-1}{N} \\frac{\\delta F}{\\delta \\phi_\\alpha} + \\frac{1}{N} \\sum_{\\beta \\neq \\alpha} \\frac{\\delta F}{\\delta \\phi_\\beta} \\\\ \u0026= - \\frac{1}{N} \\sum_{\\beta \\neq \\alpha} \\left( \\frac{\\delta }{\\delta \\phi_\\alpha} -\\frac{\\delta }{\\delta \\phi_\\beta} \\right)F \\\\ \\end{aligned} $$最后，我们考虑到由于我们只考虑有效序参量，即不为 0 的序参量，这里的 $N$ 可以修改为 $\\tilde{N}$；括号内属于对两相间的界面场的驱动力描述，对于不同的两相驱动力，驱动力大小应该是不同的，所以我们给驱动力前面乘以和两相相关的界面移动参数，$\\tilde{L}_{\\alpha\\beta}$。这样一来结果为：\n$$ \\frac{\\partial \\phi_\\alpha}{\\partial t} = -\\frac{1}{\\tilde{N}}\\sum_{\\beta \\neq \\alpha} \\tilde{L}_{\\alpha\\beta}\\left(\\frac{\\delta }{\\delta \\phi_\\alpha} - \\frac{\\delta }{\\delta \\phi_\\beta} \\right)F, $$即我们的多相场模型。\n模型解释 上面的推导过程，在最后一步之前都是比较合理的。然而为什么最后能把 $\\tilde{L}_{\\alpha\\beta}$ 硬生生塞进求和里面呢？也许只能通过物理的角度去尝试解释。这个公式在考虑 “Relaxation Ansatz” 时没有引入移动性的一些参数，比如经典 Allen-Cahn 方程里的移动性矩阵，也是为了方便公式推导，否则会陷入求和地狱，得到的 $\\lambda$ 的值会变成：\n$$ \\lambda = \\frac{\\sum_\\alpha\\sum_\\beta{}L_{\\alpha\\beta}\\frac{\\delta F}{\\delta \\phi_\\beta}}{\\sum_\\alpha\\sum_\\beta{}L_{\\alpha\\beta}}, $$带入公式后会得到：\n$$ \\frac{\\partial \\phi_\\alpha}{\\partial t} = \\frac{\\sum_\\beta{L_{\\alpha\\beta}}}{\\sum_\\xi\\sum_\\zeta L_{\\xi\\zeta}}{\\sum_\\xi\\sum_{\\zeta\\neq\\beta} L_{\\xi\\zeta}\\left( \\frac{\\delta }{\\delta \\phi_\\beta} -\\frac{\\delta }{\\delta \\phi_\\zeta} \\right)F} $$虽然严谨，但是难以理解，而当考虑到这里的移动性参数可以直接集成在 $\\tilde{L}_{\\alpha\\beta}$ 和 $\\tilde{N}$ 后，整个式子都会变得更简洁，物理意义也更加明确。\n另外，在 I. Steinbach 和 F. Pezzolla 的文章 里，$\\left( \\frac{\\delta }{\\delta \\phi_\\alpha} -\\frac{\\delta }{\\delta \\phi_\\beta} \\right)F$ 被解释为界面场 $\\psi_{\\alpha\\beta}$，这也是为什么这个模型叫做界面场模型。而这篇文章中的推导过程里，如果考虑使用界面场进行推导的话，可以绕过求取 $\\lambda$ 的显式表达，因为这个 $\\lambda$ 对所有相都是相同的，而界面场这样差值的定义方式注定会消去 $\\lambda$ 的影响。\n最后，我们指出，这个演化方程并没有对自由能 $F$ 做出任何的约束，因此该模型适用性非常广。事实上，多相场模型的应用极为广泛，经常可以在近年的相场模拟文章中见到。所以，尽管看起来这个模型的推导（在我看来，也许是我的问题）并不足够可靠，但是它很好用。是的，很好用。\n巨势方程 模型介绍 为了演化保守场变量，我们经常需要使用 Cahn-Hilliard 方程。然而，为了得到更好的结果，又或者当我们遇到了一些由演化方程引入的数值上的问题，我们也许需要对这个经典的方程做一些改变，就像上面的 Allen-Cahn 方程和多相场模型之间的关系一样。对于浓度这个最经典的变量而言，我们有总浓度场模型（考虑整个模拟域的浓度），相浓度场模型（考虑每个相内部的物质浓度），以及我们这里要介绍的巨势方程（演化模拟域内的化学势）。\n在介绍巨势方程具体的表达式之前，我们先来看一下所谓的“相浓度”和“总浓度”吧。我们知道，对于整个体系而言，其组分数量（元素）是固定的，而一个体系中可能有多个晶粒，而每个晶粒又可能分属不同的相。对不同的相而言，其成分很有可能是不同的。因此，一个组分的浓度在每个相内应该是不变的（不随位置变化），而在整个模拟域内会发生改变（随着相的不同而变化）。另外，浓度的改变是依赖于扩散势的，扩散势梯度会引导浓度进行变化，从高势处流向低势处。因此，相生长过程中浓度的变化可以认为是相浓度不同所导致的相之间扩散势不同所引发的。根据这一点，我们还可以通过演化模拟域内扩散势的变化来间接地模拟浓度的变化。这里我们要介绍的巨势方程，就是这么一个用来模拟扩散势变化的方程。\n巨势方程的表达式如下：\n$$ \\frac{\\partial \\mu_i}{\\partial t} = \\left[\\phi_\\alpha \\frac{\\partial c_j^\\alpha}{\\partial \\mu_i} \\right]^{-1} \\left( \\nabla\\cdot \\bar{M}_{jk} \\nabla\\mu_k + R_j - c_j^\\alpha\\frac{\\partial \\phi_\\alpha}{\\partial t} \\right). $$我需要解释一下这个方程的记号。首先，和往常相似，$c$ 代表相浓度（即一个相内部的浓度），$\\phi$ 代表相。此外，这个公式中的 $\\mu$ 代表化学势（严格来讲是巨势，这也是这个方程名称的由来，但为方便理解我们就称为化学势），$M$ 代表浓度的移动性参数， $R$ 代表可能存在的浓度/物质源。再者，这个方程实际上使用了爱因斯坦求和约定，即如果一个乘积中一个指标出现了两次，那么就对这个指标求和。我们举个例子，比如方程右侧圆括号中的最后一项的记号代表的是：\n$$ c_j^\\alpha\\frac{\\partial \\phi_\\alpha}{\\partial t} \\coloneqq \\sum_{\\alpha}^{N}c_j^\\alpha\\frac{\\partial \\phi_\\alpha}{\\partial t}. $$因此，上面的方程实际上是一个复杂求和。另外，记号中的 $i,j,k$ 都是用以标记元素（组分）的，我们设一共有 $K$ 个组分，所以独立组分一共有 $K-1$ 个（最后一个的量可以用 1 减去其余所有的组分的量），同时 $\\alpha,\\beta$ 等是用来标记相的，我们设一共有 $N$ 个相。根据我们的记号，上面的公式中如果有某个量没有重复指标（重复指标通常也称为哑指标，dummy index），则说明这个变量实则是代表了一个向量，这个向量根据指标的记号区别有 $N$ 或者 $K-1$ 个分量。而如果一个变量有两个指标，则说明这个变量实则是一个矩阵。我们后文记 $K-1$ 为 $\\tilde{K}$ 以方便书写。\n最后我们要解释的是中括号和 $-1$ 的上标。这个记号是代表我们先以括号内的元素组成一个矩阵，然后对矩阵求逆。至此方程中的下标记号应该已经全部清晰明了了。\n方程推导 下面我们来尝试对这个方程进行推导。我们直接从 Cahn-Hilliard 方程出发：\n$$ \\frac{\\partial \\tilde{c}_i}{\\partial t} = \\nabla \\cdot \\sum_{j}^{\\tilde{K}}\\nabla M_{ij}\\nabla \\frac{\\delta F}{\\delta \\tilde{c}_j} + R_i. $$这里我们再次对记号做一些解释。这里我们先不使用爱因斯坦求和约定，方便解释方程内部发生了什么，另外这里的 $\\tilde{c}_i$ 代表的是体系内的总浓度。我们加上了波浪线是为了强调是整个体系内的总浓度，方便和后面的相浓度做出区分。\n由于我们这里使用了总浓度，它实际上可以使用相浓度和相分数来表示：$\\tilde c_i = \\sum_\\alpha^N \\phi_\\alpha c^\\alpha_i$。另外我们知道，$\\frac{\\delta F}{\\delta \\tilde{c}_j}$ 实际上是表示的体系内化学势（巨势）。所以我们直接用 $\\mu_j$ 来替代。这样就有：\n$$ \\frac{\\partial \\sum_\\alpha^N \\phi_\\alpha c^\\alpha_i}{\\partial t} = \\nabla \\cdot \\sum_{j}^{\\tilde{K}}\\nabla M_{ij}\\nabla \\mu_j + R_i. $$现在我们把目光聚焦在等式左侧，因为等式右侧，可以看到，其实已经是最终结果的一部分了。对于等式左侧，首先对有限求和而言，求导的线性性保证了我们可以把求导和求和交换次序。然后我们考虑使用对乘积偏导（求导）的规则，则有：\n$$ \\frac{\\partial \\sum_\\alpha^N \\phi_\\alpha c^\\alpha_i}{\\partial t} = \\sum_\\alpha^N\\left(\\phi_\\alpha \\frac{\\partial c^\\alpha_i}{\\partial t} + c^\\alpha_i \\frac{\\partial \\phi_\\alpha }{\\partial t} \\right) = \\nabla \\cdot \\sum_{j}^{\\tilde{K}}\\nabla M_{ij}\\nabla \\mu_j + R_i. $$我们考虑把求和拆开，把含有相分数对时间求偏导的部分挪到等式右侧，则有：\n$$ \\sum_\\alpha^N \\phi_\\alpha \\frac{\\partial c^\\alpha_i}{\\partial t} = \\nabla \\cdot \\sum_{j}^{\\tilde{K}}\\nabla M_{ij}\\nabla \\mu_j + R_i - \\sum_\\alpha^N c^\\alpha_i \\frac{\\partial \\phi_\\alpha }{\\partial t} . $$接下来是比较关键的一步，我们考虑把浓度和化学势联系起来。即考虑相浓度作为化学势的函数：$c_i^\\alpha = c_i^\\alpha\\left( \\mu_1, \\mu_2, \\cdots, \\mu_{\\tilde{K}} \\right)$。这样我们就可以使用求（偏）导的链式法则，有：\n$$ \\sum_\\alpha^N \\phi_\\alpha \\frac{\\partial c^\\alpha_i}{\\partial t} = \\sum_\\alpha^N \\phi_\\alpha \\sum_k^{\\tilde{K}}\\frac{\\partial c^\\alpha_i}{\\partial \\mu_k}\\frac{\\partial \\mu_k}{\\partial t}, $$然后考虑到对成分求和实际上与相无关，我们把对成分求和的求和号挪到最外面，这样就得到了：\n$$ \\sum_\\alpha^N \\phi_\\alpha \\sum_k^{\\tilde{K}}\\frac{\\partial c^\\alpha_i}{\\partial \\mu_k}\\frac{\\partial \\mu_k}{\\partial t} = \\sum_k^{\\tilde{K}} \\sum_\\alpha^N \\phi_\\alpha \\frac{\\partial c^\\alpha_i}{\\partial \\mu_k}\\frac{\\partial \\mu_k}{\\partial t}. $$我们先在这里暂停一下，回忆矩阵乘法的记号。设我们有两个矩阵，一个 $n\\times m$ 矩阵 $A = \\{a_{ij}\\}$ 和一个 $m\\times p$ 矩阵 $B = \\{b_{jk}\\}$，则它们的乘积矩阵 $C$ 应该是一个 $n \\times p$ 矩阵，它的元素可以记为：$\\sum_j^m a_{ij}b_{jk}$。另外，我们考察偏导 $\\frac{\\partial c^\\alpha_i}{\\partial \\mu_k}$ ，这个偏导在当 $i$ 和 $k$ 都在 $\\tilde{K}$ 个元素中取值时，实际上它组成了一个 $\\tilde{K} \\times \\tilde{K}$ 矩阵中的元素。对应的，我们可以把 $\\partial \\mu_k$ 看作一个具有 $\\tilde{K}$ 个分量的向量（或者 $\\tilde{K} \\times 1$ 的矩阵）。\n根据上面的内容，我们可以发现，实际上这里的求和可以写作两个矩阵的乘积（或者矩阵乘以一个向量）。至此我们采用爱因斯坦求和约定，则有：\n$$ \\sum_k^{\\tilde{K}} \\sum_\\alpha^N \\phi_\\alpha \\frac{\\partial c^\\alpha_i}{\\partial \\mu_k}\\frac{\\partial \\mu_k}{\\partial t} \\coloneqq \\phi_\\alpha\\frac{\\partial c^\\alpha_i}{\\partial \\mu_k}\\frac{\\partial \\mu_k}{\\partial t}. $$我们把上面等式右边的三个因子做简单的区分，前两个因子的乘积实际上由于 $\\alpha$ 指标重复的原因，代表了一个求和，而后又因为这个求和与第三个因子的 $k$ 指标重复，代表了矩阵的乘法。或者我们可以把 $\\sum_\\alpha^N \\phi_\\alpha \\frac{\\partial c^\\alpha_i}{\\partial \\mu_k}$ 理解为矩阵中的第 $\\left( i,k \\right)$ 个元素\n那么经过上面的说明，我们将等价变量依次带回，并对整个方程使用爱因斯坦求和约定重写，则有下面的结果：\n$$ \\phi_\\alpha \\frac{\\partial c_i^\\alpha}{\\partial \\mu_k}\\frac{\\partial \\mu_k}{\\partial t} = \\nabla\\cdot \\bar{M}_{ij} \\nabla\\mu_j + R_i - c_i^\\alpha\\frac{\\partial \\phi_\\alpha}{\\partial t}. $$现在我们可以将上式翻译为：一个 $\\tilde{K} \\times \\tilde{K}$ 的矩阵 $\\left\\{\\phi_\\alpha \\frac{\\partial c_i^\\alpha}{\\partial \\mu_k} \\right\\}$ 与一个 $\\tilde{K} \\times 1$ 矩阵 $\\frac{\\partial \\mu_k}{\\partial t}$ 相乘，得到的结果是三个 $\\tilde{K} \\times 1$ 矩阵相加。而我们希望的是能够得到演化体系扩散势变化的方程，这正好可以用 $\\frac{\\partial \\mu_k}{\\partial t}$ 来表示。所以我们的最后一步就是在等式两边同时左乘上这个 $\\tilde{K} \\times \\tilde{K}$ 矩阵的逆矩阵，得到了：\n$$ \\frac{\\partial \\mu_k}{\\partial t} = \\left[\\phi_\\alpha \\frac{\\partial c_i^\\alpha}{\\partial \\mu_k}\\right]^{-1}\\left(\\nabla\\cdot \\bar{M}_{ij} \\nabla\\mu_j + R_i - c_i^\\alpha\\frac{\\partial \\phi_\\alpha}{\\partial t}\\right). $$也许你会发现这个式子和我们一开始给出的式子在下标上有差别。这个实际上是为了公式美观而改变了下标的排列顺序。只要保证公式内部的记号顺序一致，就可以保证公式，或者说矩阵乘法的逻辑顺序一致，因此我们这里得到的结果和上面给出的公式是没有本质区别的。\n模型解释 我知道，这里其实留了很多的坑，比如说什么是巨势方程里的“巨势”？巨势和化学势有什么关系？为什么非要用化学势/巨势来演化整个体系，用总浓度不好吗？相浓度不行吗？我们来一个个解释这些问题。\n首先，巨势是什么呢？我们知道，热力学中有很多不同的热力学函数，比如焓 $H$，熵 $S$，内能 $U$，吉布斯自由能 $G$，亥姆霍兹自由能 $F$ 等等。巨势，又称朗道自由能也是一种热力学函数，其表达式为：\n$$ \\Omega \\coloneqq F-\\mu N = U-TS-\\mu N, $$其中 $F$ 是亥姆霍兹自由能，$U$ 是内能，$T$ 是体系温度，$S$ 是熵，$\\mu$ 是化学势，$N$ 是体系内的粒子数。巨势的微分形式为：\n$$ \\mathrm{d}\\Omega = \\mathrm{d}U-T\\mathrm{d}S-S\\mathrm{d}T-\\mu\\mathrm{d}N-N\\mathrm{d}\\mu = -P\\mathrm{d}V-S\\mathrm{d}T-N\\mathrm{d}\\mu. $$巨势在体系达到热力学平衡的时候会取到最小值。当体系内的其余变量 $V$，$T$ 不变时，巨势的变化实际上就反映了化学势的变化。另外我们还可以从这个公式中得到浓度的表达方式：考虑将巨势除以体系的体积得到能量密度，此时 $N$ 将从体系内粒子数量变为体系内的粒子浓度/数密度 $\\rho$。假设我们还得到了物质的原子体积 $V_a$，那么浓度 $c$ 就可以表达为：\n$$ c = V_a \\rho = V_a \\left(\\frac{\\partial \\Omega}{\\partial \\mu}\\right)_{V,T}. $$据此，我们可以考虑将浓度表达为化学势的函数。这也是前述的浓度能对化学势求导的一个佐证吧。\n那么，为什么要用巨势方程呢？它对比总浓度或者相浓度有什么优势呢？我们考虑一个多元多相体系，每个相内部都有多种组元，在相内部这些组元的浓度是固定的，而相与相之间的组元浓度一般是不同的。当发生相变时，相内物质浓度可能会发生变化。在这个情况下，我们如果想演化整个体系的浓度分布情况，就不可避免地必须演化每个相的浓度分布。\n我们首先会想到使用相浓度去演化整个体系，这样再将相浓度和相分数相结合就可以得到整个体系内的浓度分布。这个方法从理论上讲很不错，但从实际处理过程中会发生一些数值问题：在相界面处，特别是相分数较小的情况下，不可避免的要用一个数去除以一个非常小的（接近于0）的数字。由于 Cahn-Hilliard 方程是直接对总浓度进行演化的，因此必须先从总浓度中拆分出相浓度才可以直接演化相浓度。从总浓度反推相浓度时，不可避免要处理在界面上的浓度分配，这时必须要借助某种假设来正确地把浓度分配到每个相中。一般采用的假设是假设界面上的每个点上，每个相的化学势都相等。根据这点，总浓度和相浓度的关系可以表达为：\n$$ c^i = \\sum_\\alpha\\phi_\\alpha c_\\alpha^i $$这里，相浓度前的 $\\phi_\\alpha$，相分数，就会引发问题。假设现在需要演化某个很靠近某个相内部的位置（或者说 $\\phi_\\alpha \\approx 1$ 的区域），此时将会有很多别的相的相分数约等于 0。为了演化各自的相浓度，就需要把这个相分数除过去，此时由于计算机精度问题，很容易造成结果不稳定。\n那如果直接考虑总浓度呢？总浓度实际上就是最传统的 Cahn-Hilliard 方程，而为了求得相的演化速率，还是需要通过某种方式去推出每个相中的浓度分配问题。这样会增加过多的计算量：反求相浓度的过程实际上是解线性方程组问题。也就是说，使用相浓度，会遇到数值问题，使用总浓度，又会增加很多的计算量，到头来不过是和相浓度方法的先后顺序调换一下，在反求相浓度的时候依旧可能遇到数值问题。\n然而，使用扩散势时，这个问题被巧妙地隐藏到了偏导数中。这样相当于用某种方法绕过了这样的数值问题，保持了合理的计算开销。简单来说就是，又快又好。\n总结 其实很不好意思地说，这篇内容实际上只是对这两个公式做了一些简单的推导，而后面的解释部分我自认为写的并不好。好像所有的解释最后都要归结到一个结论上：好用。这个点实际上在考虑纯理论时是没有什么用处的：我需要精准的理论来描述物理现象，结果你却告诉我 XXX 然后 YYY 最后得到这些东西，它的理论背景可能不够强，但是它好用就够了。我相信这样的解释是很难真正地打动某个人的心的。\n然而，好用其实就已经够了，因为这些理论到头来本就是为了能够帮助我们在某个假设的基础上能够更好地做模拟。在这里，这个基础假设可以说是 relaxation ansatz 以及等势假设。首先第一个假设能够让我们的体系从一个非平衡态演化到平衡态，而不是只能直接地给出一个平衡态下的数量场，而第二个假设则能够解决相场法中界面上物质分配的问题，让演化能够得以在多相的情况下正常进行下去。这些假设，不论从过程还是结果来看，都是很有必要的。而除了这些假设外，（在不考虑我自己推导过程不够严谨的情况下，）推导过程都是尽可能严谨的。得到的结果，也正如上面所说，好用。\n上面这一大段，我希望能传达到的意思就是，这些公式已经在较少的叫宽松的假设的基础上用尽可能严谨的逻辑推导出了可用，好用的结果，那么作为使用这些公式的人来讲，它好用就够了，坚持实用主义也许是更实际的做法。当然了，阅读本段的您也可以认为是我对自己的推导过程没有什么自信的开脱就是了，嘿嘿嘿~\n那么最后，祝您生活愉快~\n","date":"2025-01-05T00:00:00+08:00","image":"https://a-moment096.github.io/p/%E5%A4%9A%E7%9B%B8%E5%9C%BA%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%B7%A8%E5%8A%BF%E6%96%B9%E7%A8%8B/ShoujouRei_MikitoP_hu_e48231bc64925011.png","permalink":"https://a-moment096.github.io/p/%E5%A4%9A%E7%9B%B8%E5%9C%BA%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%B7%A8%E5%8A%BF%E6%96%B9%E7%A8%8B/","title":"多相场模型与巨势方程"},{"content":"本文系拾人牙慧之作，仅为解决公式推导过程中的一些边角料的数学问题，内容如有错漏还请谅解。另外，感谢老大中先生的《变分法基础》第三版。本文的主要内容几乎全部参考本书。\n头图出自 雨野 太太，为 r-906 所作的 Hello World! 的曲绘\n2025.06.06 更新：感谢@which-is-my-way指正，公式 16 补上点乘单位法向量\n晶体相场公式带来的问题 在一个阳光明媚的晚上，师兄找到我问了一个问题：下面的这个相场公式是怎么组装起来的？具体来讲是：从下面的公式（2）和公式（3）是怎么得到公式（4）的： $$ \\begin{align} F \u0026= \\int_V f \\mathrm{d}v\\\\ \u0026= \\int_V \\left(\\frac{\\psi}{2} \\omega \\left(\\nabla ^2\\right)\\psi + \\frac{\\psi^4}{4}\\right) \\mathrm{d}v;\\\\ \\frac{\\partial \\psi}{\\partial t} \u0026= \\nabla^2 \\frac{\\delta F}{\\delta \\psi} + \\xi;\\\\ \\frac{\\partial \\psi}{\\partial t} \u0026= \\nabla^2 \\left( \\omega\\left( \\nabla^2 \\right) \\psi + \\psi^3 \\right)+ \\xi. \\end{align} $$ 这里我们做一些简单的背景介绍吧。这个公式来源于这篇文章，是提出晶体相场理论的文章，其重要性不言而喻，近乎所有的该领域的文章在使用这篇文章的结果时都需要引用这些个公式。我们这里不对晶体相场做太多介绍了（因为我也不了解，虽然也有相场两个字，但是几乎只有最最基础的假设相似而已了），简单介绍一下这些公式（名称）这些方便后面表述。其中公式（1）是指体系总能量可以表达为能量密度对体积的积分（这里先不给出能量和能量密度的参量），这里可以看到总能量实际上是一个泛函；（2）是指能量密度的具体构造，（3）是和传统相场形式相类似的一个演化方程，在传统相场里是 Cahn-Hilliard 方程。而（4）就是将（3）中的变分展开得到的结果，或者说是具体计算过程中使用的公式的显式表达。\n另外我必须提到的一点是，这里列出的公式并不完整，比如 $\\omega$ 是什么我并没有做说明，这是为了复述一下我的心路历程（即便是笔记，也不希望太死板，毕竟是从实际问题来的）。当然，后面会把完整的问题复述，以及推导过程完整地列出来的。\n传统相场公式，对吗？ 拿到这个公式的时候其实并不是直接从文献拿到的，而是几张图片（大概就是公式（2）（3）和（4））。而我看到公式的第一反应是：这符号不是很对吧？把 $\\psi$ 放到括号外面？这不太对吧？然后我便开始按照以往推导传统相场能量变分的方式推导了。我们来看看传统相场公式吧。 $$ \\begin{align} F(c, \\nabla c ) \u0026= \\int_{\\Omega} f(c, \\nabla c )\\, \\mathrm{d}\\omega = \\int_{\\Omega} f_b(c, \\eta) + \\kappa_c \\left| \\nabla c \\right|^2 \\mathrm{d}\\omega;\\\\ \\frac{\\partial c_i}{\\partial t} \u0026= \\nabla \\cdot M_{ij} \\nabla \\frac{\\delta F}{\\delta c_j \\left( r,t \\right)}, \\end{align} $$ 其中，公式（6）即为 Cahn-Hilliard 方程，而公式（5）则是传统相场中的总能构造的一种常见（最基础的）形式，其中 $f$ 是能量密度，$f_b$ 是体自由能密度。可以看到能量泛函是依赖于（?）浓度和浓度的梯度的。对这个公式的推导我们直接使用三维条件下的 Euler-Lagrange 方程： $$ \\begin{align} \\frac{\\delta F\\left[ x,y,y' \\right]}{\\delta x} = \\frac{\\partial f}{\\partial x} - \\nabla \\cdot \\frac{\\partial f}{\\partial \\nabla x}. \\end{align} $$ 这样一来，这个公式就可以被展开了，只需要按照能量泛函的具体表达形式带入，然后求一下偏导，很快就会得到结果。\n说实话，这是在太棒了，只需要用很多现成（?）的内容，做一些非常简单（?）的推导，就（?）可以得到最后体系的演化方程具体表达形式。那心动不如行动，直接把这一套挪到上面的原始问题吧。很好，我们先对 $\\psi$ 求偏导，得到（?）下面的东西： $$ \\frac{\\partial f}{\\partial \\psi} = \\frac{1}{2}\\omega\\left( \\nabla^2 \\right)\\psi + \\psi^3, $$ 然后，我们要对 $\\nabla \\psi$ 求偏导了。嗯，$\\nabla \\psi$ …… 但是这里是 $\\nabla^2$ ？话说回来为什么要用 $\\omega$ 带括号把 Laplacian 算子包起来呀？啊？\n这对吗？这不对吧？\n重新审视问题，$\\omega$ 是什么？ 问题看来根本不是我想得那么简单。还是需要从零开始一步步建立起这个问题的合理描述，并找到真正的解决方法。首先要解决的，就是 $\\omega(\\nabla^2)$ 这个奇怪的写法。假如这个写法是对的，那 $\\omega$ 就不是什么参数之类的东西了，就应该是算符的一个函数或者别的什么东西了。\n找到原始文献，查看定义，我们得到了 $\\omega$ 的真面目： $$ \\begin{align} \\omega (\\nabla^2) = r + \\left(1 + \\nabla ^2\\right)^2, \\end{align} $$ 其中的 $r$ 是一个复杂的常数，不用关心。果不其然。$\\omega$ 应该解释为一个对 $\\nabla^2$ 算子做一种变换得到的新的算子。或者说，它是把算子映射到算子的一个映射。太棒了，我们把这个结果带入公式（1）中的 $f$ 吧： $$ \\begin{align*} f \u0026= \\frac{\\psi}{2} \\omega \\left(\\nabla ^2\\right)\\psi + \\frac{\\psi^4}{4}\\\\ \u0026= \\frac{\\psi}{2} \\left(r + \\left(1 + \\nabla ^2\\right)^2 \\right)\\psi + \\frac{\\psi^4}{4}. \\end{align*} $$ 等一下，算子中的平方应该怎么解释？常数作用于一个变量应该怎么解释？根据算符的运算规则，我们得知：算符的平方，应该解释为算符作用于被作用量两次，而常数作用应解释为标量乘法。那么我们得到： $$ \\begin{align*} f \u0026= \\frac{\\psi}{2} \\left(r\\psi + \\left(1 + \\nabla ^2\\right)^2\\psi \\right) + \\frac{\\psi^4}{4}\\\\ \u0026= r\\frac{\\psi^2}{2} + \\frac{\\psi^2}{2} + \\psi \\nabla^2\\psi + \\frac{1}{2}\\psi\\nabla^2\\nabla^2\\psi + \\frac{\\psi^4}{4}. \\end{align*} $$ 啊，看起来头好晕，怎么 Laplacian 也有个平方？我们更换符号：$\\Delta = \\nabla^2$，就有了： $$ \\begin{align} f \u0026= r\\frac{\\psi^2}{2} + \\frac{\\psi^2}{2} + \\psi \\Delta\\psi + \\frac{1}{2}\\psi\\Delta\\Delta\\psi + \\frac{\\psi^4}{4}. \\end{align} $$ 好了，这下我们搞清楚了 $\\omega$ 到底是什么以及它对公式有何影响，现在我们对 $\\psi$ 求的偏导应该就没问题了吧？\n等等，什么是 $\\Delta\\Delta\\psi$ ？对 $\\psi$ 求偏导的话要管它吗？就算不管这个东西，这个公式里没有熟悉的 $\\nabla\\psi$ 呀，那我们的能量密度对 $\\nabla\\psi$ 求偏导等于 0 ？这不太对吧？话说回来我们的总能量泛函到底依赖于什么变量？再等一下，依赖？对于一个泛函而言，我们只需要找到最符合要求的一个函数就好了呀？这个函数自然就可以通过对坐标求导得到自己的偏导数了，那偏导数就不应该是一个独立变量才对吧，我们对它做偏导数到底是为什么？\n完了，本来以为什么都知道，现在什么都不知道了。变分法，Euler-Lagrange 方程，这些都不应该是现成的吗？Laplacian，奇怪的 $\\Delta\\Delta\\psi$，这些都不是能直接套到已有公式里的吧？\n死胡同？从头开始吧！ 其实 $\\Delta\\Delta\\psi$ 或多或少能想到是怎么个形式，无非就是把 $\\Delta$ 作用两次就行了，关键在于这个变量，以及 $\\Delta \\psi$ 怎么参与到这个泛函构造中的，并且它们应该怎么参与到泛函导数里面。而为了搞清楚这个问题，我们也许必须明白这个泛函的“自变量”都有哪些，或者说，依赖于哪些变量，并且要搞清楚变量函数本身和它对位置的求导之间到底是有着什么样的关系。\n问题很多，我们干脆从头开始，一步步拆解吧，就从泛函是什么这个问题开始。\n泛函 我们讨论的泛函其实是一类特殊的映射，这个映射拥有定义域和陪域，其定义域为在某个空间上定义的全体函数组成的空间（比如，$\\mathbb{R} \\supseteq \\Omega\\to\\mathbb{R}$ 的函数组成的空间，或者 $\\mathbb{R}^3 \\supseteq \\Omega\\to\\mathbb{R}$ 的函数空间，根据我们的问题是几维的来确定这些函数的定义域），而泛函的陪域则是一个数域，对于能量而言我们就选择 $\\mathbb{R}$ 好了。所以这个映射，从形式上来写，应该就是：\n$$ F:\\left\\{ y \\;\\Big|\\; y: \\Omega \\to \\mathbb{R} \\right\\} \\to \\mathbb{R}. $$另外我们的泛函的另一个特殊之处在于，它常常可以写成这样一个积分的形式：\n$$ F = \\int_\\Omega f\\, \\mathrm{d}\\omega. $$我们常遇到的变分问题，也就是说在求什么样的函数 $\\phi \\in \\left\\{ y \\\\;\\Big|\\\\; y: \\Omega \\to \\mathbb{R} \\right\\}$ 能够使得将之带入泛函 $F$ 时能让这个泛函取到最小值1。甚至我们遇到的问题更加得特殊，因为我们要求函数族 $\\left\\{ y \\\\;\\Big|\\\\; y: \\Omega \\to \\mathbb{R} \\right\\}$ 满足这样的条件：在区域边界 $\\partial \\Omega$ 上这些函数族内的函数都必须相等，或者换句话说，就是我们的问题是固定边界问题。\n太棒了，但是上面这些叙述，对我们的问题有什么帮助呢？我们把目光聚焦到泛函积分形式中的这个 $f$ 上。它没这里有具体的表达式，只是说明了要对它做积分。它具有什么样的意义呢？\n被积函数（泛函的核） 我们这里指出：这个被积分的东西 $f$ 实际上是对泛函的要求。在部分文献中 $f$ 也称为泛函的核。$f$ 的具体表达形式，将会对最后得到的 $y$ 做出约束，使之满足泛函 $F$ 取到最小值的结果。那么，一个对 $y$ 的约束，要怎么表达它呢？或者说我们应该对 $y$ 做一些什么，来使之成为 $y$ 的约束呢？\n为了用 $f$ 来约束 $y$，我们考虑使用 $f$ 来描述 $y$ 的行为。$y$ 在什么情况下，会得到什么样子的结果，大概就是这样的方式去描述。而我们常常在描述 $y$ 的行为时，会考虑到它的导数的行为，将导数 $y'$ 和 $y$ 二者相互作用时得到的结果结合起来。最后考虑到我们描述 $y$ 时很难避免加入函数自变量 $x \\in \\Omega$，最后我们得到的 $f$ 就会变成这样的东西：它看起来像是一个关于 $x\\in \\Omega$，$y : \\Omega \\to \\mathbb{R}$ 以及 $y' : \\Omega \\to \\mathbb{R}^n$ 三个变量的函数（其中 $n$ 的取值取决于考虑的函数的定义域维数）。当存在更多高阶导数参与描述 $y$ 的行为时，这个函数 $f$ 所依赖的变量就更多了。在这个函数中，我们不考虑 $y$ 是和 $y'$ 或者更高阶的导数相关的，因为它们都独立地描述函数 $y$ 的行为。可以这样理解：$y'$ 对函数 $y$ 的约束作用是没法直接用 $y$ 自己或者 $x$ 自己单独去描述的，所以它的影响就应该是独立于 $y$ 和 $x$ 的。 这样一来，令 $f$ 对 $y$，$y'$ 等求偏导也是可以理解的了。另外，我们只关注对 $y$ 起实际约束作用的量，假如 $f$ 中不含有 $y'$，我们认为 $f$ 是不显含 $y'$ 的，此时并不是说 $y'$ 不存在了，而是它不参与到对 $y$ 的行为约束中。\n当我们想要求取得到的函数的定义域从一维上升到我们更常遇到的三维时，函数 $y$ 所依赖的变量也就更加复杂了，可能包括 $\\nabla y$，$\\nabla \\cdot y$，$\\nabla \\cdot \\nabla y$ 等等。和上面类似，我们依旧将这些处理为独立存在于 $f$ 中的变量。有了上面这些的铺垫，我们至少能让我们的问题变得更加清楚一些：问题中的能量形式，将其变量依赖状态完整地写出，应该是以下的形式（这里我们按照惯例将双调和算子 $\\Delta\\Delta$ 写成 $\\Delta^2$ 的形式，它也可以写作 $\\nabla^4$）：\n$$ \\begin{align} F\\left[\\psi\\right] \u0026= \\int_V f \\left(\\psi,\\Delta\\psi,\\Delta\\Delta\\psi\\right) \\mathrm{d}v\\\\ \u0026= \\int_V r\\frac{\\psi^2}{2} + \\frac{\\psi^2}{2} + \\psi \\Delta\\psi + \\frac{1}{2}\\psi\\Delta\\Delta\\psi + \\frac{\\psi^4}{4} \\mathrm{d}v. \\end{align} $$再考察 Euler-Lagrange 方程 然而上面的一切似乎只是澄清了一些基本事实，并没有对解决这个问题起到非常实质的帮助呀。别灰心，至少我们知道了：上面的 Euler-Lagrange 方程，应该是只适用于 $f(x,y,\\nabla y)$的，而对于新的 $f$，我们需要自己想办法得到这样的方程。因此，我们必须深入到变分法的根本，去了解变分法到底是怎么推导出了上面我们用到的 Euler-Lagrange 方程的。为此，我们采用我们一开始认为非常轻易地获得的 Euler-Lagrange 方程所对应的泛函形式来作为例子，自己推导一下它对应的 Euler-Lagrange 方程。\n回忆我们面对的变分法的一般问题：在什么样子的函数 $y$ 下，我们构造出的泛函能够取最小值。我们的函数 $y$ 的定义域是固定的，所以我们要关心的是这个符合要求的函数在每一个点处的值应该是什么样的。不妨假设我们已经有了一个最佳的函数满足要求了，称这个函数为 $\\varphi$。此时，由于这个函数已经是最好的，最满足需求的函数了，任何对这个函数某个值的改变，都会让我们的泛函不能取最小值。\n我们来试着把这个结论写成更形式化一些的表达：假设函数 $\\varphi : \\Omega \\to \\mathbb{R}$ 是满足泛函 $F$ 的最小值需要的函数，则此时任意函数 $y \\neq \\varphi$ 都会造成这样的结果：$F[y] - F[\\varphi] = \\delta F \u003e 0$ ，这里的 $\\delta F$ 就是泛函 $F$ 的变分。这里大于 0 是因为我们已经知道了 $F[\\varphi]$ 是最小值。反过来讲，当 $\\delta F = 0$ 的时候，就能说明此时的函数 $y$ 就是我们需要的函数 $\\varphi$。\n这个表达是否让你感到一丝熟悉？我们先继续向下推进。\n可以看到，假如我们把这个不等式用我们之前熟悉的泛函的积分形式展开，并根据积分的线性性合并，得到的结果是：\n$$ \\delta F = \\int_\\Omega f(x,y, \\nabla y) - f(x,\\varphi,\\nabla\\varphi) \\mathrm{d} \\,\\omega = \\int_\\Omega \\delta f\\, \\mathrm{d}\\omega. $$上面的第二个等号是我们把被积函数的差记为了这样对函数的全变分。这个积分不等式的被积分项里，变量 $x$ 没有什么变化，那我们干脆将 $f$ 在现在看作一个二元函数。我们把 $\\varphi$ 改写为以 $y$ 为基础加上一个扰动的形式：$\\varphi = y+\\delta y$，那么我们可以模仿全微分那样，把这里对函数的全变分 $\\delta f$ 做全微分式的处理，就可以根据它的两个变量的偏导来写出其全变分的表达式。带入上式，则有：\n$$ \\delta F = \\int_\\Omega \\delta f\\, \\mathrm{d}\\omega = \\int_\\Omega \\left(\\frac{\\partial f}{\\partial y}\\delta y + \\frac{\\partial f}{\\partial \\nabla y}\\cdot\\delta\\nabla y \\right) \\, \\mathrm{d}\\omega. $$这个形式已经是我们很熟悉的形式了，但是还有一些区别。这里我们指出，函数对向量求偏导得到的也是一个向量，所以这里需要用向量内积，其中的技术细节我们不多赘述，我们更关注的是：怎么把 $\\delta \\nabla y$ 写成别的形式，来进一步向我们的结果前进。注意到 $\\nabla$ 是对坐标求导，而 $\\delta$ 则是在保持定义域不发生改变的情况下，改变了函数的值。因此二者应该是相互独立的，也意味着两个算符是可以相交换的。再使用点乘的乘积律：$\\nabla \\cdot (f{\\bf{}v}) = f\\nabla\\cdot{\\bf v}+{\\bf v}\\cdot\\nabla f$，这样一通操作，就得到：\n$$ \\begin{align} \\delta F = \\int_\\Omega \\delta f\\, \\mathrm{d}\\omega \u0026= \\int_\\Omega \\left(\\frac{\\partial f}{\\partial y}\\delta y + \\frac{\\partial f}{\\partial \\nabla y}\\cdot\\nabla\\delta y \\right) \\, \\mathrm{d}\\omega \\\\ \u0026= \\int_\\Omega \\left(\\frac{\\partial f}{\\partial y}\\delta y - \\nabla \\cdot \\frac{\\partial f}{\\partial \\nabla y}\\delta y \\right) \\, \\mathrm{d}\\omega + \\int_\\Omega \\nabla\\cdot\\left(\\frac{\\partial f}{\\partial \\nabla y}\\delta y\\right) \\, \\mathrm{d}\\omega\\\\ \u0026= \\int_\\Omega \\left(\\frac{\\partial f}{\\partial y} - \\nabla \\cdot \\frac{\\partial f}{\\partial \\nabla y} \\right)\\delta y \\, \\mathrm{d}\\omega + \\int_\\Omega \\nabla\\cdot\\left(\\frac{\\partial f}{\\partial \\nabla y}\\delta y\\right) \\, \\mathrm{d}\\omega . \\end{align} $$而在式（13）中，最后的积分可以根据多元积分的 Green 公式，化成对区域 $\\Omega$ 的边界 $\\partial \\Omega$ 积分。而此时，由于在边界上所有的函数的值都要相等，此时 $\\delta y = 0$，这样最后一项积分就化为0了。我们写为下面的结果：\n$$ \\begin{align} \\delta F \u0026= \\int_\\Omega \\left(\\frac{\\partial f}{\\partial y} - \\nabla \\cdot \\frac{\\partial f}{\\partial \\nabla y} \\right)\\delta y \\, \\mathrm{d}\\omega + \\int_\\Omega \\nabla\\cdot\\left(\\frac{\\partial f}{\\partial \\nabla y}\\delta y\\right) \\, \\mathrm{d}\\omega\\\\ \u0026=\\int_\\Omega \\left(\\frac{\\partial f}{\\partial y} - \\nabla \\cdot \\frac{\\partial f}{\\partial \\nabla y} \\right)\\delta y \\, \\mathrm{d}\\omega + \\int_{\\partial\\Omega} \\left(\\frac{\\partial f}{\\partial \\nabla y}\\delta y\\right)\\cdot\\hat{n} \\, \\mathrm{d}A\\\\ \u0026=\\int_\\Omega \\left(\\frac{\\partial f}{\\partial y} - \\nabla \\cdot \\frac{\\partial f}{\\partial \\nabla y} \\right)\\delta y \\, \\mathrm{d}\\omega. \\end{align} $$ 这样，我们就距离我们希望得到的形式，Euler-Lagrange 公式只差一步了。注意到这里使用的 $\\delta y$ 是任意的，假如 $\\delta F = 0$，从积分里的内容来看，只能是括号内的部分等于 0。 我们可以看到，上面的过程，可以分为大致四个部分：得到全变分形式，将非目标变分以变分和微分的交换律改写为目标函数变分，消去多余项，由变分任意性得到被积函数内部等于 0。我们因此，可以根据我们已经熟悉的函数导数的概念，将公式（18）中的被积函数括号内这个关键部分定义为泛函的导数，即： $$ \\frac{\\delta F}{\\delta y} = \\frac{\\partial f}{\\partial y} - \\nabla \\cdot \\frac{\\partial f}{\\partial \\nabla y}, $$ 当其为 0 时， $$ \\frac{\\delta F}{\\delta y} = \\frac{\\partial f}{\\partial y} - \\nabla \\cdot \\frac{\\partial f}{\\partial \\nabla y} = 0, $$ 泛函即取到极值（在我们的情境下即为最小值）。这就是所谓的 Euler-Lagrange 方程。\n最后一步 现在，我们对泛函的概念做了一些解释，并从头建立起了我们之前使用的 Euler-Lagrange 公式。这里我希望做一些补充说明。可以看到这里的泛函导数并不是直接的“某些东西的商然后做极限”，而是将某个对我们有用的部分定义为了泛函导数。对这个概念最佳的解释，就是它等于 0 时代表泛函的极值，通过解这个方程就能得到令泛函取得极值的极限函数。它不应被解释为变化率或者什么别的内容。\n另外，我们上面用到了“二元函数全微分”这样的类比。平心而论，我自己并不是特别能接受这种说法。另一个可行的解释是，将函数 $y$ 化为 $y = \\varphi + \\varepsilon\\eta$，也就是说我们使用了一个任意函数 $\\eta : \\Omega \\to \\mathbb{R}$，让它乘上一个极小的量 $\\varepsilon$，这样就相当于用 $\\varepsilon\\eta$ 形成了一个函数的扰动，即 $\\delta y$。我们要求 $\\eta$ 是一个任意的函数，而在任何计算过程中都保持 $\\eta$ 不变。此时整个式子将会成为只关于 $\\varepsilon$ 的一元函数了。对于一个一元函数，其极值点就会出现在导数等于 0 的位置。那么此时对 $\\varepsilon$ 求偏导，也能得到和上面类似的结论，并且通过格林公式化简得到最后的结论。当然，这也只是另一种思路，仅供参考。\n最后要提出的是，上面的推导过程是和 $f$ 的表达式强相关的，尤其是其依赖的变量。然而当我们再考察其和变量之间的关系时，可以发现每个变量实际上对应到最后的 Euler-Lagrange 公式中都是相对独立的。比如，$x$ 这个部分没有在公式中出现，$y$ 的部分对应对 $y$ 求偏导，而 $\\nabla y$ 的部分则对应着对 $\\nabla y$ 求偏导后再对结果做散度。这个结果是可以预想到的：由于全微分公式，或者换成泛函的语境，全变分公式，的性质，是会出现这样的结果。那么我们也自然可以预想到，假如 $f$ 依赖的变量是别的变量，也应该有类似的结论才对。\n到这里，我们近乎完全搞通了我们最后想要解决问题的路径。我们已经得到了泛函具体的表达式，搞清楚了泛函的核（即那个被积函数 $f$）的参数表，得到了对泛函做变分法的具体思路。我们的下一步，或者最后一步，便是真的带进去算了。\n计算！ 为了读者的精神健康，我们隐藏当 $f$ 依赖情况为 $f(p,\\psi,\\Delta \\psi,\\Delta\\Delta \\psi)$ （其中 $p \\in V$ 代表位置）时的 Euler-Lagrange 公式的推导，直接给出结果：\n$$ \\begin{equation} \\frac{\\delta F}{\\delta \\psi} = \\frac{\\partial f}{\\partial \\psi} + \\Delta \\left(\\frac{\\partial f}{\\partial \\Delta \\psi}\\right)+ \\Delta\\Delta \\left(\\frac{\\partial f}{\\partial \\Delta\\Delta \\psi}\\right) \\end{equation} $$ 如果你愿意看推导过程的话： 不，你其实不想看，你只是好奇我到底有没有真的写这些推导过程。事实是：写了，下面就是。\n但是如果你真的想看这个部分，谢谢你，我的努力没有白费。\n我们先根据全变分，写出泛函的核函数变分后的结果：\n$$ \\begin{align*} \\delta F \u0026 = \\delta \\int_V f(p,\\psi,\\Delta\\psi,\\Delta\\Delta\\psi) \\,\\mathrm{d}v \\\\ \u0026 = \\delta \\int_V f(p,\\psi,\\Delta\\psi,\\Delta\\Delta\\psi) \\,\\mathrm{d}v \\\\ \u0026 = \\int_V \\delta f(p,\\psi,\\Delta\\psi,\\Delta\\Delta\\psi) \\,\\mathrm{d}v \\\\ \u0026 =\\int_V \\left(\\frac{\\partial f}{\\partial \\psi}\\right)\\delta \\psi + \\left(\\frac{\\partial f}{\\partial \\Delta\\psi}\\right)\\delta \\Delta\\psi + \\left(\\frac{\\partial f}{\\partial \\Delta\\Delta\\psi}\\right)\\delta \\Delta\\Delta\\psi \\,\\mathrm{d}v. \\\\ \\end{align*} $$接下来我们分别考察被积分的每一项。其中第一项的对 $\\psi$ 的变分 $\\delta\\psi$ 已经符合我们的要求了，第二项中的 $\\delta \\Delta \\psi$ 和第三项中的 $\\delta \\Delta\\Delta\\psi$ 则需要我们处理为某个函数乘以 $\\delta\\psi$ 的形式，以便于最后的逻辑处理。\n根据变分与求导和交换的关系，我们有：\n$$ \\left(\\frac{\\partial f}{\\partial \\Delta\\psi}\\right)\\delta \\Delta\\psi = \\left(\\frac{\\partial f}{\\partial \\Delta\\psi}\\right)\\Delta \\delta \\psi = f_1 \\Delta\\delta\\psi;\\\\ \\left(\\frac{\\partial f}{\\partial \\Delta\\Delta\\psi}\\right)\\delta \\Delta\\Delta\\psi = \\left(\\frac{\\partial f}{\\partial \\Delta\\Delta\\psi}\\right) \\Delta\\Delta\\delta\\psi = f_2\\Delta\\Delta\\delta\\psi, $$其中每行公式的第二个等号都是为了护眼做的处理，即将括号中的偏微分用记号表示。我们先看上面第一个式子，这是两个标量函数的乘积，其第二个因式展开应为:\n$$ \\Delta \\delta \\psi = \\nabla \\cdot \\nabla \\delta\\psi, $$注意到散度存在恒等式：$\\nabla \\cdot (f\\mathbf{v}) = f\\nabla\\cdot\\mathbf{v} + \\nabla f \\cdot \\mathbf{v}$，其中 $f$ 为标量函数或标量场， $v$ 为向量值函数或向量场，我们可以对上面的结果变换得到：\n$$ \\begin{align*} f_1\\nabla \\cdot \\nabla \\delta\\psi \u0026= \\nabla\\cdot(f_1\\nabla\\delta\\psi) - \\nabla f_1\\cdot \\nabla\\delta\\psi \\\\ \u0026= \\nabla\\cdot(f_1\\nabla\\delta\\psi) - \\nabla\\cdot(\\delta\\psi\\nabla f_1) + \\delta \\psi \\nabla\\cdot\\nabla f_1. \\end{align*} $$上式对一个三维区域 $\\Omega$ 的积分，根据散度定理，有：\n$$ \\begin{align*} \\int_V f_1 \\nabla\\cdot\\nabla\\delta\\psi \\,\\mathrm{d}v \u0026= \\int_V \\nabla\\cdot(f_1\\nabla\\delta\\psi)\\,\\mathrm{d}v -\\int_V \\nabla\\cdot(\\delta\\psi\\nabla f_1) \\,\\mathrm{d}v+\\int_V \\delta \\psi \\nabla\\cdot\\nabla f_1 \\,\\mathrm{d}v \\\\ \u0026=\\int_{\\partial V} f_1\\nabla\\delta\\psi\\cdot\\hat{n}\\,\\mathrm{d}s - \\int_{\\partial V} \\delta\\psi\\nabla f_1\\cdot\\hat{n} \\,\\mathrm{d}s + \\int_{V} \\delta \\psi \\nabla\\cdot\\nabla f_1 \\,\\mathrm{d}v\\\\ \u0026=\\int_{V} \\delta \\psi \\nabla\\cdot\\nabla f_1 \\,\\mathrm{d}v. \\end{align*} $$上式第二个等号使用了散度定理，第三个等号则是考虑到在边界处 $\\delta\\psi = 0$，$\\nabla\\delta\\psi = \\mathbf{0}$。这样我们就得到了原变分中被积函数第二项的表达形式。我们现在考虑其中的第三项，即 $f_2\\Delta\\Delta\\delta\\psi$。我们先将其中的 $\\Delta\\delta\\psi$ 看作函数标量函数 $\\varphi$，则原式写为 $f_2\\Delta\\varphi$。此时，套用我们上面已经得到的结果，有：\n$$ \\begin{align*} \\int_V f_2 \\Delta\\Delta\\delta\\psi \\,\\mathrm{d}v \u0026= \\int_V f_2 \\Delta\\varphi \\,\\mathrm{d}v\\\\ \u0026= \\int_{\\partial V} f_2\\nabla\\varphi\\cdot\\hat{n}\\,\\mathrm{d}s -\\int_{\\partial V} \\varphi\\nabla f_2\\cdot\\hat{n} \\,\\mathrm{d}s+\\int_V \\varphi \\nabla\\cdot\\nabla f_2 \\,\\mathrm{d}v \\\\ \u0026= \\int_V \\varphi \\nabla\\cdot\\nabla f_2 \\,\\mathrm{d}v = \\int_V \\varphi \\Delta f_2 \\,\\mathrm{d}v \\\\ \u0026= \\int_V \\Delta\\delta\\psi \\Delta f_2 \\,\\mathrm{d}v = \\int_V \\nabla\\cdot\\nabla\\delta\\psi\\, \\Delta f_2 \\,\\mathrm{d}v\\\\ \u0026= \\int_{\\partial V} \\Delta f_2\\nabla\\delta\\psi \\cdot\\hat{n}\\,\\mathrm{d}s -\\int_{\\partial V} \\delta\\psi\\,\\nabla (\\Delta f_2)\\cdot\\hat{n} \\,\\mathrm{d}s+\\int_V \\delta\\psi \\Delta \\Delta f_2 \\,\\mathrm{d}v \\\\ \u0026= \\int_V \\delta\\psi \\Delta \\Delta f_2 \\,\\mathrm{d}v, \\end{align*} $$其中所有的操作与前面是一样的，不断用恒等式拆开，然后由于在边界上的包含 $\\delta\\psi$ 的项全部归零，所有对 $V$ 的边界 $\\partial V$ 的积分都会变成 0，最后就得到了我们想要的结果。我们把这些积分再合起来，将为了方便所做的记号带回，就有：\n$$ \\begin{align*} \\delta F \u0026 = \\int_V \\left(\\frac{\\partial f}{\\partial \\psi}\\right)\\delta \\psi + \\left(\\frac{\\partial f}{\\partial \\Delta\\psi}\\right)\\delta \\Delta\\psi + \\left(\\frac{\\partial f}{\\partial \\Delta\\Delta\\psi}\\right)\\delta \\Delta\\Delta\\psi \\,\\mathrm{d}v \\\\ \u0026= \\int_V \\left(\\frac{\\partial f}{\\partial \\psi}\\right)\\delta \\psi + \\Delta\\left(\\frac{\\partial f}{\\partial \\Delta\\psi}\\right)\\delta \\psi + \\Delta\\Delta\\left(\\frac{\\partial f}{\\partial \\Delta\\Delta\\psi}\\right)\\delta \\psi \\,\\mathrm{d}v \\\\ \u0026= \\int_V \\left(\\left(\\frac{\\partial f}{\\partial \\psi}\\right) + \\Delta\\left(\\frac{\\partial f}{\\partial \\Delta\\psi}\\right) + \\Delta\\Delta\\left(\\frac{\\partial f}{\\partial \\Delta\\Delta\\psi}\\right)\\right)\\delta \\psi \\,\\mathrm{d}v. \\end{align*} $$那么，由泛函导数的定义，我们就得到了 Euler-Lagrange 方程： $$ \\frac{\\delta F}{\\delta \\psi} = \\frac{\\partial f}{\\partial \\psi} + \\Delta \\left(\\frac{\\partial f}{\\partial \\Delta \\psi}\\right)+ \\Delta\\Delta \\left(\\frac{\\partial f}{\\partial \\Delta\\Delta \\psi}\\right). $$ 现在,我们来把式子带进去吧。为了方便，我们先把公式待带入的公式写在下面：\n$$ \\begin{align} F[\\psi] \u0026= \\int_V f(p,\\psi,\\Delta\\psi,\\Delta\\Delta\\psi) \\mathrm{d}v\\\\ \u0026= \\int_V \\left(\\frac{\\psi}{2} \\omega \\left(\\nabla ^2\\right)\\psi + \\frac{\\psi^4}{4}\\right) \\mathrm{d}v;\\\\ \\omega (\\nabla^2) \u0026= r + \\left(1 + \\nabla ^2\\right)^2;\\\\ \\frac{\\partial \\psi}{\\partial t} \u0026= \\nabla^2 \\frac{\\delta F}{\\delta \\psi} + \\xi.\\\\ \\end{align} $$我们的目的也就是将公式（21）先带入公式（20）得到能量的具体表达形式，然后将得到的结果带入公式（18）来计算能量变分，最后得到公式（22）的显式表达。其中第一步已经完成了，能量密度的具体表达形式为：\n$$ \\begin{equation} f = r\\frac{\\psi^2}{2} + \\frac{\\psi^2}{2} + \\psi \\Delta\\psi + \\frac{1}{2}\\psi\\Delta\\Delta\\psi + \\frac{\\psi^4}{4}. \\end{equation} $$我们先对公式（23）计算需要的这些偏导数，得到：\n$$ \\begin{align} \\frac{\\partial f}{\\partial \\psi} \u0026= r\\psi + \\psi + \\Delta\\psi + \\frac{1}{2}\\Delta\\Delta\\psi+\\psi^3;\\\\ \\frac{\\partial f}{\\partial \\Delta \\psi} \u0026= \\psi;\\\\ \\frac{\\partial f}{\\partial \\Delta\\Delta \\psi} \u0026=\\frac{1}{2}\\psi. \\end{align} $$现在把这些得到的结果，即公式（24-26）带入到我们得到的 Euler-Lagrange 方程（18）中。注意在前面加上对应的 Laplace 算子或者双调和算子。得到的结果为：\n$$ \\begin{align} \\frac{\\delta F}{\\delta \\psi} \u0026= r\\psi + \\psi + \\Delta\\psi + \\frac{1}{2}\\Delta\\Delta\\psi+\\psi^3 + \\Delta\\psi+\\frac{1}{2}\\Delta\\Delta\\psi \\\\ \u0026=r\\psi + \\psi + 2\\Delta\\psi + \\Delta\\Delta\\psi+\\psi^3\\\\ \u0026=\\left(r + \\left(1 + 2\\Delta + \\Delta\\Delta\\right)\\right)\\psi+\\psi^3\\\\ \u0026=\\omega(\\Delta)\\psi + \\psi^3.\\\\ \\end{align} $$那么最后，把式（30）带回到式（22）中。此时我们尊重原文，把符号统一，将 $\\Delta$ 重写回 $\\nabla^2$，就有：\n$$ \\begin{equation} \\frac{\\partial \\psi}{\\partial t} = \\nabla^2 \\left(\\omega(\\nabla^2)\\psi + \\psi^3\\right) + \\xi. \\end{equation} $$这就是我们一开始的目标，式（4）。\n后记 其实这个问题一开始就很清楚：只要找到正确的 Euler-Lagrange 公式，带入无脑计算就行了。但是如何找到正确的 Euler-Lagrange 公式则是一个比较棘手的问题。本文的思路启发自老大中先生的《变分法基础》，翻开书，几乎所有的笔墨全都放在了如何去根据泛函的形式来推导出对应的 Euler-Lagrange 方程上。所幸，我们的这个方程形式非常简单，且答案几乎是现成的，只需要找到正确的位置后取用即可。\n那么这篇文章前面的部分有什么用呢？像跳梁小丑一样跳来跳去，最后发现从一开始就不对劲，转而从头开始推导整个公式。如果一开始就找到这个合适的公式，不就好了吗？也许能够找到这个合适的公式确实能立马解决眼前的问题，但是以后呢？如果遇到了一个形式又不太一样的泛函，此时应该怎么推导出其对应的 Euler-Lagrange 方程呢？而且从文章前半部分可以看到：我对变分法的理解，在推导出这个公式以前，是有问题的。我机械地认为就是带入那个人尽皆知的 Euler-Lagrange 方程，然后算算算就好了。旋即就遇到了第一个问题：怎么让 Laplacian 对梯度求导。是的，我当时并不怀疑是公式问题，而是考虑怎么让这个公式能算下去。在网上搜索一段时间之后，我貌似得到了结果，但总归不太满意，因为带入后得不到最后的公式。\n一段迷茫过后，我突然对变量之间的依赖情况产生了疑惑。网上搜寻的结果表明，不能单纯地看作相互关联的变量，或者说单纯的求导关系。最后我得到了上文中的解释，也许我在这部分的解释是错误的，但我用这个方法说服了自己。希望这个观点没有问题。顺带，我得到这个解释或多或少受到了热力学的启发：热力学中的偏导数必须标明哪些变量是固定不变的，这时因为热力学参数张成了一个高维空间，而体系的热力学状态则是这个空间上的一个超平面，热力学状态函数则是这个超平面上定义的场。因此，对热力学状态函数求偏导的时候必须固定求导方向，也就是固定某些变量不变。也许是这样的理解让我将泛函的核理解为了对函数的约束（我也不知道怎么联系上去的，所以说只可谓之启发）。\n然而即便如此，我依旧没法得到最后最关键的公式。此时只能从头开始一步步推导 Euler-Lagrange 公式了。所幸，我找到了老大中先生的这本书，读过一部分之后，遍跳着找到了我需要的答案。感谢这本书，让我少走了不知道多少弯路。\n最后，感谢您能阅读到这里，看这么久的流水账也挺辛苦的。希望这篇流水账一样的文章也能帮助正在阅读的你增进对 Euler-Lagrange 公式和变分法或者泛函导数的理解。\n那么，祝您生活愉快~\n请容许我这里混淆最小值和极小值，以及最值和极值，因为我们默认需要这个泛函取到的是极小的部分，且这个极小值一定是全局的，即最小值。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-01-04T00:00:00+08:00","image":"https://a-moment096.github.io/p/%E5%85%B3%E4%BA%8E%E6%B3%9B%E5%87%BD%E5%AF%BC%E6%95%B0%E5%92%8C%E5%8F%98%E5%88%86%E6%B3%95-%E6%9D%A5%E8%87%AA%E7%9B%B8%E5%9C%BA%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E7%9A%84%E9%97%AE%E9%A2%98/HelloWorld-r-906_hu_5c7084224fc31154.jpg","permalink":"https://a-moment096.github.io/p/%E5%85%B3%E4%BA%8E%E6%B3%9B%E5%87%BD%E5%AF%BC%E6%95%B0%E5%92%8C%E5%8F%98%E5%88%86%E6%B3%95-%E6%9D%A5%E8%87%AA%E7%9B%B8%E5%9C%BA%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E7%9A%84%E9%97%AE%E9%A2%98/","title":"关于泛函导数和变分法-来自相场公式推导的问题"},{"content":"其实这节就是换成 Allen-Cahn 方程，然后多个变量而已，主要是俺不想实现 Voronoi 结构（逃\n简介 上一部分我们以调幅分解为基础讨论了浓度场在 Cahn-Hilliard 方程下的演化过程。对相场方法而言，另一个无法绕开的演化方程则是针对非保守场变量的 Allen-Cahn 方程。这一部分我们将对晶粒长大过程进行分析，了解 Allen-Cahn 方程并使用它进行晶粒长大过程的模拟。\n晶粒长大 晶粒长大的过程各位材料学子应该已经很熟悉了，在这个过程中，由于晶界能量较高而体自由能相较之下较低，体系能量希望能够达到全局最低的情况下，需要尽可能地降低晶界能在总能中的占比，提高体自由能的占比。但是，晶界能的能量密度应该是某个变化不大的数值，几乎可以看作定值，因此为了降低晶界能，体系会倾向于降低晶界的体积，提高晶体的体积。这样一来，从宏观上的表现来看就是晶粒长大的过程。\n这样来看，晶粒长大过程对能量的需求是：晶粒内的能量较低，晶界处的能量较高。那么，之前的 Cahn-Hilliard 方程 + 浓度的组合是否可行呢？我们需要考察晶粒长大过程中涉及什么量。由于同一种相的不同的晶粒都具有相同的成分，故无法用浓度来表示某一个特定的晶粒；不考虑取向的话，晶粒与晶粒之间只存在位置，大小之间的差异，也就是单纯的几何差异。而在界面上，一个晶粒与另一个晶粒相接，还需要某种方法来表示某些晶粒之间的界面。而且在晶粒生长的过程中，小晶粒可能会变得更小最后消失。\n综合上面来看，Cahn-Hilliard 方程和浓度并不适合这个问题，那么应该如何处理呢？相场方法中我们经常使用场变量来表示某个区域存在某种性质，那么可以考虑为每个不同的晶粒赋予一个不同的变量，比如假设有 10 个小晶粒，那么就使用 10 个变量来分别代表这些晶粒区域。其次，考虑到这些晶粒仅存在位置上的差异，我们需要在他们参与热力学讨论时没有数值上的差异。我们可以让这些变量类比于浓度：存在于某区域时变量为 1，不存在则变量为 0。这样，界面部分也可以简单地表示出来：所有序参量都不为 0 的部分即为界面部分，这样也摆脱了追踪界面的麻烦。\n那么，我们需要使用什么样的方程来演化这样的场呢？这个场，根据上面的分析，是不满足守恒条件的。我们这里就不卖关子了（因为上个部分已经剧透了），答案就是使用 Allen-Cahn 方程。那么这个体系的能量呢？这个方程要怎么理解呢？\n模型分析 演化方程 我们先看看 Allen-Cahn 方程吧： $$\r\\frac{\\partial \\eta_i}{\\partial t} = -L_{ij}\\frac{\\delta F}{\\delta \\eta_j}\r$$ 简单地令人发指（也许）。简单来说，就是某个变量的变化速率受到所有的势的加权求和影响。但是要如何理解这个公式呢？它是怎么来的呢？其实如果有看过上一篇内容的话，应该已经猜到了。如果物质不守恒，那么物质流的散度项就可以替换成某种别的形式。这个所谓“别的形式”需要满足这些条件：\n需要和能量/势相关以满足热力学要求 最终是令体系演化达到平衡的 那么干脆就让演化速率和势成正比好了，然后用符号调整演化方向最终是朝着体系稳定的方向发展的。这样就得到了上面的 Allen-Cahn 方程。\n除了这样解释之外，我们还可以采用更加数学一些的方式。当我们需要体系朝着稳定方向发展时，实际上也就是说我们希望体系自由能向着最小的方向发展。而当体系稳定时，我们有如下关系：\n$$\r\\frac{\\delta F}{\\delta \\eta_i} = 0\r$$这里需要运用我们已经了解到的泛函导数的相关内容，当泛函导数为 0 时，说明这个构型的 $\\eta_i$ 是令泛函 $F$ 取得极值的点。考虑到 $F$ 具有能量的物理意义，这里的极值自然是极小值。在热力学中，极小值表示体系至少出于亚稳态。当该构型下恰好能量是最低的时，则体系出于热力学稳定状态。\n这样一来，体系的稳态表示就没有任何问题，但是我们需要的是向着稳态演化，而不是直接求得稳态的状态。这时就需要使用经典的数值方法：弛豫法。我们给方程右边的 0 改变为某个微小变量。这个变量的意义是令体系向着平衡态发展，所以这个变量应该越来越小。通过不断迭代，最终这个微小变量将趋近于 0，此时我们便得到了平衡稳态的结果。那么这个微小变量，按照我们的预想，应该和场变量本身是相关的；不断迭代的过程又说明和时间相关。要让这个微小变量不断减小，根据能量函数（泛函）的特性，干脆就让弛豫变量设置为场变量的演化速率，再乘上一个弛豫常数。由于演化方向，弛豫常数应该是一个小于 0 的值，最后考虑所有项的影响，就得到了这个方程。\n最后要指出，上面这些都是从一些不够物理的，十分唯象的角度来提出的。实际上，Allen-Cahn 方程是建立晶界迁移速率与驱动力成正比这一结论得出的，而这一结论更是从晶体排列构型的基态得到的。\n关于 A-C 方程的一些碎碎念另外，这个形式的方程非常常见，或者说，水非常深。几乎可以在物理学的许多领域见到这个方程，而对这个方程的描述都各有千秋。有人称其为 Landau–Khalatnikov 方程（描述磁性），有人称之为 Model A（界面动力学，[Theory of dynamic critical phenomena](https://doi.org/10.1103/RevModPhys.49.435)），还有一些奇奇怪怪的名称，但是这些文章几乎都没有对这个方程做出详细的解释。也许这些方程是从某些物理直觉中得到的？又或者这些这些方程有其更深刻的数学/物理背景，但是这些我也无从得知。\r能量构造 本模拟使用的能量模型来自D. Fan 与 LQ. Chen 的文章，其构造如下： $$\r\\begin{align*}\rF \u0026= \\int_\\omega f_{bulk} + f_{int} \\,\\mathrm{d}\\Omega;\\\\\rf_{bulk}\\left(\\eta_0,\\eta_1,\\cdots,\\eta_N\\right) \u0026= \\sum_{i}^{N}\\left( -\\frac{A}{2}\\eta_i^2 + \\frac{B}{4}\\eta_i^4 \\right) + \\sum_{i}^{N}\\sum_{j\\neq{}i}^{N}\\eta_i^2\\eta_j^2;\\\\\rf_{int}\\left(\\nabla\\eta_0,\\nabla\\eta_1,\\cdots,\\nabla\\eta_N\\right) \u0026= \\sum_{i}^{N}\\frac{\\kappa_i}{2} \\left| \\nabla \\eta_i \\right|^2.\r\\end{align*}\r$$其中的界面能项我们不再赘述，因为它就是上一部分介绍过的能量而已，只不过这里要加上所有序参量的贡献而已。我们重点放在体能上。和上次相比，体能的部分变化很大，但是也有一些熟悉的部分。我们把这个体能重新整理一下： $$\r\\begin{align}\rf_{bulk}\u0026= \\sum_{i}^{N}\\left( -\\frac{A}{2}\\eta_i^2 + \\frac{B}{4}\\eta_i^4 \\right) + \\sum_{i}^{N}\\sum_{j\\neq{}i}^{N}\\eta_i^2\\eta_j^2\\\\\r\u0026=\\sum_{i}^{N}\\left( -\\frac{A}{2}\\eta_i^2 + \\frac{B}{4}\\eta_i^4 \\right) + \\sum_{i}^{N}\\eta_i^2 \\sum_{j\\neq{}i}^{N} \\eta_j^2\\\\\r\u0026=\\sum_{i}^{N}\\left(\\left( -\\frac{A}{2}\\eta_i^2 + \\frac{B}{4}\\eta_i^4 \\right) + \\eta_i^2 \\sum_{j\\neq{}i}^{N} \\eta_j^2\\right)\\\\\r\u0026=\\sum_{i}^{N}\\left( \\left(-\\frac{A}{2} + \\sum_{j\\neq{}i}^{N} \\eta_j^2\\right) \\eta_i^2 + \\frac{B}{4}\\eta_i^4 \\right)\\\\\r\\end{align}\r$$ 上面第二个等号是由于对 $j (j\\neq i)$ 的求和的部分与 $i$ 无关，我们可以把 $\\eta_i^2$ 从二重求和中提出来， 然后第三个等号中把对 $i$ 的求和的部分提取合并，最后第四个等号里提出 $\\eta_i^2$，把 $\\sum_{j\\neq{}i}^{N} \\eta_j^2$ 作为系数和 $-\\dfrac{A}{2}$ 合并。现在我们把目光放在求和里面的这个，关于 $\\eta_i$ 的多项式。为简单起见，我们设 $A = B = 1$。下面是这个函数在 $\\sum_{j\\neq{}i}^{N} \\eta_j^2 = 0$ 时候， 即 方程(1) 的第一项的图像（当然，这个假设不够合理，但是我们可以先看看）。\n是我们很熟系的双势阱，但是这里有一些问题：序参量实际上不能小于0，也不应该大于1。如果我们只关注 0 到 1 之间的值，不难发现现在这个能量的最低点处在 $\\eta = 1$ 的地方。这很合理：在其余的所有序参量（我们简称所有的 j ，对应的本个序参量则为 i）都为 0 的情况下，或者说在没有任何 j 的点，i 占据该点是理所应当的。考虑到每个序参量都是平权的，这说明了这个方程是符合体相内部的热力学要求的。接下来我们考察当这个求和项不为 0 的情况。j 求和的值的变化范围我们先设为 0 到 2。\n可以看到，当 j 不为 0 时，结果也是合理的，这里 i 的值也不在 1 处取到最小值，而是在 0 到 1 之间的区域取到最小值了。感兴趣的话您可以自行尝试绘制这里的图像，然后调整这些值，观察序参量-能量曲线的最低点位置。当然，我们也可以使用更数学一些的方式来研究这里的最低点取值情况，不过图像方法更加直观一些就是了。最后来简单描述一下表达式 (1) 的物理意义：将每个参量都赋予一个类势阱的能量，然后通过第二项的交叉作用将这些能量结合在一起。第二项的二重和即是其他参量对本参量的影响。\n相场演化方程与扩散方程之间的关系 我们其实很早就发现了 Allen-Cahn 和 Cahn-Hilliard 两个方程与扩散方程（Fick 定律）之间的相似性。我们现在来更仔细地看看这些方程与 Fick 定律之间有什么关系吧。\n对于 Cahn-Hilliard 方程而言，可以看到它与 Fick 第二定律的形式非常地像。如何看待这种相似性呢？我们可以讲，对于 Fick 第二定律而言，其提供扩散驱动力的部分是浓度本身，或者说浓度的梯度。而当这个驱动力放在更加广阔的语境下时，例如，上坡扩散等现象发生时，我们必须根据热力学原理，使用扩散势来解释这类现象。因此，可以将 Cahn-Hilliard 方程看作是更加符合热力学原理的扩散方程。\n那么，Allen-Cahn 方程呢？ 我们需要把 Allen-Cahn 方程和经典的能量泛函构造联系起来，并展开公式。这时我们得到： $$\r\\frac{\\partial \\eta_i}{\\partial t} = L_{ij}\\nabla^2 \\eta_j - L\\mu_i\r$$这个形式，熟悉吗？如果去掉第二项，那么这个方程就是 Fick 第二定律！那么第二项代表了什么呢？第二项实际上代表了某种界面上发生的反应。为什么说是界面上的？观察这个方程与 Fick 第二定律所代表的情况，第一项代表了某个变量是守恒的，然而第二项的化学势的存在打破了这种平衡。我们使用界面上的反应来解释这种情况的出现是最合适的：不守恒的序参量是被“消耗”掉了。实际上，按照这种思路，我们可以构造出更加复杂的演化方程，即根据体系内存在的反应，向能量中添加反应造成的能量变动，最后则会反映到 Allen-Cahn 方程的反应项中。\n问题分析 OK，现在我们应该对这次模拟所需要的演化方程以及能量构造有一定的理解了。这次我们要尝试的问题是：假设有两块单晶，一块出于另一块的中心，中心晶粒的形状是半径 14 单元的一个圆盘。现在需要通过模拟得到晶粒长大的过程。\n十分简单的问题，只需要创建两个序参量网格，然后对每个网格进行迭代即可。也许求和部分有一些问题，然而可以通过一些程序技巧简化一部分的运算。直接看代码吧。\n代码实现 我们依旧使用 C++ 实现，这里一次性全都贴出来。\n1#include \u0026lt;filesystem\u0026gt; 2#include \u0026lt;fstream\u0026gt; 3#include \u0026lt;iostream\u0026gt; 4#include \u0026lt;string\u0026gt; 5#include \u0026lt;vector\u0026gt; 6 7double laplacian(double eta_l, double eta_r, double eta_d, double eta_u, double eta_c, double dx) { 8 return (eta_l + eta_r + eta_d + eta_u - 4.0 * eta_c) / (dx * dx); 9} 10 11double df_deta(double A, double B, double eta_square_sum, double this_eta) { 12 return -1.0 * A * this_eta + B * this_eta * this_eta * this_eta + 2.0 * this_eta * (eta_square_sum - this_eta * this_eta); 13} 14 15std::ofstream create_vtk(std::string file_path, int time_step) { 16 std::filesystem::create_directory(file_path); 17 std::filesystem::path f_name{\u0026#34;step_\u0026#34; + std::to_string(time_step) + \u0026#34;.vtk\u0026#34;}; 18 f_name = file_path / f_name; 19 20 std::ofstream ofs{f_name}; 21 return ofs; 22} 23 24void write_vtk_head(std::ofstream \u0026amp;ofs, std::string filename, double dx, size_t Nx, size_t Ny) { 25 ofs \u0026lt;\u0026lt; \u0026#34;# vtk DataFile Version 3.0\\n\u0026#34;; 26 ofs \u0026lt;\u0026lt; filename \u0026lt;\u0026lt; std::endl; 27 ofs \u0026lt;\u0026lt; \u0026#34;ASCII\\n\u0026#34;; 28 ofs \u0026lt;\u0026lt; \u0026#34;DATASET STRUCTURED_GRID\\n\u0026#34;; 29 30 ofs \u0026lt;\u0026lt; \u0026#34;DIMENSIONS \u0026#34; \u0026lt;\u0026lt; Nx \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; Ny \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; 1 \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; 31 ofs \u0026lt;\u0026lt; \u0026#34;POINTS \u0026#34; \u0026lt;\u0026lt; Nx * Ny * 1 \u0026lt;\u0026lt; \u0026#34; float\\n\u0026#34;; 32 33 for (size_t i = 0; i \u0026lt; Nx; i++) { 34 for (size_t j = 0; j \u0026lt; Ny; j++) { 35 ofs \u0026lt;\u0026lt; (double)i * dx \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; (double)j * dx \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; 1 \u0026lt;\u0026lt; std::endl; 36 } 37 } 38 ofs \u0026lt;\u0026lt; \u0026#34;POINT_DATA \u0026#34; \u0026lt;\u0026lt; Nx * Ny * 1 \u0026lt;\u0026lt; std::endl; 39} 40 41void write_vtk_data(std::vector\u0026lt;std::vector\u0026lt;double\u0026gt;\u0026gt; mesh, std::ofstream \u0026amp;ofs, std::string data_label, double dx) { 42 size_t Nx{mesh.size()}, Ny{mesh.at(0).size()}; 43 ofs \u0026lt;\u0026lt; \u0026#34;SCALARS \u0026#34; \u0026lt;\u0026lt; data_label \u0026lt;\u0026lt; \u0026#34; float 1\\n\u0026#34;; 44 ofs \u0026lt;\u0026lt; \u0026#34;LOOKUP_TABLE default\\n\u0026#34;; 45 for (size_t i = 0; i \u0026lt; Nx; i++) { 46 for (size_t j = 0; j \u0026lt; Ny; j++) { 47 ofs \u0026lt;\u0026lt; mesh.at(i).at(j) \u0026lt;\u0026lt; std::endl; 48 } 49 } 50} 51 52int main() { 53 int Nx = 64; 54 double dx = 0.5, dt = 0.005; 55 int nstep = 20000, pstep = 100; 56 int radius = 14; 57 double mobility = 5.0, kappa = 0.1; 58 double A = 1.0, B = 1.0; 59 double eta_trun = 1e-6; 60 61 std::vector\u0026lt;std::vector\u0026lt;double\u0026gt;\u0026gt; grain_1(Nx, std::vector\u0026lt;double\u0026gt;(Nx, 0)); 62 auto grain_2 = grain_1; 63 64 for (int i = 0; i \u0026lt; Nx; i++) { 65 for (int j = 0; j \u0026lt; Nx; j++) { 66 if ((i - Nx / 2) * (i - Nx / 2) + (j - Nx / 2) * (j - Nx / 2) \u0026lt; radius * radius) { 67 grain_1.at(i).at(j) = 1.0; 68 grain_2.at(i).at(j) = 0.0; 69 } else { 70 grain_1.at(i).at(j) = 0.0; 71 grain_2.at(i).at(j) = 1.0; 72 } 73 } 74 } 75 76 std::vector\u0026lt;std::vector\u0026lt;std::vector\u0026lt;double\u0026gt;\u0026gt;\u0026gt; grains = {grain_1, grain_2}; 77 auto grains_temp = grains; 78 79 for (int istep = 0; istep \u0026lt; nstep + 1; istep++) { 80 std::vector\u0026lt;std::vector\u0026lt;double\u0026gt;\u0026gt; grain_square_sum(Nx, std::vector\u0026lt;double\u0026gt;(Nx, 0)); 81 for (int igrain = 0; igrain \u0026lt; 2; igrain++) { 82 for (int i = 0; i \u0026lt; Nx; i++) { 83 for (int j = 0; j \u0026lt; Nx; j++) { 84 grain_square_sum.at(i).at(j) += grains.at(igrain).at(i).at(j) * grains.at(igrain).at(i).at(j); 85 } 86 } 87 } 88 for (int igrain = 0; igrain \u0026lt; 2; igrain++) { 89 for (int i = 0; i \u0026lt; Nx; i++) { 90 for (int j = 0; j \u0026lt; Nx; j++) { 91 int im = i - 1, jm = j - 1, ip = i + 1, jp = j + 1; 92 if (im == -1) { 93 im = Nx - 1; 94 } 95 if (jm == -1) { 96 jm = Nx - 1; 97 } 98 if (ip == Nx) { 99 ip = 0; 100 } 101 if (jp == Nx) { 102 jp = 0; 103 } 104 double eta_l = grains.at(igrain).at(im).at(j); 105 double eta_r = grains.at(igrain).at(ip).at(j); 106 double eta_d = grains.at(igrain).at(i).at(jm); 107 double eta_u = grains.at(igrain).at(i).at(jp); 108 double eta_c = grains.at(igrain).at(i).at(j); 109 110 grains_temp.at(igrain).at(i).at(j) = eta_c - mobility * dt * (df_deta(A, B, grain_square_sum.at(i).at(j), eta_c) - kappa * laplacian(eta_l, eta_r, eta_d, eta_u, eta_c, dx)); 111 112 if (grains_temp.at(igrain).at(i).at(j) \u0026gt; 1.0 - eta_trun) { 113 grains_temp.at(igrain).at(i).at(j) = 1.0; 114 } 115 if (grains_temp.at(igrain).at(i).at(j) \u0026lt; eta_trun) { 116 grains_temp.at(igrain).at(i).at(j) = 0.0; 117 } 118 } 119 } 120 } 121 grains = grains_temp; 122 if (istep % pstep == 0) { 123 auto ofs = create_vtk(\u0026#34;./result\u0026#34;, istep); 124 write_vtk_head(ofs, \u0026#34;step_\u0026#34; + std::to_string(istep), dx, Nx, Nx); 125 write_vtk_data(grains.at(0), ofs, \u0026#34;grain_1\u0026#34;, dx); 126 write_vtk_data(grains.at(1), ofs, \u0026#34;grain_2\u0026#34;, dx); 127 } 128 } 129} 这次我们优化了 vtk 文件的生成函数，使之能够分部写入。其余部分都是非常简单的。考虑到计算过程，这次的模拟甚至比上次的还要简单一些。运行这里的代码之后，程序会在其位置生成一个 result/ 文件夹并且把结果文件都放在里面。和之前一样，使用 Paraview 即可打开这些文件了。\n结果 和上次一样，这里就贴一下几张截图。\n第5步 第25步 第75步 第150步 可以看到，随着时间推进，小晶粒（中间红色部分）被大晶粒（蓝色部分）不断吞并。而且根据步数，可以看到一开始由于两个晶粒的体积近似，演化速率并不大；随着不断的演化，两个晶粒的体积差距越来越大，演化速率也变大了。这符合我们对晶粒长大过程的认知，小晶粒会非常快速地消失，而较大的晶粒则会演化地比较慢。\n结语 我刚开始写的时候也没有想到这里会写这么多的模型解析的内容。不过也算是补充了之前对相场模型介绍不足的问题吧。这里的模拟部分，因为是参考的 Programming Phase Field Modeling 的 Case Study II，实际上还应该实现一下 Voronoi 结构的模拟，然后把多序参量情况下的代码结构处理一下。这里的代码应该是没有完全支持多相场情况的。但，我实在不想手搓一个 Voronoi 结构生成的函数，而能生成这个结构的库都太大了，我也不想给这个示例/教学代码引入什么第三方库。所以，结果就是，这里只实现了两个晶粒的模拟。也许之后会突然对 Voronoi 结构生成算法开窍了，然后就写进这个程序里呢？那也是以后的事了。\n和上一个部分一样，对模型和模拟过程更深层的理解是离不开调整参数进行测试的。这两个案例都是比较简单的案例，可调的参数并不多，而且在模拟一开始的时候就已经有了参考的参数了，也不是面对的实际存在的体系，填入的数字的物理意义并没有很大，或者说是比较唯结果论的一些数据。在面对实际物理体系的时候，填参数这块儿是模拟过程最折磨的部分了。如何精确地控制这些参数，让他们配合起来形成一个符合物理特性，而且也能跑出合理结果，这也许是相场方法最麻烦的点。参数的可解释性经常会和参数的数值特性相悖，而能平衡二者的结果几乎都是经过精心设计的。总而言之，多调参数总没错。\n那么这就是这个教程（自称）系列的最后一部分了。相场方法作为一种材料模拟方法，能做的东西非常多，但是其本身也有一定的限制。它最大的限制就是所谓的扩散界面，这样的界面解决了微分方程不好解的问题，但是也让这个方法很容易滑向物理意义不明确的道路，也经常会因为界面的存在而导致一些模拟发生数值失稳（即便引入界面常常就是希望能解决数值失稳的）。这些特点注定让相场成为一门比较复杂的交叉学科：需要对材料科学有深入的理解，对材料的物理特性有清晰的物理图像，对数值方法有清晰的认知，明白各种方法之间的优缺点选择合适的方法，最后还需要有一定的程序能力来支撑实现模拟。这也许也是相场复杂的地方吧。\n相场方法并不是一个很新的模拟方法，但是它还有很大的发展空间。不论是比较传统的调幅分解的深入研究模拟，还是使用相场法研究固体力学、电磁学、流体力学这些更复杂的外场，又或者是开发新的程序软件来帮助进行相场模拟，甚至是使用机器学习来辅佐相场计算，这些都是相场正在发展的方向。这个系列的教程希望能够提供相场方法最基础的部分，比如相场的数学基础，程序基础等等。这些内容应该能够成为学习相场过程中比较重要的工具，以便于学习和发展更深层的更复杂的理论/实践。希望阅读本教程的您可以从中有所收获。\n那么就是这样，最后祝您生活愉快，科研顺利~\n","date":"2024-12-25T00:00:00+08:00","image":"https://a-moment096.github.io/p/phase-field-%E7%9B%B8%E5%9C%BA%E6%A8%A1%E6%8B%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-v/Skadi_hu_21f59ab02598ae65.png","permalink":"https://a-moment096.github.io/p/phase-field-%E7%9B%B8%E5%9C%BA%E6%A8%A1%E6%8B%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-v/","title":"Phase Field: 相场模拟学习笔记 V"},{"content":"终于，真的要做相场模拟了。先从最软的柿子，调幅分解开始吧\n简介 所以，经过前面三个部分的学习，利用 C++ 进行相场模拟的所有前置几乎全部获得了：公式推导，编程基础，基础算法等，几乎全都拿到手了。这部分开始，我们就正式开始用 C++ 实现相场模拟。我们先从一个很经典且简单的例子开始：A-B 合金的调幅分解。\n调幅分解 所以什么是调幅分解？它有什么特殊的地方？为什么相场法的第一个例子是算这么个有点陌生的东西？我们一个一个来解答这些问题。\n首先值得明确的是，调幅分解是一类相变过程，且这类过程非常适合使用相场法来计算其演化过程。作为相变，我们自然关心其相图和自由能曲线的情况。下面是一副调幅分解的示意图：\n从图上可以看到，调幅分解下的自由能曲线十分特殊，呈现一种双势阱的形貌。再观察这里的相图和自由能曲线，可以看到虚线部分对应于自由能曲线中比较平坦的区域。没错，这个点即为所谓的拐点（Spinodal Point），这也是调幅分解的英文 Spinodal Decomposition 中 “Spinodal” 的来由。由于调幅分解自由能曲线的特殊性，当自由能对成分的二阶偏导小于 0 时，如果成分正好出于混溶间隙里调幅线内，那么任何一点微小的成分扰动都会导致整个体系的稳定性被破坏，产生的自由能差（即所谓的相变驱动力）将增大并将体系演化至自由能曲线中“谷底”的位置，并形成所谓调幅分解的形貌。\n调幅分解最特殊的地方在于，相场法这个方法几乎可以说是起源于调幅分解过程的。观察调幅分解的自由能曲线，它描述了一个中间态物质由于自身能量最小化的要求从而分散为两个不同组分的物质的过程。这个能量曲线将会是相场法这一计算方法的核心之一，意义在于在给出体系的体自由能描述的情况下，体自由能的最小化将会推动整个体系发生演化。Cahn 和 Hilliard 两人在 Ginzburg-Landau 自由能模型的基础上建立了用来描述调幅分解过程的自由能泛函，并推导出了对这个泛函的演化方程，这个演化方程即为所谓的 Cahn-Hilliard 方程。因此，从调幅分解入手开始了解相场法也许是最理想的选择了。\n模型分析 能量构造 本次我们使用的自由能构造如下：\n$$\r\\begin{align*}\rF \u0026= \\int_\\Omega f_{bulk} + f_{int}\\, \\mathrm{d}\\omega;\\\\\rf_{bulk}\\left(c \\right) \u0026= Ac^2(1-c)^2; \\\\\rf_{int}\\left(\\nabla c \\right) \u0026= \\kappa \\left|\\nabla c \\right| ^2. \\\\\r\\end{align*}\r$$ 其中，$F$ 即为体系的总能量，由两部分的能量密度积分构成，第一部分为体自由能 $f_{bulk}$，其图像为一个双势阱：\n而第二部分则为界面能密度部分，这里采用界面能梯度内积的值。这个能量构造保证了体系有演化的趋势（由体自由能密度驱动），又保证了体系中存在稳定的相界面（由界面能提供，在存在界面区域（梯度不为 0 ）时提高能量从而迫使物质不倾向于汇集在界面处）。这样的总能 $F$ 构造是一类非常经典的构造方法，而能量密度的具体表达式则需要根据体系做更改。\n演化方程 接下来我们分析 Cahn-Hilliard 方程。我们之前有提到这个方程，但是没有仔细分析它。其形式如下：\n$$\r\\frac{\\partial c_i}{\\partial t} = \\nabla\\cdot\\left(M_{ij}\\nabla\\frac{\\delta F}{\\delta c_j}\\right)\r$$值得注意的是，这里括号内的乘积实际上是使用了 Einstein 求和约定 （对，就是那个 Albert Einstein）。这里不做过多解释，大概就是讲要把所有浓度的驱动力都算在一起作为总驱动力然后进行计算。\n那么如何理解这个公式呢？首先我们先搞清楚这个公式里的所有的变量的物理含义。括号内的梯度项应该是各个组分的化学势，而与化学势梯度相乘然后求和的张量 $M_{ij}$ 则是所谓的迁移率矩阵，它是用来平衡各个化学势梯度对体系的贡献的，这时，等式右侧变成了化学势的 Laplacian，从数学上看是一个对空间所有方向求二阶偏导后加在一起的量，可以用来表示空间平直程度或者起伏程度的量。如果 Laplacian 在某点极大，则代表这个点附近的值有极大的变化。考虑到这里计算的是化学势的 Laplacian，如果化学势变化激烈，则它在这一点的 Laplacian 的数值自然会很大。\n经过上面的分析，可以得到一个很初步但很重要的结论：当化学势变化越大时，变量的变化速率越大。这很合理，因为作为相变驱动力而言，浓度或物质的重新分配主要是由于化学势的变化而产生的，物质应该从化学势高的地方流向化学势更低的位置。那么，为什么必须是这样的散度套梯度的形式呢？这主要是因为浓度的守恒性，因为浓度是保守变量，不能随意产生和消失。根据物质守恒定律，有 $$\r\\frac{\\partial c_i}{\\partial t} + \\nabla \\cdot J = 0,\r$$ 其中 $J$ 是浓度流。考察物质流，由于我们一直处于热力学语境下，物质流必须符合热力学定律，即只能从化学势高的区域流向化学势低的区域。这时我们尝试构造出一个形式最简单的，把化学势和物质流相关联的表达式，由于从浓度高的区域流向浓度低的区域这一现象凝聚在某一点时表现为反浓度梯度，再考虑到要求形式最简，我们能想到的最简单的形式即为： $$\rJ = - \\nabla \\frac{\\delta F}{\\delta c}.\r$$ 但是考虑到体系内可能存在多种物质，这些物质对化学势均有贡献，反过来所有的化学势都会对某一单一成分组元的演化情况产生影响，因此应该考虑所有的化学势的影响。然后由于不同物质的化学势贡献存在不同，我们使用 $M_{ij}$ 来对这些贡献进行配平。由此，我们便拼凑出了上面的 Cahn-Hilliard 方程。上面的分析和推导过程参考了 这篇 Review 和 这篇博文。\n那么，顺着这个思路，要是不要求物质守恒，那么最简形式是什么样的呢？答案已经呼之欲出了，那就是下一节会提到的 Allen-Cahn 方程。也许有人发现，可以把这两个方程与扩散方程做比较。这些内容放在下一个部分吧，要不然没字数水了（）\n问题分析 我们希望能模拟出调幅分解的过程，在二维条件下可以创建一个模拟域，规定其长宽后在其上每一个点赋予一个浓度 $c$，然后在每个点随机添加噪音来让初始浓度出现一个微小波动。随后我们便可以根据前面所列出的能量以及演化方程来演化该模拟域。考虑到该模拟需要保持物质守恒，我们采用周期性边界条件，即让最右端的点在取其右侧的点的时候反取到最左端的点，而最底端的点取其下方点时取到最上端的点，等。我们先从浓度 $c = 0.4$ 开始，考虑噪音大小为 $0.001$，处理边界条件时使用下标运算来保证获取的是在周期边界条件下的点。\n这里我们再推导一下前面用到的公式，将能量带入演化方程直接获得迭代浓度场所需要的表达式。 $$\r\\frac{\\partial c}{\\partial t} = M \\nabla^2\\left( 2Ac(1-c)(1-2c)-\\kappa\\nabla^2c\\right)\r$$根据这个公式，我们需要先计算浓度的 Laplacian，然后计算出化学势后，计算括号内整体的 Laplacian，最后使用向前欧拉法迭代到浓度上。这里我们取用一些简单的值来进行计算，取 $A = 1.0$，$M = 1.0$，$\\kappa = 0.5$。然后考虑离散步长，取 $\\Delta t= 0.01$，$\\Delta x= 1.0$。\n代码实现 下面直接一口气给出所有的代码：\n1#include \u0026lt;filesystem\u0026gt; 2#include \u0026lt;fstream\u0026gt; 3#include \u0026lt;iostream\u0026gt; 4#include \u0026lt;string\u0026gt; 5#include \u0026lt;vector\u0026gt; 6 7void write_vtk(std::vector\u0026lt;std::vector\u0026lt;double\u0026gt;\u0026gt; mesh, std::string file_path, int time_step, double dx) { 8 std::filesystem::create_directory(file_path); 9 std::filesystem::path f_name{\u0026#34;step_\u0026#34; + std::to_string(time_step) + \u0026#34;.vtk\u0026#34;}; 10 f_name = file_path / f_name; 11 12 std::ofstream ofs{f_name}; 13 size_t Nx{mesh.size()}, Ny{mesh.at(0).size()}; 14 15 ofs \u0026lt;\u0026lt; \u0026#34;# vtk DataFile Version 3.0\\n\u0026#34;; 16 ofs \u0026lt;\u0026lt; f_name.string() \u0026lt;\u0026lt; std::endl; 17 ofs \u0026lt;\u0026lt; \u0026#34;ASCII\\n\u0026#34;; 18 ofs \u0026lt;\u0026lt; \u0026#34;DATASET STRUCTURED_GRID\\n\u0026#34;; 19 20 ofs \u0026lt;\u0026lt; \u0026#34;DIMENSIONS \u0026#34; \u0026lt;\u0026lt; Nx \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; Ny \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; 1 \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; 21 ofs \u0026lt;\u0026lt; \u0026#34;POINTS \u0026#34; \u0026lt;\u0026lt; Nx * Ny * 1 \u0026lt;\u0026lt; \u0026#34; float\\n\u0026#34;; 22 23 for (size_t i = 0; i \u0026lt; Nx; i++) { 24 for (size_t j = 0; j \u0026lt; Ny; j++) { 25 ofs \u0026lt;\u0026lt; (double)i * dx \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; (double)j * dx \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; 1 \u0026lt;\u0026lt; std::endl; 26 } 27 } 28 ofs \u0026lt;\u0026lt; \u0026#34;POINT_DATA \u0026#34; \u0026lt;\u0026lt; Nx * Ny * 1 \u0026lt;\u0026lt; std::endl; 29 30 ofs \u0026lt;\u0026lt; \u0026#34;SCALARS \u0026#34; \u0026lt;\u0026lt; \u0026#34;CON \u0026#34; \u0026lt;\u0026lt; \u0026#34;float 1\\n\u0026#34;; 31 ofs \u0026lt;\u0026lt; \u0026#34;LOOKUP_TABLE default\\n\u0026#34;; 32 for (size_t i = 0; i \u0026lt; Nx; i++) { 33 for (size_t j = 0; j \u0026lt; Ny; j++) { 34 ofs \u0026lt;\u0026lt; mesh.at(i).at(j) \u0026lt;\u0026lt; std::endl; 35 } 36 } 37 38 ofs.close(); 39} 40 41void energy_curve(std::vector\u0026lt;double\u0026gt; f_list, double kappa, std::string file_path, int pstep) { 42 std::filesystem::create_directory(file_path); 43 std::filesystem::path f_name{\u0026#34;energy_time.csv\u0026#34;}; 44 f_name = file_path / f_name; 45 46 std::ofstream ofs; 47 ofs.open(f_name); 48 ofs \u0026lt;\u0026lt; \u0026#34;time\u0026#34; \u0026lt;\u0026lt; \u0026#34;,\u0026#34; \u0026lt;\u0026lt; \u0026#34;value\\n\u0026#34;; 49 for (size_t i = 0; i \u0026lt; f_list.size(); i++) { 50 ofs \u0026lt;\u0026lt; i * pstep \u0026lt;\u0026lt; \u0026#34;,\u0026#34; \u0026lt;\u0026lt; f_list.at(i) \u0026lt;\u0026lt; std::endl; 51 } 52 ofs.close(); 53} 54 55double laplacian(double cl, double cr, double cd, double cu, double cc, double dx) { 56 return (cl + cr + cd + cu - 4.0 * cc) / (dx * dx); 57} 58 59double df_dc(double mu, double kappa, double lap_c) { 60 return mu - kappa * lap_c; 61} 62 63double chem_potential(double A, double c) { 64 return 2.0 * A * (c * (1 - c) * (1 - c) - c * c * (1 - c)); 65} 66 67double chem_energy(double A, double c) { 68 return A * c * c * (1 - c) * (1 - c); 69} 70 71double F_total(std::vector\u0026lt;std::vector\u0026lt;double\u0026gt;\u0026gt; mesh, double kappa, double A) { 72 double energy{0}; 73 74 for (size_t i = 0; i \u0026lt; mesh.size() - 1; i++) { 75 for (size_t j = 0; j \u0026lt; mesh.at(0).size() - 1; j++) { 76 double cc = mesh.at(i).at(j); 77 double cr = mesh.at(i + 1).at(j); 78 double cu = mesh.at(i).at(j + 1); 79 80 energy += (cr - cc) * (cr - cc) * kappa / 2.0; 81 energy += (cu - cc) * (cu - cc) * kappa / 2.0; 82 energy += chem_energy(A, cc); 83 } 84 } 85 return energy; 86} 87 88const int Nx = 64; 89const double dx = 1.0; 90const double dt = 0.01; 91const int nstep = 10000; 92const int pstep = 50; 93const double c0 = 0.4; 94const double mobility = 1.0; 95const double kappa = 0.5; 96const double A = 1.0; 97 98int main() { 99 100 std::vector\u0026lt;std::vector\u0026lt;double\u0026gt;\u0026gt; mesh(Nx, std::vector\u0026lt;double\u0026gt;(Nx, 0)); 101 for (int i = 0; i \u0026lt; Nx; i++) { 102 for (int j = 0; j \u0026lt; Nx; j++) { 103 mesh.at(i).at(j) = c0 + (double)(100 - rand() % 200) / 1000.0; 104 } 105 } 106 std::vector\u0026lt;double\u0026gt; F_time_curve{}; 107 108 auto df_dc_mesh{mesh}; 109 110 for (int istep = 0; istep \u0026lt; nstep + 1; istep++) { 111 for (int i = 0; i \u0026lt; Nx; i++) { 112 for (int j = 0; j \u0026lt; Nx; j++) { 113 int im = i - 1; 114 if (im == -1) 115 im = Nx - 1; 116 int ip = i + 1; 117 if (ip == Nx) 118 ip = 0; 119 int jm = j - 1; 120 if (jm == -1) 121 jm = Nx - 1; 122 int jp = j + 1; 123 if (jp == Nx) 124 jp = 0; 125 double cl{mesh.at(im).at(j)}; 126 double cr{mesh.at(ip).at(j)}; 127 double cd{mesh.at(i).at(jm)}; 128 double cu{mesh.at(i).at(jp)}; 129 double cc{mesh.at(i).at(j)}; 130 131 df_dc_mesh.at(i).at(j) = df_dc(chem_potential(A, cc), kappa, laplacian(cl, cr, cd, cu, cc, dx)); 132 } 133 } 134 for (int i = 0; i \u0026lt; Nx; i++) { 135 for (int j = 0; j \u0026lt; Nx; j++) { 136 int im = i - 1; 137 int ip = i + 1; 138 int jm = j - 1; 139 int jp = j + 1; 140 if (im == -1) 141 im = Nx - 1; 142 if (ip == Nx) 143 ip = 0; 144 if (jm == -1) 145 jm = Nx - 1; 146 if (jp == Nx) 147 jp = 0; 148 double df_dc_l{df_dc_mesh.at(im).at(j)}; 149 double df_dc_r{df_dc_mesh.at(ip).at(j)}; 150 double df_dc_d{df_dc_mesh.at(i).at(jm)}; 151 double df_dc_u{df_dc_mesh.at(i).at(jp)}; 152 double df_dc_c{df_dc_mesh.at(i).at(j)}; 153 154 mesh.at(i).at(j) += dt * mobility * laplacian(df_dc_l, df_dc_r, df_dc_d, df_dc_u, df_dc_c, dx); 155 } 156 } 157 if (istep % pstep == 0) { 158 write_vtk(mesh, \u0026#34;./result\u0026#34;, istep, dx); 159 F_time_curve.push_back(F_total(mesh, kappa, A)); 160 } 161 } 162 energy_curve(F_time_curve, kappa, \u0026#34;./result\u0026#34;, pstep); 163} 这里再简单介绍一下 write_vtk 函数，这个函数参考 VTK 文件的标准，每个 pstep 步之后便输出一次 vtk 文件。其中的文件格式使用 std::fstream 来控制输入。\n结果 输出的 vtk 文件需要使用 Paraview 进行可视化。如果程序无误，那么执行程序后输出的结果将会保存在程序所在文件夹下新创建的子文件夹 result 中，里面应该是若干个 vtk 文件。使用 Paraview 打开这些文件之后，则能看到整个体系的演化。这里贴出一些截图。\n第5步 第25步 第75步 第150步 总结 这部分内容相对而言应该是比较少的，因为只要分析好了所使用的能量模型，理解使用的演化方程之后，剩下的工作几乎全都是不断调试，根据调试的结果来观察不同的参数会对模拟结果造成什么样的影响。这里提供几个调参思路吧：\n调整时空间步长。求解结果应该会随着两者的变大而变大 调整扩散速率（迁移率），更高的扩散速率会让相聚集会变得更迅速 调整自由能函数的参数，越强的势阱会让相分散更加迅速且边界更分明 调整初始浓度 调整界面能参数。越大的界面能参数会导致越宽的相界面。而该参数太小时可能会发生数值不稳定的现象 可以参考这些描述调参，观察参数的影响。调参几乎是相场模拟中必不可少的一环。\n那么，我们就下一节见吧。\n","date":"2024-12-24T00:00:00+08:00","image":"https://a-moment096.github.io/p/phase-field-%E7%9B%B8%E5%9C%BA%E6%A8%A1%E6%8B%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-iv/Skadi_hu_21f59ab02598ae65.png","permalink":"https://a-moment096.github.io/p/phase-field-%E7%9B%B8%E5%9C%BA%E6%A8%A1%E6%8B%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-iv/","title":"Phase Field: 相场模拟学习笔记 IV"},{"content":"接上一节内容, 这节会简单介绍 C++ 的一些语法知识, 然后用 C++ 实现一维传热方程的模拟。\nC++：一门高效的，适宜科学计算的程序语言 C++ 是一门经典的编程语言，于 1979 年由 Bjarne Stroustrup 设计，最初目的是为了成为更好的 C 语言，而后随着自身发展，成为了一门和 C 语言有许多相似之处，而又截然不同的一门语言。 C++ 支持多种编程范式，包括但不限于面向过程，面向对象，函数式，模板元编程等等。 其丰富的生态，高效的算法库以及零成本抽象的理念让 C++ 极为适合进行各类科学运算。此外，C++ 的语法较为亲民，其多种编程范式也便于不同背景的开发者上手，故我们在这里引入 C++ 作为后续计算使用的程序语言。\nC++ 简介 首先，我们对 C++ 的一些基础概念做出简单的介绍。这些概念你也许在上节中已经遇到过来，这里再做出进一步的解释。\nC++ 编译器 C++ 作为一门语言，当谈起 C++ 编程时，实际上我们只是书写了以 C++ 的格式书写的代码，而将这些代码翻译为机器能够阅读并执行的程序，需要许多道不同的工序。幸运的是，编译器（compiler）可以近乎一步到位地帮助我们完成这个过程。C++ 历史悠久，自然发展有多种编译器来编译源代码。这里列举其中三个较为知名的编译器（工具链）：\nGNU Compiler Collection (GCC) 以及 G++：来自 GNU 基金会的开源老牌编译器工具集合，其中用以编译 C++ 的编译器为 G++。G++ 编译器几乎是 Linux 平台的标准编译器，而 Windows 平台可以考虑使用一些迁移工程，如 Cygwin， MSYS2 或 MinGW（Minimalist GNU for Windows）。其链接器为 ld，调试器为 gdb。 Microsoft Visual C++ (MSVC)：微软开发的 C++ 编译器工具，除了编译 C++ 外还兼职编译其他的一些代码，如 C 等。其命令行工具名为 cl.exe，但只能通过微软的开发者命令行调用。使用 MSVC 的一般方式为使用微软开发的 IDE。其链接器为 LINK.exe，调试器为 vsdbg.exe。 Clang++ / LLVM：LLVM 组织开发的一款模块化的现代编译器工具集合，其中用以编译 C++ 的编译器前端为 Clang++。 Clang++ 为 MacOS 系统默认的编译器。当然也可以安装在 Windows 平台或 Linux 平台上。其链接器为 lld， 调试器为 lldb。 以上三款编译器近乎最受欢迎的 C++ 编译器，当然也有一些其他的 C++ 编译器，但由于不同编译器对语言的实现可能有所不同，依旧是建议没有特殊需求的开发者采用三大主流编译器编译 C++ 代码。 编译器负责将源码编译为二进制文件，而链接器（linker）则负责将不同的二进制文件按照要求链接起来，形成一个单独的二进制文件。调试器（debugger）则负责读取符号表后对二进制文件进行逐行运行与调试。至于编译器的前端，后端以及其具体运行超出了单纯运用的范围，这里不深入介绍（其实笔者也不太懂）。\n这里同时也稍微提一下 编译器，编辑器，解释器 和 IDE 的区别。其中，解释器我们已经在 Python 中遇到过，它负责将 Python 代码逐行解释给机器并令机器执行。其属于广义上的编译器，即将源代码（文本）转化为机器能识别的指令等的程序。而狭义的编译器则指将文件整体处理并编译为二进制文件的程序。由于 C++ 的执行必须先编译为二进制文件，故其编译器是必不可少的。编译器则与前两者完全区分开，是编辑文字的工具。常见的编辑器如 Windows 上的记事本，Linux 上常用的 Eamcs，Vim，较为现代的 VSCode 等。 经常与编辑器搞混的概念则为IDE。IDE是指集成开发环境（Integrated Developing Enviroment），其兼具编辑器与编译器的功能，可以在其中编辑代码并编译为二进制文件后运行，且通常具有别的功能，如断点调试等等。 这些概念是有一定区分的必要的，否则容易造成误解。\nC++ 编译链接 理解 C++ 的编译过程与链接过程对正确运用编译器编译 C++ 代码是必要的。这里不会过分深入，旨在介绍大致过程，以免出现一些常见问题（如找不到符号定义等）。\n在编译过程中，编译器会首先将所有的源文件（通常后缀为 .cpp, .cxx 等）按照要求编译为相对应的对象文件（Linux 上为 .o 文件，Windows上为 .obj 文件），并留下没有实现但是已经声明过的函数、类等，等待链接器链接至对应位置的静态或动态库。随后链接器将执行链接，即将对象文件，外部静态库（ Static Library, Linux上的 .o 或 Windows 上的 .lib 文件）和外部的动态库（Shared Object 或 Dynamic Library，Linux上的 .so 或 Windows 上的 .dll 文件）链接至一起形成一个二进制文件。其中，静态库将和程序生成的对象文件合并到一起形成一个文件，动态链接库则不被合并到文件中。因此，使用动态链接库可以减少重复代码，降低程序的大小。随后在运行该程序时，当程序需要外部链接库中定义的内容时，操作系统将按照一定的顺序寻找动态链接库，并找到其中的定义然后执行。当没能找到动态链接库时，程序便会报出“未定义的符号 XXX”的错误。一般程序会到环境变量中的位置寻找动态链接库，随后在程序所在文件夹下寻找动态库。如果用到了动态链接库，请注意让程序能找到动态库，否则无法成功运行。\n上面仅为简单的介绍，其中编译过程还可以细分为若干步，链接过程也可以分为若干步骤。这里不再介绍。但是需要指出的是：编译过程中，根据编译的类型，会对代码进行不同程度的优化。常见的所谓 Release 版本即为打开所有优化选项，且不生成/加载符号表的程序版本，其程序体积小，运行速度快，但通常无法调试（因为缺少符号表）。与之对应的 Debug 版的优化则较少，但其含有的符号表可以在调试过程中逐步运行代码并查看变量值。编译程序时请注意这些区别。\n调试器与调试 调试器通常是一类独立的程序，其可以运行编译链接完成的可执行程序，并且加载程序对应的符号表后可以逐行运行程序。调试器还支持断点，在特定位置暂停程序的运行，并且显示当前位置程序中加载的变量和函数调用栈等。调试器的出现极大地方便了程序的调试，可以方便定位程序中存在的问题并做出修改，以编写出更加符合要求的代码。\n调试器常常拥有自己的界面，可以独立运行，然而目前常见的使用方式是使用一些外部程序调用调试器，捕获其输出并传递输入的参量，以便与源代码进行对照。常见的 IDE 均有此功能，而一些编译器经过合理的配置之后，也可以调用调试器进行使用。通常的调试过程为：添加断点，逐步运行，查看变量/修改变量值，步入函数/步出函数等。调试过程中可以多加探索。\nC++ 环境搭建 如果您使用 Windows 平台，最简单的方法即为考虑微软旗下的 Visual Studio。作为一款成熟的 IDE，Visual Studio 可以在简单的了解其操作之后便将注意力集中在编程解决问题本身而非工具的使用。只需要在官网下载 Visual Studio 的下载器，在下载器界面内选择 C++ 桌面开发的组件，便可以在安装后创建一个解决方案+一个项目，并在左边资源管理器中新建一个 C++ 源文件后开始编写程序了。所有的编译器选项等等都可以通过项目属性来管理配置。如果需要在 Windows 平台上编写大型程序的话，Visual Studio 近乎是 Windows 平台的不二之选。\n不过如果只需要编译运行单个 C++ 文件，又或者 Visual Studio 太过笨重，不适合您的电脑环境的话，可以考虑使用 MinGW-w64 或者 MSYS2 中的编译器与 C++ 运行时。在写好 C++ 源文件之后， 像在 Linux 环境下一样调用 g++ 命令编译源文件，即可得到可执行的程序。除了在 Windows 上模拟 Linux 环境外，还可以考虑使用 WSL 来创建本地的轻量化 Linux 子系统，登录到子系统后就相当于打开了 Linux 虚拟机，此时便可在 Linux 环境下安装编译所需要的工具链并进行编译了。\n由于所谓源代码仅为有一定格式的文本文件，故而您可以使用任何喜欢的文本编辑工具来编写源代码。然而好的编辑器可以辅助编写，特别是代码高亮，自动补全，调用编译器等功能可以极大地方便代码编写。这里推荐使用 VSCode，其丰富的插件生态可以在安装好编译器与对应插件的情况下提供良好的代码高亮，定义跳转，自动补全的功能，且可以编译 C++ 源文件并调试/执行。具体内容由于 VSCode 提供了详尽的文档，这里不再赘述。\nC++ 标准 作为一门发展良久的语言，C++ 经历了数次版本迭代，也因此拥有多个语言版本。根据 ISO 的标准，C++ 委员会将对语言特性，语法规则等进行调整，对语言库做出提案，并由各大编译器厂商进行实现。不同的编译器厂商可能会采用不同的实现方式，且不同的编译器可能会添加不同的扩展，故而非标准的 C++ 代码可能需要根据平台和编译器进行编译。而当源码采用的标准与编译器标准不同时，也常常会出现编译错误。所以在编写/编译源文件时应明确采用的 C++ 标准。目前业界常用的且拥有广泛编译器支持的 C++ 标准为 C++14，但该标准较为老旧，缺少很多便利的库函数等。可以考虑使用 C++17 或者 C++20 标准以方便使用。本教程使用 C++17 标准。请注意 Visual Studio 默认的 C++ 标准为 C++14，如有必要请在项目属性中修改 C++ 标准。\nC++ 语法基础 经过上面的介绍，相信您已经对 C++ 所配套的工具和其必要的信息已经有所了解，而到目前为止，我们还没有介绍 C++ 具体的语法。那么我们接下来便开始 C++ 语法的介绍。\n注释，头文件和 #include 程序通常都有注释。C++ 中的单行注释以 // 开始，让编译器忽略一行中 // 后的所有内容。 而多行注释（或者更准确地说，范围注释）则是以 /* 开始，以 */ 结束。简单更改程序时，单行注释很常用，而多行注释常用来书写大段说明性的文字，特别是版权信息等。\n打开一个 C++ 文件，首先看到的常常是各种 #include 开头的若干行。在 C++ 中，当需要使用外部的内容时（如，函数，类等），通常使用 #include 预处理命令来将对应库的头文件引入该文件。比如需要使用标准库的输入输出流时，则需要在源文件中使用 #include \u0026lt;iostream\u0026gt;。而在使用自建库时，通常使用冒号 \u0026quot;\u0026quot; 而非尖括号 \u0026lt;\u0026gt; 来引入头文件。\n所谓头文件，通常指以 .h 结尾的 C++ 代码，其中声明了一些函数或者类等，也可以在头文件中实现这些函数/类。在引入头文件后，便可以使用头文件中定义的名称，作用类似于 Python 中的 import，但更为原始一些，因为 #include 会令编译器直接将对应文件复制粘贴到对应位置。\n标准库的头文件常常与标准库相关联，所谓标准库，是指 C++ 标准所提供的一系列函数，类，函数模板以及类模板等内容。上面的 iostream 便是一个例子。 标准库非常地多，当有需要时请自行搜索是否存在已有的库可以满足需求。\nmain 函数和小例子 对 C++ 程序而言，一个可执行文件必须要包含一个 main 函数作为程序的主入口。当程序执行时，会从 main 函数开始执行，并且逐行向下。一个 C++ 程序只能拥有一个程序入口，意即 main 函数。下面是一个简单的例子：hello_world.cpp\n1#include \u0026lt;iostream\u0026gt; 2 3int main(){ 4 std::cout\u0026lt;\u0026lt;\u0026#34;Hello C++ world!\u0026#34;\u0026lt;\u0026lt;std::endl; 5 return 0; 6} main 函数拥有以下几个特点：\nmain 函数必须拥有 int 返回值类型 main 函数的参数列表可以为空，也可以有两个参数：一个整值类型用以表示接受参数的个数，一个字符串数组/指针/容器用以存储接受的参数。 main 函数成功执行时应返回 0。标准允许不写返回值，默认返回 0。 main 函数除了作为程序入口以外，本身也是一个满足 C++ 语法的函数。我们后面会看到 main 函数作为函数的几个要素。\n变量类型 C++ 和 Python 最大的区别中，其中一个便是所有的变量具有静态类型（别的区别还有不需要代码缩进表示代码块等等）。在 C++ 中，声明变量需要首先声明变量的类型，然后是变量名。可以（也推荐）在声明变量时给变量初始化，通常只需在变量名后用等号 = 接上需要赋予的值即可。也可以通过初始化列表进行变量初始化，且对于类而言还可以使用合适的类构造函数进行变量初始化。下面是一个例子：\n1#include \u0026lt;vector\u0026gt; 2#include \u0026lt;string\u0026gt; 3int main(){ 4 int i = 0; 5 double j; 6 int k {1}; 7 bool yes = false; 8 9 std::vector\u0026lt;double\u0026gt; vd {0.1,0.2,0.4}; 10 std::string str = \u0026#34;I\u0026#39;m a string!\u0026#34;; 11} 为了简化内容，我们只介绍 int，double，bool，string 和 vector 五种类型，他们分别代表有符号整数，双精度浮点数，布尔值，字符串和向量。其中前三种是 C++ 的内置变量类型，在计算过程中常用到；后两者需要引入对应的头文件才能使用。这里有以下几点需要注意：\n变量不进行初始化时请不要使用。可能会带有垃圾数据。如上面示例中的 double j 并没有对变量 j 进行初始化，里面可能存有任何错误的数据，需要在初始化之后使用。 变量可以使用大括号 {} 进行初始化，称为初始化列表。该方式对多个数据的组合变量较为常用。 使用标准库内的变量/类/函数时，如果没有使用 using namespace std; 进行全局获取名称，请使用 std:: 来告诉编译器该名称的位置。 这里不介绍命名空间的内容。 对于 vector 这种类模板，请在后面的尖括号中指明容器中数据的类型。如上的 std::vector\u0026lt;double\u0026gt; 意即声明一个内部变量类型为 double 的容器类 vector。 字符串以双引号\u0026quot;开头，以双引号\u0026quot;结尾。 请勿使用全角字符，C++ 文本使用半角字符作为其符号。 变量命名不能以数字开头，可以包含数字，下划线和英文字母。 请注意，C++ 是严格类型语言。 当类型不匹配（且自动类型转换失败）时编译器会报错，在存在自动类型转换的情况下编译器可能会警告。请尽量不要让类型做自动转换，如使用 double 将整数变量强行转化为小数等。\n作用域 和 Python 相似，C++ 也有变量作用域的概念。在 C++ 中，代码块使用花括号（大括号）来区分，代码块可以嵌套于代码块内。代码块内的变量可以获取代码块外变量的信息，但代码块外的变量无法获取代码块内的信息。变量在离开自己定义位置所在代码块时，如果没有特殊情况，将会自动销毁。使用循环，判断语句以及声明函数时使用的花括号也是一个作用域。下面是一个小例子：\n1int main(){ 2 int i = 0; 3 { 4 int j = 1; 5 i = 888; // success 6 } 7 // i will be 888 here 8 9 // Below is an error: 10 // j = 666; 11} 控制流，循环和判断语句 首先介绍循环语句。这里仅介绍 for 循环与 while 循环。下面是使用 for 和 while 循环的例子。\n1for (int i = 0; i \u0026lt; 10; i ++){ 2 std::cout\u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; 3} 4 5{ 6 int j = 0; 7 while (j \u0026lt; 10){ 8 std::cout\u0026lt;\u0026lt; j \u0026lt;\u0026lt; std::endl; 9 j += 1; 10 } 11} 这两个循环都会将数字从 0 打印至 9，且其语法特征是完全相同的。其中 for 循环圆括号内第一项为循环前语句，会在循环开始前执行，常用来声明并初始化循环变量；第二项为循环条件，满足条件则继续循环；第三项为循环末尾语句，在执行完循环体内语句后将执行第三项中的语句。而 while 循环则显得简单很多：只要满足括号内的语句条件便可以一直进行下去。 请注意下面的循环在套上一层代码块后才能与上方等同。换句话说，在 for 循环括号中定义的变量时临时变量，在离开循环后将会自动销毁。另外值得注意的是，for 循环的括号内是三个语句，使用分号 ; 分割，而非逗号 ,。另外，判断条件实际上是一个表达式，当表达式值为 true 时则继续循环，为 false 则停止。\n这里再介绍一下所谓的 range for 循环。当存在一个不变长的容器式的变量时，可以通过：\n1for (auto rep_elem in container){ 2 /* xxx */ 3} 这样的语法来用 rep_elem 依次从前向后地取用所有的元素，以此完成循环。\n判断语句这里仅介绍 if-else 语句。下面是一个例子：\n1if (3 \u0026gt; 4){ 2 std::cout\u0026lt;\u0026lt; \u0026#34;false\u0026#34; \u0026lt;\u0026lt; std::endl; 3} else if (3 \u0026lt; 4) { 4 std::cout\u0026lt;\u0026lt; \u0026#34;yes\u0026#34; \u0026lt;\u0026lt; std::endl; 5} else { 6 std::cout\u0026lt;\u0026lt; \u0026#34;?\u0026#34; \u0026lt;\u0026lt; std::endl; 7} 其语法特性一目了然，这里不再赘述。\n另外要介绍的是 break 和 continue 控制命令。当循环遇到 break 命令时将会立刻停止循环，而当执行到 continue 时则会结束本次循环，进入到下一次循环。对于嵌套循环，break 和 continue 只负责当前循环的控制，不会控制父循环。\n函数 C++ 中的函数包含五个要素：返回值类型，函数名，参数列表，函数体，返回值。下面是一个例子：\n1double my_add(double a, double b){ 2 return a+b; 3} 这里我们声明了一个函数：返回值类型为 double，函数名为 my_add，参数列表中接受两个 double 类型的参数。这三个要素即可声明一个函数的存在。后面的函数体和返回值则是对该函数的实现方法，这里只做了一件事，即返回了参数列表中两个值的和。\n这里要提出的是，C++ 中的函数允许不返回值，此时返回值类型为 void；函数也可以不接受任何参数，这时只需空置参数列表即可，但是圆括号是必须的。我个人建议声明函数时即将函数做出定义，但是在有必要时，可以列出声明后在另外的地方做出函数定义，例如将声明放在头文件中，函数定义则放在一个源文件中。\n另外，在这里我尝试提出另一种理解函数的方式：提供了对外通道的独立代码块。这个代码块可以把外部的数值通过参数列表交换给代码块内部，而后从代码块内部返回一个结果交给代码块外部。在需要使用该代码块时，只需使用代码块的名称即可。此外需要注意的时，在使用函数时，像上面例子所定义的函数是无法改变外部数据值的。可以理解为代码块内部的所有内容都独立于其他部分，不会对接外部的上下文，只会根据传入的数据进行处理。如果需要改变外部数据，则需要在参数列表中传入指针或者引用，这两个概念会在下一个部分介绍。\n最后要提出的是，函数允许递归调用，即函数调用自己。通过递归调用，可以将复杂的逻辑用较为简单的代码实现。C++ 函数还允许重载，即同一个函数名通过参数列表的不同来让编译器自动区分调用的是什么函数。请注意，仅返回值不同是无法区分的，只有参数列表才能让编译器对同名函数做出区分。也许可以考虑将参数列表纳入“函数名”的一部分，这可以为所谓的函数指针带来一定的解释，但可能有一些问题？所以仅供参考。\n指针 我们这里不会介绍指针太复杂的内容，仅对指针最基本的用法以及其背后（可能）的思想做出大致介绍。在介绍指针之前，有必要先简单介绍 C++ 语言下的内存逻辑。\n在程序运行过程中，由操作系统所管理的程序内存可以根据代码中的内容而区分为两个部分：堆和栈。其中的栈实际上是一种数据结构，指先入后出的队列，但这里我们只把它理解为一个由程序直接管理的内存。这些内存（比如某些变量）会由代码创建后存在栈上，当该程序的变量脱离某个部分时，由于变量的生存周期便会从栈上弹出销毁。这带来了一些好处，让程序的所有内存都得到恰当的管理，但是操作系统能分配给程序的栈空间大小是有限的，当栈空间不足以储存所有变量时，程序便会报出栈溢出的错误。\n为了解决这样的痛点，程序允许和操作系统沟通，拿到不直接属于程序栈空间内的内存。拿到的这些内存就保存在堆上，而声明或使用这些内存则可以使用指针来取得。需要注意的是，虽然堆空间很大，但是堆空间由于数据散乱，其速率可能不如栈上的内存；另外，即便空间很大，不加限制的创建内存且不加销毁，特别是运行时间较久的时候，程序可能会用光所有的内存，此时便会造成所谓的内存泄漏。由于使用堆上数据近乎只能依靠指针，所以使用指针时需要格外注意，特别是内存的释放。\n那么指针到底是什么？我们提取上面所给出的一些信息：指针需要能够获得堆上的内存，C++ 是强类型语言，需要使用指针获取并管理堆上内存。如果考虑 C++ 可以通过内存的地址管理内存，那么答案就呼之欲出了：指针，实际上是一种特别的变量。它会记录一个地址，并记录上这个地址下的数据的类型（同一数据，在不同类型解释下会给出不同的值，比如 0 在 int 下就是数字0，而在 bool 下则会解释为 false，所以指针的类型（大部分情况下）是必须的），随后在使用该地址内所存储的数据时，只需要对指针解引用便可以获得该值。下面是一个例子来说明如何声明指针，以及如何获取变量的地址：\n1int i = 0; 2int *p = \u0026amp;i; 3 4// Output i\u0026#39;s address 5std::cout\u0026lt;\u0026lt;p\u0026lt;\u0026lt;std::endl; 6 7// Modify i\u0026#39;s value 8*p = 1234; 9std::cout\u0026lt;\u0026lt;i\u0026lt;\u0026lt;std::endl; //1234 上面的例子中，我们先声明了（栈上）的一个变量 i，随后用 int * 作为数据类型名声明了一个指针 p，并用 \u0026amp;i 取得 i 的地址，然后给这个变量 p 赋予了 i 的地址的值（称为指针p指向i）。此时输出 p 的值时会打印出一些十六进制数字。之后，通过 * 运算符，取出了保存在 p 中的地址下存储的值，并直接对该内存地址覆写数据 1234。由于 p 保存的地址正是 i 的地址，所以对 i 的地址写入新数据即为给 i 重新赋值。这样一来，输出 i 的值时，得到的结果即为 1234。\n希望这个例子以及这里的简单介绍能帮助你理解指针是什么以及有什么作用。值得注意的是，这里指针指向的变量依旧是一个栈上的变量，而在很多需要使用指针的情况下，需要的常常是堆上的数据。为了在堆上创建变量，需要使用 new 关键字。而当在堆上创建变量后，如果不再使用变量时，必须使用 delete 关键字删除该变量。其主要原因是，当我们声明指针时，通常都是在栈上创建的数据；作为一个栈上的变量而言，当指针变量离开其作用域时便会被销毁。如果只有一个指针指向某个内存空间时，销毁该指针之后，内存中的数据便没有别的办法取到；而此时由于通过 new 创建了这个内存，操作系统会一直保留这个内存直到 delete 删除该内存，或者程序退出由操作系统销毁所有内存。这样一来，只 new 不 delete，当数据量较大时便会造成严重的内存泄漏；此外只 new 不 delete 还会把数据暴露在外，造成安全风险。然而要是使用了两个指针指向同一个内存时，如果在一个指针上销毁了内存，而另一个指针仍然认为内存没有销毁，那么该指针便会称为野指针，或者悬空指针。这时，当尝试使用该指针时，程序便会出错，轻则报错退出，重则产生难以排查的奇怪问题。\n上面这么一大段，其最终目的只为了说明一件事：请不要轻易使用指针。指针很好用，但是 C++ 中也提供了别的很多更友好的方式来管理并使用内存。一旦使用裸指针又不小心忘记删除或者出现空指针，程序便会出现很多奇怪的问题。所以，对自己技术没有绝对自信时，请不要轻易使用指针。\n最后我们提出如何使用指针来帮助函数改变外部变量的值：通过指针传入参数时，虽然函数无法改变参数的值，但是由于参数传入的指针指向的内存空间不会受到影响，所以可以在函数内部给传入的指针内保存的地址下的变量赋值，从而绕开函数的限制。然而，为了达成这一目的，有一种更加安全，且更加便于理解的方式：引用。\n引用 与指针相比较而言，引用就显得更加和蔼一些了，简单来讲，声明一个引用也就是声明了一个变量的别名。我们先看一个例子：\n1int i = 0; 2int \u0026amp;ri = i; 3 4std::cout\u0026lt;\u0026lt;ri\u0026lt;\u0026lt;std::endl; 5 6ri = 5678; 7std::cout\u0026lt;\u0026lt;i\u0026lt;\u0026lt;std::endl; //5678 这里我们首先声明了一个变量 i，然后创建了一个引用 ri 作为 i 的别名。这样一来，我们对 ri 所做出的任何操作（应该）都是相当于对 i 本身所做出的。当 i 被销毁时，变量 i 和它的引用 ri 会一起消失。和指针相比，引用显然要安全的多。但是与此同时，引用也有一些限制：引用不能改变它引用谁。一旦引用被创建，引用本身和引用所指向的内容就绑定死了。此外，由于引用别名的特性，引用不可能存在空引用，这也就要求了引用的“声明”必须立刻对其初始化，且一经初始化就不可改变。所以这里不应该使用“声明”，“赋值”等描述这一过程，最恰当的描述即为“初始化”。\n值得注意的时，引用，和指针类似，也可以作为函数参数传入函数内部。当作为函数参数把引用传入函数内部时，引用的“别名”特点依旧保持，函数内对参数的改变依旧会反映在函数外部。一种理解方式是，函数参数列表的默认传参方式是把参数的值复制一份，生成一个临时变量，然后使用该变量；指针传参时把指针的地址复制了一份，然后使用该临时地址可以在不改变地址的情况下改变地址内部的数据；引用传参时，创建了一个临时的引用，由于引用的特性，函数对引用的影响就相当于对变量本身的影响。\n总之，引用在 C++ 中是更加推荐的使用方式。当然，引用也有别的限制。引用由于终究是变量的“别名”，不会改变变量的内存布局，所以不存在“引用数组”这一数据结构。同时，也不会出现引用的引用，也不会有指针的引用。这主要是因为，引用并不是实际的对象，不会占据内存，因此也没有对应的地址（参考 Stack Overflow 上的回答）。\n最后，有人声称引用是必须初始化的常量指针。这一点见仁见智，个人认为可以这么去理解行为，但二者不能划等号，具体实现需要根据不同的编译器去考虑。\n类，模板，STL 前面的部分几乎涵盖了所有 C++ 的基础语法。这里再做出一些补充，比如 C++ 的面向对象（类），模板和标准模板库。\n类，面向对象 面向对象在 Python 已经做出了简单的介绍。这里在其基础上介绍 C++ 的面向对象的语法。\n首先需要注意的是，C++ 中存在结构体 struct 和 类 class 两种类似的数据结构。一般认为，struct 和 class 的区别仅在于默认的访问控制。 struct 的默认访问是 public 的，而 class 则是默认 private 的。然而，也许二者也有一些微妙的区别，这里不加区分。（我也不知道）\n下面是一个简单的类声明的例子：\n1class my_class{ 2 private: 3 int value{0}; 4 bool is_true{false}; 5 public: 6 my_class(int v, bool is){ 7 this-\u0026gt;value = v; 8 s_value = is; 9 } 10 void print_info(){ 11 std::cout\u0026lt;\u0026lt; \u0026#34;Data is obtained? \u0026#34;\u0026lt;\u0026lt; is_true\u0026lt;\u0026lt;std::endl; 12 std::cout\u0026lt;\u0026lt; \u0026#34;Value is \u0026#34;\u0026lt;\u0026lt; value\u0026lt;\u0026lt;std::endl; 13 } 14} simple_class_sample ; 这里我们声明了一个类，名为 my_class，其中包含有两个数据，这些数据由 private 保护起来所以外界无法直接取得这两个数据；在公开的部分（public）中有两个函数，一个 my_class 和一个 print_info。由于是 public 的，可以在类外调用这两个函数。其中可以看到，my_class 的函数名和类名相同。这是一类特殊的函数，名为类的构造函数。在使用该类声明一个新的变量时，可以使用该函数来初始化变量。由于函数重载的特性，一个类可以拥有多个不同的构造函数以满足不同的构造条件。这里隐藏了一些函数，这些函数会自动定义好，包括析构函数（变量退出作用域时会调用析构函数销毁变量），拷贝赋值函数（将变量复制从而创建一个新变量），以及默认构造函数（什么都不做，采用默认值初始化类内的变量），等等。\n这里再次提醒，创建一个类实际上就是创建了一个新的复合数据类型，通过该复合数据类型以及其内部定义的函数（方法），可以实现通过方法来操控用该类型创建的变量（对象）。\n最后，类的定义必须在大括号后添加一个分号，否则编译器会报错；定义好一个类后可以立刻创建一个变量，这里创建了一个变量名为 simple_class_sample，使用了默认构造函数。\nC++ 的面向对象的特性十分丰富且比较完备，这里不再做出介绍。\n模板 模板是一类更加复杂的，更加高阶的编程方式。模板会在编译器即进行运算，因此模板从某种角度而言，可以说是用来生成代码的代码。这里提到模板，主要是引入后面的标准模板库，因此这里仅做出最简单的介绍。\n下面是一个类模板创建和函数模板创建的例子：\n1template\u0026lt;typename T\u0026gt; 2T my_add_t(T a, T b){ 3 return a+b; 4} 5 6template\u0026lt;typename T\u0026gt; 7class class_T{ 8 private: 9 T value{}; 10 int index{0}; 11 public: 12 void print_T_value(){ 13 std::cout\u0026lt;\u0026lt; T.text \u0026lt;\u0026lt;std::endl; 14 } 15}; 这里创建了一个函数模板 my_add_t 和一个类模板 class_T。在使用它们时，只需要在其模板名后面跟上一个尖括号，然后在尖括号内写上需要的类型名即可。这里需要注意的是，在使用这里定义的类模板时，要保证 T 类型中拥有 text 这个属性，否则会报错。\nSTL: 标准模板库 STL 是 Standard Template Library的缩写，即标准模板库，是一系列的函数和类库，允许使用库中的类模板和函数模板。科学计算中，最常见的类模板便是 std::vector 了。作为类模板，需要在使用它的时候用尖括号来放入变量的类型。这个类型没有太大的限制，除了因为历史遗留问题而不推荐 bool 作为函数模板外，几乎可以使用任何变量类型来实例化该类模板。像这样的容器模板类还有 std::deque，std::array 等，它们都有各自的特性，感兴趣请自行搜索。这里介绍这些容器类共有的一些常用方法。\n作为容器，一定存在一个方法来告知其内部元素的数量，这个方法为 size()。调用 size() 方法后会返回一个 size_t 类型的数字来表示容器内元素数量。其次，我们需要存取容器中的元素。取用元素时，STL 提供了 at() 方法来从容器的某个位置下取出元素，这个方法接受一个整型数据来取出容器中的元素，当这个数字超出了容器范围时将会报错。当然 STL 也提供了传统的下标方法 [] 取用，但是这个方法不安全，不会进行边界检查。对 std::vector 而言，可以通过 push_back() 方法来将参数列表中的元素添加入容器的最后。当需要删除最后一个元素时，可以使用 pop_back()。最后我们介绍这些 STL 容器都有的 iterator，即迭代器。通过使用 begin() 方法即可返回一个迭代器，这个迭代器的作用类似于指针，允许与整数做加减法，允许比较大小（第一个元素最小，最后一个最大）以及是否相等，而最后一个元素再向后一个位置的迭代器为 end()。因此，使用迭代器取用容器中的元素也是允许的。另外，使用迭代器比较时，建议尽量使用判断相等/不等，而非比较大小。因为有部分迭代器可能没有实现迭代器的大小比较。\nC++ 简单计算案例：传热方程 终于，经过漫长且枯燥的语法学习，我们终于可以看一些实际的问题，并尝试使用 C++ 来解决它们了。我们遇到的第一个案例，即为所谓的 Fourier 传热问题。\n问题描述 问题描述如下：\n问题：设现在有一个热源，其中心处在 x = 64 的位置，宽度为40，温度为1，再设整个模拟域的宽度为 128，且边界上采用固定边界条件，除了热源外的位置温度为 1。先在已知传热方程如下： $$ \\dfrac{\\partial T}{\\partial t} = \\mu \\dfrac{\\partial^2 T}{\\partial x ^2},$$ 且在该问题中取 $\\mu = 1$，求算该体系在上述方程下的演化过程。\n其中的偏微分方程即为所谓的 Fourier 传热方程的简化版，将每一点的热导率看作一个定值并将所有其他参数合并后称为 $\\mu$。\n问题拆解 分析该问题，我们拥有的信息十分完全，再根据已知的 Laplacian 算符和向前欧拉法，我们很快就能构建出该问题对应的 C++ 代码。我们采用 $\\Delta x = 1$，$\\Delta t = 0.2$ 的空间和时间步长以计算时空间导数，并使用向前欧拉法迭代演化出该体系的演化过程。代码层面，我们考虑使用最基础的面向过程方法，并且注意到边界判断时固定边界上的温度值为 0.0。\n代码实现 下面是我编写的一个例子：\n1#include \u0026lt;chrono\u0026gt; 2#include \u0026lt;filesystem\u0026gt; 3#include \u0026lt;fstream\u0026gt; 4#include \u0026lt;iostream\u0026gt; 5#include \u0026lt;string\u0026gt; 6#include \u0026lt;vector\u0026gt; 7 8const int Nx = 128; 9const double dx = 1.0; 10const double dt = 0.2; 11const double mu = 1.0; 12const int nstep = 20000; // total iterate time 13const int pstep = 200; // print result every 200 step 14 15int main() { 16 auto begin_time{std::chrono::high_resolution_clock::now()}; 17 std::string result_dir{\u0026#34;./results/\u0026#34;}; 18 std::filesystem::create_directories(result_dir); 19 20 std::vector\u0026lt;double\u0026gt; mesh(Nx, 0.0); 21 for (int i = 0; i \u0026lt; Nx; i++) { 22 if (i \u0026gt;= 44 \u0026amp;\u0026amp; i \u0026lt;= 84) { 23 mesh.at(i) = 1.0; 24 } 25 } 26 27 // tempory mesh for value storage 28 std::vector\u0026lt;double\u0026gt; temp_mesh(mesh); 29 30 // ----- Begin Simulation ----- // 31 for (int istep = 0; istep \u0026lt; nstep + 1; istep++) { 32 33 for (int i = 0; i \u0026lt; Nx; i++) { 34 int im = i - 1; 35 int ip = i + 1; 36 double val_m{0.0}, val_p{0.0}; 37 38 // Fixed boundary condition (to 0) 39 if (-1 == im) { 40 val_m = 0.0; 41 } else { 42 val_m = mesh.at(im); 43 } 44 if (Nx == ip) { 45 val_p = 0.0; 46 } else { 47 val_p = mesh.at(ip); 48 } 49 50 temp_mesh.at(i) = mesh.at(i) + mu * dt * ((val_m + val_p - 2.0 * mesh.at(i)) / (dx * dx)); 51 } 52 // update the origin mesh 53 mesh = temp_mesh; 54 55 if (istep % pstep == 0) { 56 std::string of_name{result_dir + \u0026#34;fixed_step_\u0026#34; + std::to_string(istep) + \u0026#34;.csv\u0026#34;}; 57 std::ofstream ofs(of_name); 58 // if the file is indeed opened 59 if (ofs) { 60 ofs \u0026lt;\u0026lt; \u0026#34;\\\u0026#34;pos\\\u0026#34;\u0026#34; \u0026lt;\u0026lt; \u0026#34;,\u0026#34; \u0026lt;\u0026lt; \u0026#34;\\\u0026#34;val\\\u0026#34;\u0026#34; \u0026lt;\u0026lt; std::endl; 61 for (int i = 0.0; i \u0026lt; Nx; i += 1) { 62 ofs \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;,\u0026#34; \u0026lt;\u0026lt; mesh.at(i) \u0026lt;\u0026lt; std::endl; 63 } 64 } 65 // close the file after write 66 ofs.close(); 67 } 68 } 69 // ----- End Simulation ----- // 70 71 auto end_time{std::chrono::high_resolution_clock::now()}; 72 std::cout \u0026lt;\u0026lt; \u0026#34;The time cost in this simulation is \u0026#34; \u0026lt;\u0026lt; std::chrono::duration\u0026lt;double\u0026gt;(end_time - begin_time).count() \u0026lt;\u0026lt; \u0026#34;s\\n\u0026#34;; 73 return 0; 74} 这里用到了一些技巧，在边界判断处使用下标运算是否越界来判断是否处于边界处，以及使用了 \u0026lt;chrono\u0026gt; 库来监测程序运行时间。在成功运行并且用输出的 csv 文件绘制曲线图后结果大致如下：\n可以看到这个结果还是比较符合预期的。\n结语 太久不更新，写起来有些不是很得心应手。写完这些回头一看，我竟然写了这么多东西？C++ 的基础知识点比我想象的要多很多呀。如果您看到了这里，感谢您的支持。C++ 平心而论，好上手是真的，在了解一定的编程相关知识后很快就能写出一份能跑的代码。但是，C++ 的语法特性繁杂，内容过于丰富导致的则是 C++ 极高的进阶难度。几乎没有人敢说自己精通 C++，因为总有一些奇怪的点会出现在这门历史丰富且悠久的语言上，而恰好提问者知道但回答者不知道。不过好在，如果仅仅是为了使用 C++ 进行简单的高效计算，那么它的入门内容应该只需要上面这些又臭又长的介绍就差不多够了。在实际编程过程中，大多数的函数和类的 API 都是需要现查的，甚至有时候确实还需要面对 CV 编程（复制粘贴）。此外，不论任何编程语言，语言本身只能提供一些好用的特性，或者一些包装好了的算法轮子。实际在编程时最重要的问题是怎么分析问题，并且就这个问题设计出一套算法来解决问题。希望语言不会称为您的绊脚石。\n下一节我会正式采用 C++ 来实现在 Cahn-Hilliard 方程引导下调幅分解的相场（其实是浓度场）模拟。再下一节则会进行 Allen-Cahn 方程下的晶粒长大模拟，并作为这个入门系列的最后一部分。敬请期待。\n","date":"2024-12-23T00:00:00+08:00","image":"https://a-moment096.github.io/p/phase-field-%E7%9B%B8%E5%9C%BA%E6%A8%A1%E6%8B%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-iii/Skadi_hu_21f59ab02598ae65.png","permalink":"https://a-moment096.github.io/p/phase-field-%E7%9B%B8%E5%9C%BA%E6%A8%A1%E6%8B%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-iii/","title":"Phase Field: 相场模拟学习笔记 III"},{"content":"接上一节内容, 这节会简单介绍 Python 的一些语法知识, 以及尝试使用 Python 实现上节所列出来的部分算法.\nPython 初探索 简介 Python 是一种蟒蛇, 而在编程语境下, Python 则是一门十分受欢迎的编程语言. Python 具有语法友好 (接近英语), 功能强大 (感谢开源与社区), 社区活跃等优秀的特点, 让 Python 成为入门编程的一个好选择.\n为什么选择 Python 来实现上节内容提到的算法呢? 主要原因有二: 一是 Python 的语法实在是太友好, 对于没有学习过或者对编程不甚了解的同学而言, 先尝试 Python 的话不容易因为语言的问题劝退. 相比于直接介绍下一节要讲的 C++, 先用 Python 熟悉一些编程中常见的概念也是有好处的. 其二可能是出于我个人的私心吧, 因为 Python 真的太好用了, 我个人而言希望能稍微做一些推广. 作为一门好用的工具语言, 它在很多情况下都可以帮助完成一些琐碎的工作. 特别是如画图, 我很喜欢用 Python 绘制函数图像之类, 非常好用.\n总之, 这里选择使用 Python 来作为程序的入门. 相信在通过 Python 了解一定的编程基础之后, 再去了解别的语言也不会显得那么吃力了 (比如, C++).\n解释器安装与环境配置 Python 解释器 Python 的运行是需要其解释器的. 目前最新版的 Python 解释器可以直接在 Python 官网 下载. Linux 平台用户可以考虑使用各自发行版的包管理器实现 Python 的安装. 安装时请切记选择 ADD TO PATH, 否则可能需要手动调整环境变量以让 Shell 能找到 Python.\n解释器是什么? 简单来说, 就是逐行把写的脚本翻译为机器所能理解的代码指令, 然后执行. 所以 Python 是逐行运行的, 这点非常适合 Debug, 也许也是 Python 受人欢迎的原因之一. 与解释器相对的一个概念是编译器. 这里所指的编译器应该是狭义上的编译器, 广义上的编译器应该也包含 Python 这类的解释器. 编译器不会逐行解释代码, 而是将代码作为一个整体, 然后处理翻译, 最后形成机器能阅读并执行的内容后进行执行. 这种方式让编译器可以为代码做出很多的优化, 但是也一定程度上牺牲了 \u0026ldquo;逐行运行\u0026rdquo; 的便利. C/C++, Rust 等语言都是需要编译器进行编译的. 为了弥补无法原生逐行运行的缺陷, 这些语言使用了调试器 (Debugger) 以及调试符号 (Debug Symbol) 等技术来在编译完成后, 根据符号表一一对照并运行代码, 呈现出逐行运行的效果. 然而这种方法依旧会损失一定的运行性能.\nPython 解释器拥有多个版本, 每个版本对语言的语法都有一定的调整. 有些调整影响巨大 (比如从 Python2 到 Python3 的转变), 另一些可能因为其语法特性不常用, 不会直接影响到用户体验. Python 解释器也不一定是最新版就最好, 需要考虑项目的适配以及对应包的版本需求. 不过在这里我们并不太依赖 Python 解释器的版本, 只要保证是比较新的 Python 解释器版本, 并且主流的科学计算库, 如 numpy, matplotlib, scipy 等即可.\n编辑器 与 Visual Studio Code 在安装好 Python 解释器之后其实就已经可以开始 Python 编程了 (没错, 就是传说中的记事本编程). 然而这当然不是最好的方法, 这种方法光是考虑到没有代码高亮就让人很难以接受了. 这里我个人推荐 Visual Studio Code (以下简称 VSC).\nVSC 功能强大, 安装方便, 插件生态极其丰富, 通过合理的配置近乎可以达到 IDE (Integrated Development Environment, 集成开发环境) 的水平. 我个人在写简单的 Python 脚本时几乎都是使用 VSC 写的. 一路默认安装后, 根据需要安装中文插件, 然后再在插件页面搜索 Python 即可安装 Python 插件全家桶, 然后就可以开始使用 VSC 写 Python 代码 (脚本)了. VSC 的安装与环境配置也可以参考我之前写的博客文章.\n这里没有推荐 IDE, 因为 IDE 对这里仅仅使用 Python 做一些简单应用而言太过 \u0026ldquo;全能\u0026rdquo;, 或者说, 负担太重. 当然, 如果感兴趣, 可以考虑使用大名鼎鼎的 PyCharm. 这里不再赘述.\n虚拟环境, venv 和 pip 这里简单介绍一下虚拟环境. 因为 Python 的生态丰富, 可能会碰到某些依赖相互冲突的情况, 尤其是在多人共同开发的情况下, 每个人的开发环境配置不同, 很容易导致依赖冲突. 为解决这种情况, 可以考虑使用 Python 的虚拟环境 virtualenv. 创建的虚拟环境下有该虚拟环境所自有的一些包, 并且和该虚拟环境以外的部分是相互独立的. 使用 VSC 创建 virtualenv 虚拟环境非常简单, 只需要 Ctrl+Shift+P 打开 VSC 的命令, 然后搜索 Python: Create Environment 即可根据向导一步步搭建虚拟环境.\n搭建好的虚拟环境会存放在 .venv 的文件夹中. 这里面将会包含所有该虚拟环境的内容, 包括在该虚拟环境下安装的各种包. 如果不想再使用该虚拟环境, 只需要删除该文件夹即可. VSC 会自动检测是否存在虚拟环境, 并且自动切换到虚拟环境下. 如果您使用 Shell, 可以手动在命令行中运行 .venv 文件夹内的 acitvate 脚本 (Windows 在子文件夹 Scripts 中, Linux 则一般在 bin 子文件夹中), 即可启动该虚拟环境.\n在搭建好虚拟环境 (或者不使用虚拟环境) 之后, 需要从网上下载需要的包来帮助 Python 脚本的运行, 实现各种功能. 这时就需要用到包管理器. Python 默认的包管理器为 pip, 使用 pip 安装或者更新包都十分简单, 以安装 matplotlib 举例, 输入命令 pip install matplotlib 即可. 要更新包, 则使用 pip install --upgrade matplotlib 就可以. 如果有一份使用 pip freeze 所生成的软件包列表 (一般该列表文件名为 requirements.txt), 则可以使用命令 pip install -r requirements.txt 即可根据该列表中的内容进行安装.\nPython 语法基础 上面的废话可能有点多了, 下面就介绍 Python 最主要的语法点, 作为使用 Python 的基础, 同时提出一些编程语言中所拥有的共性:\n类型 虽然 Python 是一门动态类型的语言, 数据在 Python 中是根据上下文做出类型判断的, 然而这里还是简单介绍一下 Python 中常用的变量类型. 其中最常用的就是一些基础类型, 如 int, float, str, bool 等, 它们分别代表整数, 浮点数, 字符串, 布尔值. 这些类型是 Python 所天然支持的, 也是一般语言中常常原生支持的类型. 除了这些基础类型外, 还有很多的组合类型, 如 List (列表), Dict (字典), Tuple (元组) 等等. 这些类型通常是由一些基础类型所产生, 比如列表, 就是由不同类型的内容组合在一起形成的类似于容器的数据结构.\nPython 中的类型通常其本身也是一个类 (class), 意味着它们也有一些成员函数可以进行操作. 这里就不详细叙述了.\n此外, 尽管 Python 是动态类型语言, 其依旧支持对类型的标注. Python 采取后置类型标记方法, 在变量的后面添加 : 然后跟上对应的类型名即可标注其类型. 值得注意的是, 尽管有了类型标注, 这个标注更应该作为仅对程序开发者或使用者的提示, 这里标注的任何类型都没有任何的约束力.\n变量声明 Python 的变量声明非常简单, 只需要遵循 name = value 的规则即可声明并初始化一个变量. 顺带一提, Python 中变量的赋值也是同样的语法, 而 Python 中的变量又具有唯一的名称, 因此在使用 name = value 的语句时, 如果前面已经声明了 name 这个变量, 则会直接使用新的值覆盖掉原有的值. 而且由于是动态类型语言, 这里不会因为类型不匹配而报错. 因此你可以随时让一个变量拥有别的类型. 这一点十分灵活, 尤其是在确定某个变量的值不再使用, 而该变量的名称又很适合用作下一个值的名称时, 即可立刻覆盖掉原有的值.\n作用域 编程语言中常常拥有作用域这一概念. 这个概念可以认为是为了约束变量的生存周期而存在的. 一般而言, 一个变量的作用域在没有特殊声明的情况下, 只能对自己所在的区域以及该区域下的子区域可见.\nPython 这门语言其中的一个特别之处就在于, Python 的作用域划分是通过缩进完成的. 当代码顶格写成时, 这些语句的作用域即为全局作用域. 而如果有代码需要在某个作用域内时 (比如, 定义的函数内, for 循环中, 条件判断中), 则需要使用冒号 : 打开一个新的子区域, 然后使用缩进去标识哪些部分是属于该作用域的. 这一点褒贬不一, 有人认为这个方法很简洁, 避免了过多的符号; 也有人认为这种风格让 Python 的代码逻辑可能不清晰, 造成阅读困难. 但是, 无论如何, Python 的作用域是这样通过缩进定义的. 那么, 在上一层的作用域中所定义的变量对下一级的子作用域是可见的, 而子作用域内定义的变量会在程序脱离该作用域之后消失, 因此子作用域的变量对外部是不可见的. 这一点几乎是所有编程语言所通用的.\n举个例子:\n1i = 10 2outside = 1 3if i \u0026gt; 0: 4 inside = 10 5 print(outside) 6# 下面这句会报错, 找不到定义. 因为在前面离开作用域的时候, inside就被回收然后消失了. 7# print(inside) 其中 if 就开启了一个新的子作用域, 其中定义的变量 inside 在外面是看不到的, 而其中是可以看到 outside 变量的.\n控制流, 循环和判断语句 Python 中可以使用 for 循环, while 循环以及其他的循环. 其中, for 循环比较特殊, 只能在某个范围内循环, 而这个循环需要是 iterable 的. 这个所谓的 iterable 可以翻译为可迭代的, 比如 range 函数所生成的范围, 一个 List, 一个 Tuple 等等. 其语法为:\n1for i in iterable: 2 # Do something 3 # And something more 4# Here is not inside the for loop. 其中的 i 会从 iterable 的第一个元素开始, 每过一个循环体便会让 i 变成 iterable 中的下一个元素, 直到 iterable 中的元素被取完. 而 while 循环则比较简单, 只要判断条件为真则一直循环, 当检测到条件为假时则终止循环. 语法为:\n1while something_is_true: 2 # Do something 3 # And something more 4# Here is not inside the while loop. 所以一般而言, 使用 while 循环时需要在循环体中让循环条件在某时不满足, 以跳出循环.\nPython 中的判断语句是较为通用的形式, 这里只介绍 if else 循环:\n1if something_might_be_true : 2 # Do something 3elif something_might_also_be_true: 4 # Do another thing 5else: 6 # No other condition is satisfied 7# Not in condition 其语法也是十分的简单. Python 还支持一行式的判断, 可以对标 C/C++ 的三元表达式:\n1do_something if condition_is_true else do_other_things 这个语法非常贴近英语语法, 且避免了难以理解的三元表达式. 但为了代码结构清晰, 请尽量使用完整的 if else 判断语句.\n函数 函数是众多编程语言的一大组成部分. Python 由于对类型不敏感, Python 的函数定义非常地简单:\n1def Some_function (parameter_1, parameter_2, parameter_with_init_value = init_value): 2 # Do something 3 # Do other things 4 return some_value 像这样就能成功地定义了一个函数. 其中 Some_function 为函数名, 其本身也是一个变量, 所以在重新定义时实际上是为这个变量赋了新的值.\nparameter* 即为函数参数, 这些参数名将用作外界参数传入函数内时使用的占位符, 并且这些参数名将用在函数体内部. 且其中最后一个参数 parameter_with_init_value 是具有默认值的参数, 其默认值为 init_value. 具有默认值也就意味着这个函数可以不传入这个参数以代表传入默认参数. 在向函数传参时, 可以按照函数参数的顺序传入参数, 也可以显式地指明某个参数的值是什么, 如 Some_function(parameter_2 = 1, parameter_1 = 3) 这种写法是合法的.\n最后的 return 代表返回的值. 所谓返回值, 可以认为是函数运算的结果. 这个结果需要手动通过 return 关键字指定, 这里使用了变量 some_value 作为占位符.\n函数除了便于代码复用之外, 还可以让代码结构更加清晰, 以及控制一段逻辑的输入-输出结构. 这里不介绍 lambda 表达式, 这是一类匿名函数, 没有函数名, 但是具有函数的功能 (参数列表, 返回值), 即便目前大部分编程语言已经支持这一特性.\nPython 面向对象, numpy, matplotlib 这里简单介绍一些进阶的语言特性, 以及展示两个常用包的使用.\n面向对象与类 面向对象是目前十分热门的编程范式, 其通过将数据以及对数据的操作等打包为一个对象, 从而实现对数据的统筹管理. 而为了实现面向对象, 就需要某种方式实现这种打包, 这一方法即为所谓的类 (class). 各个语言对面向对象的实现均有其特点, 在 Python 中对类的声明与定义语法如下:\n1class some_class: 2 def __init__(self, param_1, param_2, param_default = default_val): 3 # Define class members 4 5 self.member_1 = param_1 6 self.member_2 = param_2 7 self.some_member = param_default 8 9 # Do something, just like in a function 10 11 self.do_something() 12 13 def do_something(): 14 # Do something 15 16# End of definition 17 18my_variable = some_class(val_1, val_2) 19 20# Use Inheritance from some_class 21class derived_class(some_class): 22 def __init__(self, para_1, para_2, sub_para, para_default = default): 23 # Must call parent class\u0026#39;s __init__ method to avoid overwritting __init__ of parent class. 24 some_class.__init__(self, para_1, para_2, para_default) 25 self.sub_member = sub_para 26 27 self.sub_class_method() 28 29 def sub_class_method(): 30 # Do sub_class things 31 32my_sub_variable = derived_class() 可以看到, Python 可以通过定义 __init__ 函数来定义类里面都有什么成员变量, 并且调用一些成员函数. 定义成员函数时语法同定义普通函数别无二致, 而在调用类中的内容时需要使用关键字 self. 并且在使用类定义变量时, 直接可以通过类的名称来作为函数名并传入 __init__ 函数中规定的参数即可调用成员函数 __init__. 最后这里要提到的是, Python 的类成员访问控制符通过变量的名字进行控制, 如双下划线代表成员是私有 (private) 的, 单下划线代表成员是保护 (protect) 的, 而其余普通名称则为公开 (public) 的.\n所谓私有成员, 即只有该类内部可以使用的成员变量或方法. 这些变量或方法在类外是不可见的. 而所谓保护成员则是只在类内部以及子类 (派生类) 内部可以使用的成员, 公开成员即为没有访问限制的成员, 无论是外部还是内部都可以取得. 使用访问控制可以控制 \u0026ldquo;谁能取到类内的数据\u0026rdquo;, 从而保护数据不会被意外读取或者篡改. 对访问控制的理解也决定着对面向对象范式的理解.\n然而我们这里并不对面向对象做要求 (主要是我也不太懂 Python 的面向对象), 这里就仅作一个介绍, 并使用其最基础的部分而已.\n包, numpy, matplotlib Python 最强大的部分当属其活跃的社区所贡献的大量好用的包. 为了实现科学运算, 常用的数学库即为 numpy, 而画图则有 matplotlib. 这里大概介绍二者的基础使用.\n为了引入包, 需要使用关键字 import. 通常, 为了使用 numpy 与 matplotlib, 有如下代码:\n1import numpy as np 2import matplotlib.pyplot as plt 3# from matplotlib import pyplot as plt 底下注释的内容和上一行内容的功能相同. 可以看到使用 as 关键字可以为包引入别名, 而为了导入子模块可以使用 from 关键字, 也可以直接 . 出来并引入.\n首先介绍 numpy 的一些使用. numpy 主要提供了一种数据结构: numpy.array, 这种结构可以用来存储数组, 矩阵等数学对象, 且支持对其进行遍历, 切片以及常见数学运算等操作; numpy.array 可以通过 Python 原生的 List 来初始化一个数组. 对于尺寸相符的数组, 可以进行加减乘除等运算, 包括数组间运算, 数组与标量运算等, 非常方便. 除此之外, numpy 还提供了大量的数学函数以供使用, 比如 numpy.exp, numpy.sin 等, 以及对文件的一些操作, 将文件中的数据加载为 numpy.array.\n然后介绍 matplotlib.pyplot, 这是一个绘制图形的库, 通常与 numpy 搭配使用, 可以高质量地将数据可视化. 下面举一个绘制 $y = sin(2x)+1$ 的图像的例子, 作为 numpy 以及 matplotlib 的应用.\n1import numpy as np 2from matplotlib import pyplot as plt 3 4x = np.linspace(0, 2*np.pi, 10000) 5y = np.sin(2*x) + 1 6plt.plot(x,y,\u0026#34;-b\u0026#34;,label=\u0026#34;$y = \\sin(2x)+1$\u0026#34;) 7plt.xlabel(\u0026#34;x\u0026#34;) 8plt.ylabel(\u0026#34;y\u0026#34;) 9plt.legend(loc = 1) 10plt.show() 上述代码首先定义了一个从 $0$ 开始到 $2\\pi$ 结束的, 总数据量为 10000 的一个 numpy.array 并命名为 x, 然后使用 x 通过运算定义了名为 y 的数组, 最后使用 matplotlib.pyplot.plot 函数进行绘制并进行图像处理. 可以看到 matplotlib 是支持 $\\LaTeX$ 语法的.\nPython 还有海量的包可以调用, 大多数都拥有友好的 API 且易于上手. 这里就不再赘述.\n算法实现 Python 的基础语法以及进阶语法先告一段落. 接下来会演示上一章节内容所展示的算法如何使用 Python 进行实现. 要实现的算法如下:\n向前欧拉法 数值积分方法 有限差分法求梯度与拉普拉斯 向前欧拉法 向前欧拉法的实现主要依赖于其显式公式部分. 设待求 ODE 为: $$\r\\dfrac{\\partial y}{\\partial x} = F(x, y),\r$$ 且解满足初值 $(x_0, y_0)$, 要求求解范围为 $[x_0, x_t]$, 则根据向前欧拉法, 选择合适的步长 $\\Delta x$ 后, 有: $$\ry_{n+1} = y_{n} + \\Delta x \\cdot F(x_n, y_n)\r$$因此, 为了实现这一算法, 该算法实现的函数有如下几点:\n接收参数:\n$x$ 轴的离散信息 (初始位置, 结束位置, 步长) 解的初始值 $y_0$ ODE 右端的函数 $F(x,y)$ 的显式表达 返回值:\n一个数组, 作为解得的 $y$ 的函数值 则有如下 Python 实现:\n1from typing import Callable 2 3def forwardEuler( 4 x_0: float, 5 x_end: float, 6 dx: float, 7 y_0: float, 8 F_x_y: Callable[[float, float], float], 9) -\u0026gt; list[float]: 10 result: list[float] = [y_0] 11 this_x = x_0 12 this_y = y_0 13 while this_x \u0026lt;= x_end: 14 this_y = this_y + dx * F_x_y(this_x, this_y) 15 result.append(this_y) 16 this_x += dx 17 return result 数值积分 数值积分的实现同样比较简单, 分析该算法的输入输出如下:\n接收参数:\n$x$ 轴的离散信息 (初始位置, 结束位置, 步长) 被积函数 返回值:\n一个数, 作为积分值 根据不同的积分算法, 可以有多种不同的实现. 下面实现四种算法: \u0026ldquo;黎曼\u0026quot;式积分法, 梯形公式, Simpson 公式, Newton-Cotes 公式.\n1from typing import Callable 2 3def RiemannIntegral( 4 f: Callable[[float], float], x_start: float, x_end: float, dx: float 5) -\u0026gt; float: 6 sum = 0 7 x = x_start 8 while x \u0026lt; x_end: 9 sum += f(x) 10 x += dx 11 return sum * dx 12 13 14def QuadratureIntegral( 15 f: Callable[[float], float], x_start: float, x_end: float, dx: float 16) -\u0026gt; float: 17 sum = 0 18 x = x_start 19 while x \u0026lt; x_end: 20 sum += f(x) 21 x += dx 22 sum -= (f(x_start) + f(x_end)) / 2 23 return sum * dx 24 25 26def SimpsonIntegral( 27 f: Callable[[float], float], x_start: float, x_end: float, dx: float 28) -\u0026gt; float: 29 sum = 0 30 x = x_start 31 while x \u0026lt; x_end: 32 sum += 4 * f(x + dx / 2) 33 sum += 2 * f(x) 34 x += dx 35 sum -= f(x_start) + f(x_end) 36 return sum * dx / 6 37 38 39def N_C_Integral( 40 f: Callable[[float], float], x_start: float, x_end: float, dx: float 41) -\u0026gt; float: 42 sum = 0 43 x = x_start 44 while x \u0026lt; x_end: 45 sum += 32 * f(x + dx / 4) 46 sum += 12 * f(x + dx / 2) 47 sum += 32 * f(x + 3 * dx / 4) 48 sum += 14 * f(x) 49 x += dx 50 sum -= 7 * (f(x_start) + f(x_end)) 51 return sum * dx / 90 梯度与拉普拉斯 这里针对二维情况进行计算. 同上, 考虑算法的输入输出:\n梯度:\n输入\n待计算网格(二维列表) 网格步长 边界条件字段 (这里固定为周期边界以便实现) 输出\n两个二维列表, 分别为对 $x$ 方向的梯度和对 $y$ 方向的梯度 拉普拉斯\n输入\n同上 输出\n一个二维列表, 存储每个网格点的拉普拉斯 以下是代码实现:\n1def calc_grad( 2 mesh: list[list[float]], dx: float, boundary: str = \u0026#34;Periodic\u0026#34; 3) -\u0026gt; tuple[list[list[float]], list[list[float]]]: 4 Nx = len(mesh) 5 Ny = len(mesh[0]) 6 grad_x = mesh 7 grad_y = mesh 8 for i in range(Nx): 9 for j in range(Ny): 10 v_l = 0 11 v_d = 0 12 v_r = 0 13 v_u = 0 14 if (boundary == \u0026#34;Periodic\u0026#34;): 15 v_l = mesh[i - 1][j] if i != 0 else mesh[Nx - 1][j] 16 v_d = mesh[i][j - 1] if j != 0 else mesh[i][Ny - 1] 17 v_r = mesh[i + 1][j] if i != Nx - 1 else mesh[0][j] 18 v_u = mesh[i][j + 1] if j != Nx - 1 else mesh[i][0] 19 # elif (boundary == \u0026#34;Fixed\u0026#34;): 20 # XXX 21 grad_x[i][j] = (v_r - v_l) / (2 * dx) 22 grad_y[i][j] = (v_u - v_d) / (2 * dx) 23 return grad_x, grad_y 24 25def calc_laps( 26 mesh: list[list[float]], dx: float, boundary: str = \u0026#34;Periodic\u0026#34; 27) -\u0026gt; list[list[float]]: 28 Nx = len(mesh) 29 Ny = len(mesh[0]) 30 laps = mesh 31 for i in range(Nx): 32 for j in range(Ny): 33 v_l = 0 34 v_d = 0 35 v_r = 0 36 v_u = 0 37 v_c = mesh[i][j] 38 if boundary == \u0026#34;Periodic\u0026#34;: 39 v_l = mesh[i - 1][j] if i != 0 else mesh[Nx - 1][j] 40 v_d = mesh[i][j - 1] if j != 0 else mesh[i][Ny - 1] 41 v_r = mesh[i + 1][j] if i != Nx - 1 else mesh[0][j] 42 v_u = mesh[i][j + 1] if j != Nx - 1 else mesh[i][0] 43 # elif (boundary == \u0026#34;Fixed\u0026#34;): 44 # XXX 45 laps[i][j] = (v_l + v_d + v_r + v_u - 4 * v_c) / (dx * dx) 46 return laps 至此, 我们使用 Python 实现了我们将在相场模拟中使用的大部分算法. 具体的模拟过程中, 我们可能不需要用函数的方式将这些算法打包起来, 只需要直接实现即可.\n总结 这部分内容希望能对上一章节中的算法内容有更进一步的补充, 并且希望能对算法如何实现为代码的过程起到促进理解的作用. 同时, 希望这里介绍的 Python 能成为您日常学习生活中的另一件有利工具, 并且能对编程这门技术有一定的入门理解, 为后续的程序编写提供基本的认识. 下一章节将会介绍如何使用 C++ 来实现这些算法, 并使用 C++ 完成一个小型的模拟, 尝试从这个小型模拟中了解模拟过程中会面临的问题, 以及数据最后的可视化方法.\n","date":"2024-11-22T00:00:00+08:00","image":"https://a-moment096.github.io/p/phase-field-%E7%9B%B8%E5%9C%BA%E6%A8%A1%E6%8B%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-ii/Skadi_hu_21f59ab02598ae65.png","permalink":"https://a-moment096.github.io/p/phase-field-%E7%9B%B8%E5%9C%BA%E6%A8%A1%E6%8B%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-ii/","title":"Phase Field: 相场模拟学习笔记 II"},{"content":"久闻 Arch Linux 大名, 以前尝试过在自己的电脑上安装 Arch Linux, 但是无情地失败了. 最近又有了尝试安装的想法, 故顺带做此记录, 以便将来回头嘲讽自己的离谱操作.\n引子: 我与 Linux 我认识 Linux 是从疫情在家无所适从的时候, 在自己的戴尔笔记本上安装 Ubuntu 开始的. 在那之前, 我只知道在 Windows 的江山之外, 还有一片名为 Linux 的世外桃源 (是的, 当时还不知道有 Mac OS,笑死). 而随着对编程兴趣的逐渐浓厚, 我愈发好奇那个 \u0026ldquo;只有高手才能玩得转\u0026rdquo; 的操作系统究竟是长什么样子. 于是, 在父亲的帮助下, 我在我的戴尔笔记本上划出来一小块硬盘留给 Linux (是的, 那时想安装双系统), 并且安装了 Ubuntu. 这个过程花费了我整整一天, 中间甚至和父亲闹了点矛盾, 把为数不多的精力全都耗光了. 自然, 安装好之后除了打开看了一眼, 安装了个 QQ 然后给同学炫耀之后, 便没了下文, 在随后的哪次格式化硬盘的时候跟着不见了.\n第二次尝试 Linux 是在英国百无聊赖的时候开始的. 那时又是对电脑感兴趣, 又是好奇 Linux 操作系统是什么样子, 于是便又一次自己尝试安装 Linux. 这次是跟着鸟叔开始的, 故而安装了他的教程里的 CentOS. emmm 这个系统好像是比较老旧了还是怎么样, 目前也不是很火的样子. 鸟叔的教程还是相当细心认真的, 我这种纯小白 (也许) 也懵懵懂懂地在虚拟机上安装好了, 尝试了几个命令, 也感受到了命令行的神奇之处. 然而, 可能是好奇心太旺盛, 抑或是其他的原因, 我的兴趣点很快跑掉了, 因此这次对 Linux 的探索之旅止步于学会用命令行关机 (当然, 现在也已经忘了hhh)\n第三次便是进入研究生之后. 由于程序需要在 Linux 环境下运行, 编译和调试, 我再一次尝试起了 Linux. 不过这一次, 我使用了 WSL 来运行 Linux. 一开始也是安装的 Ubuntu, 后来总是在网上听到什么 \u0026ldquo;BTW, I use Arch\u0026rdquo; 这样的段子, 以及各路网友的推荐, 我便尝试了一下在虚拟机上安装 Arch Linux. 不过也许是心浮气躁, 没能搞成, 后来安装了网上大佬的 Arch WSL, 现在也随着老笔记本的退役而说再见了.\n目前我使用 Linux 系统还是主要通过 WSL, 毕竟真的很方便. 但是, 心里总是痒痒的: 为什么我不能装个 Arch 呢? 所以这一次, 我一定要安装好 Arch Linux 口牙! 即便可能后面还是会沦为文件夹角落的落灰软件, 我也要骄傲地喊出: \u0026ldquo;BTW, I use Arch!\u0026rdquo; (下期可能是 Debian 也说不定, 哈哈哈)\n准备: VirtualBox 和 Arch 镜像站 环顾电脑一圈, 发现我以前用的 VMware Workspace 安装包没有导到这台新电脑上来, 而且即便现在安装 VMware Workspace 17 Pro 是免费的, 它竟然还要我注册…… 于是我还是选择了 Oracle 家开源的 VirtualBox. 再下来便是 Arch Linux 的源了, 我选择使用 ISO 镜像安装, 下载是通过淘宝的阿里云镜像站(其实就是第一个而已, 懒得往下翻了). 下载了大概40来分钟吧, 感觉速度还行, 1G 的大小来讲感觉还不错.\nVirtualBox 里给 Arch 预留了 4096MB (4GB)内存和 8GB 的硬盘容量, 希望这么多够 Arch 用. 校验过 SHA256 之后, 因为之前设置虚拟机的时候没有指定 Arch 的镜像文件 (因为还没有下载好), 所以在启动虚拟机之后会显示 \u0026ldquo;failed to boot\u0026rdquo; 并且要求指定 DVD 的路径. 这里选好 Arch 的镜像之后直接 mount and reboot, 便会进入 Arch 的安装界面了. 从这里开始也算是正式进入 Arch Linux 的安装环节了.\n开始 (准备) 安装 帅气的开屏, 然后进入 Shell 这里我们打开 Arch Linux Installation Guide以便根据官方教程进行安装. 我不打算用 Arch Install, 感觉那个没什么意思 (上次也是这么说的). 按照小节 1.4.2, 我们使用了光盘介质 (ISO也算是光盘镜像), 所以直接第一个选项就可以了.\n旋即屏幕闪过很有黑客感觉的画面 (个人猜测是系统自检, 感觉像是 systemd, 因为左边有很多绿色 OK 字样), 然后便进入了如下画面:\n根据 1.4.3, 我们这是来到了第一个虚拟终端 (Virtual Console), 身份是管理员用户 root, 使用的 Shell 是 Zsh. 感谢虚拟机, 让我不用担心在 root 账户下做的愚蠢操作会害死我的电脑和我自己. 那么我们继续吧~\n键盘映射和字体, 以及验证启动模式 接下来要设置键盘映射. 其实个人感觉美式键盘就不错, 不过还是看一下吧. 说不定以后会考虑搞点中文输入法, 之前看到的小狼毫还不错的样子 (现在也还再用).\n扯远了, 查看键位映射的命令是: localectl list-keymaps. 这个命令感觉很容易拆分为 \u0026ldquo;locale ctl\u0026rdquo;, 本地化控制的感觉. 很快阿, 输入命令之后直接跳出来一个长长的列表! 里面应该是所有 Arch Linux 支持的键盘映射选项. 这里好像就是使用了 Vim 输出到屏幕上的, 所以支持所有的 Vim 操作 (当然, 我就只会那几个, 以及退出). 坏消息是, 没有中文的选项, 不过这里应该是我犯蠢了, 键盘布局其实中文用的貌似就是美式布局…… Anyway, 我们就直接接受最基本的设置即可, 不考虑更改键盘布局了. 后面可能我会考虑把 CapsLock 键映射为 ESC/Ctrl, 不过就现在而言还是省了吧. 这里还可以设置键盘的字体, 但是也省了吧, 以后再说. 感觉这个地方设置的主要目的还是为了能顺利安装 Arch Linux, 个性化之类的内容按理应该是放在装完系统之后的.\n接下来是验证启动模式. 使用命令如下: cat /sys/firmware/efi/fw_platform_size. WTF? 竟然显示没有这个文件. 按照说明, 这里系统应该是使用 BIOS 或者 CSM 方式启动了. 查看虚拟机设置里的母板(主板)部分, 可以看到 启用EFI 没有被勾选上. 好吧, 那就说明应该就是 BIOS 启动了.\n验证网路环境, 然后更新系统时间 然后尝试联网. 作为网络小白, 我只能按照说明上的一步步来了. 首先检查网络接口 (network interface) 有没有打开, 使用命令 ip link, 得到了两行内容, 一行是 lo, 另一行是 enp0s3. 看不懂. 查看 Arch Wiki 上关于网络接口的部分, lo 是 virtual loopback interface 的意思, 且不会用在联网上. 而另一个 enp0s3 看起来像是正确的网络接口. 根据说明, en 代表的是以太网 (Ethernet), 而且只要显示了 UP 的字样, 便表明该接口是已启用了的. 很好, 说明我们的网络接口设置没遇到什么阻碍.\n我的虚拟机是使用的 NAT, 这个 NAT 根据 Google 得到的结果来看, 是 Network Address Translation 的缩写, 是一种把 IP 地址重映射的技术. 听起来很像是路由器在做的工作. 根据安装引导的说明, 我们需要做的是插好网线并且配置好动态IP, 而动态 IP 又好像是会自动配置好的. 所以实际上什么都不需要做就可以了其实. 那么网络这块儿的最后一步便是尝试 ping archlinux.org. 很不错, ping 出来结果了. 这个命令就我的认知而言, 是尝试向某个网址发送一些短数据包, 然后让对应网址的服务器返回一个数据包, 以此来检测网络延迟情况. 除了尝试 archlinux.org, 我还试了试 ping B站, Google, 百度. 结果除了谷歌以外都不错. 可能是因为代理没有代理虚拟机的端口吧 (瞎猜). 无论如何, 网络这块儿是搞定了. 接下来是更新系统时间. 这个简单, timedatectl 就可以. 轻轻松松. 看来这会儿是美国时间下午4点半.\n磁盘分区咯, 还要格式化并挂载 现在要进行的就是磁盘分区了. 每次到了这里总会感觉紧张, 不知道是不是因为之前搞坏过磁盘的缘故 (虽然是物理损坏, 和操作系统没关系). 先来看看都有哪些设备可用: fdisk -l. 结果显示找到了两个设备: /dev/sda 和 /dev/loop0, 一个是我预留好的 8GB 固态虚拟文件系统, 另一个是什么我不是很懂. 教程上讲, 以 loop 结尾的可以不用管. 可是我这是以 loop 开头的呀…… 算了, 应该没问题. 这里提示如果没有显示硬盘, 需要确保硬盘控制器没有处于 RAID 模式. RAID 阿, 看来磁盘阵列这种好像还不太好直接搞 Arch? 因为我这里的硬盘是普通的 SATA, 所以就忽略NVMe 等的提示了.\n接下来正式开始分区. 这里指出了两个要划出来的分区: 用于根目录 / 挂载的分区 以及 用以 UEFI 模式启动的 EFI 系统分区. 这个 EFI 分区我有印象, 在 Windows 系统的磁盘管理中, 可以看到 C 盘里面就又一个 EFI 系统分区. 看来 EFI 现在是比较通用的系统启动方法. 这里我发现我好像设置的磁盘空间太小了, 教程里给的是至少 23-32GB 留给根目录挂载的, 唉. 郁闷阿. 看来要火速删机然后重新搞起.\nWaiting\u0026hellip;\n还好之前基本都是检查性质的条目, 直接可以跳过. 重新分配硬盘空间到了 64G, 启动后就可以开始分区了. 这里教程里有提到几个点: 1. 想好怎么分配空间; 2. 如果要组存储池之类现在就要搞; 3. 如果这个盘上已经有 EFI 了就不要重新建立 EFI 了; 4. 可以在支持 Swap 的文件系统设置 Swap. 底下还有两个分区示例, 我们就尝试最简单的那个, 也就是 1.9.1 中的 第一个方案. 个人而言这个方案也挺合适的.\n我们使用 fdisk 来创建硬盘分区: fdisk /dev/sda (我这里用来分区的磁盘是这个 /dev/sda, 所以命令后面跟着的是这个). 这个命令行工具我从来没用过 (上次安装好像用的不是这个, 有个 TUI. 也有可能 fdisk 也有 TUI, 这次没搞出来吧), 查阅 fdisk 的说明, 直接从第四节开始, 首先是说明创建分区会抹掉这个磁盘上的所有数据. 很吓人, 还好我们在虚拟机上. 应该不会影响到我可爱的C盘的吧.\n首先创建分区表. 这里使用 MBR 分区表, 因为默认如此. 根据网上的搜索结果, MBR 也适合我这种磁盘容量比较小的情况. 然后按 n 进入创建分区引导界面. 这里会询问你的分区类型 (是初始还是拓展), 分区的编号, 以及起始和结束扇区. 第一个分区分给 /boot 作为启动分区, 结束扇区前的部分一律默认 (初始分区, 1号, 从 2048 扇区开始), 然后通过命令 +1G 来给第一个分区 1G 的容量. 然后创建第二个分区, 也是前面全部默认, 最后用 +4G 指定容量为 4G. 这里我把这 4G 作为 Swap (好像就是虚拟内存)分区, 先使用命令 l 查看每种分区类型的代码 (Swap的代码是 82), 然后 t 开始改变分区类型, 选择 2 号, 类型写82. 最后把所有的空间分给第三个区, 然后给分区1打上 bootable 的标签 (用命令 a 然后选 1 号).\n这个时候可以用 p 来查看分区结果, 会有一个表格写着所有的内容. 确认无误就可以 w 来写入分区结果了. 接下来要格式化文件系统, 不然操作系统不知道文件是怎么存放的. 首先用命令 lsblk -f 来查看现在的磁盘信息 (或者就是刚刚的分区情况). 这里我显示的结果如下:\n说明之前的 sda 磁盘已经被分成了三个区域, 且都没有挂载. 现在我发现了一个问题: 我用的是 MBR 分区表, 为什么使用了 GPT分区表推荐的 /boot呢? 而且之前还说没有开启 EFI, 现在又要搞 EFI 适用的 /boot, 离谱. 很好, 那就重新分区吧.\nWaiting\u0026hellip;\n很好, 在熟练的操作下~~ (指现学)~~, 先用 d 删除所有分区, 然后创建 4G 的 Swap 分区, 以及 bootable 的主目录分区. 现在的分区结果是这样的:\n我们采用最经典的 ext4 文件格式 (其实就是教程里这么推荐的) 来格式化 /dev/sda2, 命令为: mkfs.ext4 /dev/sda2; 然后用命令 mkswap /dev/sda1 将 /dev/sda1格式化为 swap. 整体结果如下:\n最后, 我们终于要挂载文件系统了. 这个我了解过, 使用 mount 命令即可挂载硬件到某个目录下. 首先我们挂载根目录, 把根目录挂载到 /mnt 下: mount /dev/sda2 /mnt. 因为我没有别的什么文件分区, 只剩下一个 Swap 分区, 所以我们直接使用命令: swapon /dev/sda1 来启动 Swap.\n真的要安装了 刚刚才发现, 上一节内容是 \u0026ldquo;Pre-installation\u0026rdquo;. 晕了, 原来刚才的真的全都是准备工作吗? 好像看起来确实如此, 因为没有涉及到什么具体的软件安装之类的, 更像是创造一个能让 Arch Linux 得以安装的环境. 但是看安装说明, 安装这一节只有两个小节, 看来也不是很复杂的样子.\n首先是要选择镜像. 这次选择的镜像感觉上是给系统使用的 pacman 的镜像源. Arch 已经有一份使用 Reflector 生成 的镜像服务器列表: /etc/pacman.d/mirrorlist, 可以查看或编辑这个文件以使地理位置最靠近的服务器地址可以被优先使用. 这里我使用 reflector --latest 10 --sort rate 来按照响应速度排序最近更新的10个服务器. 结果好多都 timeout 了. 尝试命令 refletor --country China --age 12 --sort rate, 试了两次, 结果又是时好时坏. 不管了, 起码这个时好时坏也算是有源可用. 使用命令 reflector --country China --age 12 --sort rate --save /etc/pacman.d/mirrorlist 即可把输出的结果保存到 /etc/pacman.d/mirrorlist 里面.\n接下来要安装必要的包. 根据教程, 这里安装的包有 base 包, Linux 内核以及一些常见的固件. 使用命令: pacstrap -K /mnt base linux linux-firmware. 之后便进入了安装界面.\n看来要安装 127 个包, 不是个小数目. 而且我这里的网速看起来也比较一般. 慢慢等吧. 这个安装进度让我莫名想起安装 $\\LaTeX$ 时候的样子.\nWaiting\u0026hellip;\n? 后续过程这么快的吗? 127个包看来都不是很大的样子. 安装好之后的样子是这样的:\n可以看到其实有一些部分是缺失的. 这个应该没什么关系, 毕竟虚拟机可能确实会缺一些不紧要的组件. 这里还可以安装一些别的组件, 比如 CPU 的指令集更新 (microcode), 使用 RAID 的工具之类. 这里就先跳过了, 之后使用 pacman 安装需要的内容. microcode 由于我使用的是虚拟机, 指令集补丁应该存在于主机 (这台Windows) 上, 所以不需要安装.\n安装在虚拟机上的时候好像不需要安装 linux-firmware, 额…… 无所谓了. 现在才看到也是醉了. 那么就下一步吧.\n设置系统吧! 分区文件, chroot, 以及本地化 首先先生成一份分区表文件, 使用命令: genfstab -U /mnt \u0026gt;\u0026gt; /mnt/etc/fstab. 之后用 cat 看看结果是否正确, 不对的话需要改一下. fstab 的 Arch Wiki 页面有一些例子, 这里就不再赘述 (因为我搞的好像没什么问题).\n接下来 change root 到新系统下: arch-chroot /mnt. 根据中文 Arch Wiki 的解释, chroot 是 \u0026ldquo;修改当前进程及其子进程的可见根目录的操作\u0026rdquo;. 似乎修改之后进程就会以 /mnt 为根目录 /:\n我大胆猜测, 现在就是把进程从 ISO 文件中的系统转移到了我虚拟机上的系统. 不过怎么验证这个想法我没什么主意. 下一步吧.\n现在要设置时区. 国内应该是东8区. 根据教程, 可以使用 timedatectl list-timezones 来列出可用时区. 然而坏消息是, 列出来的时区因为太多了, 而不知道为什么, 这个终端我没法滚动 (鼠标或者键盘的 Shift + PgUP 好像都不可以). 经过一番查找, 向上翻页的功能应该是被从内核中砍掉了, 因为没多少人用了, 目前几乎都在用终端模拟器. 好吧, 只好把结果重定向到文件里, 然后再用 Vim 打开试试了. 不过竟然新系统是真的什么都没有, 包括 Vim 或者 Nano 都没有??? 只好退回到安装镜像里看看了. 国内时区使用的是 Asia/Shanghai, 所以重新 arch-chroot /mnt 回到根目录, 使用命令 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 命令设置好时区, 然后使用命令 hwclock --systohc 生成 /etc/adjtime.\n再下来是设置本地化. 我个人倾向于不改中文使用, 而且因为没有安装编辑器, 现在要改变本地化设置也不行 (太蠢了, 为什么不安装编辑器!). 好吧, 再憋一下. 还是先设置主机名吧. 因为没有编辑器, 干脆直接使用 echo 重定向到 /etc/hostname 好了. 那么在不使用 LVM 或者 RAID 的情况下, 下一步便是设置密码. 设置密码的时候输入的字符是隐形的, 所以看不见是正常现象. 好像 Linux 下的大多数密码输入的时候都会隐形, 也算是保护隐私的一种惯例了.\nBoot loader, 然后决定命运的重启! 最后, 选择并安装 boot loader. 这一步很重要, 不然会导致无法启动 Arch Linux. 根据 boot loader 的特性表, 以及网上查找到的信息 (其实是我没找到怎么搞 EFI boot stub 的安装), 我选择使用 GRUB 作为 boot loader. 首先安装 GRUB (算了, 顺带这一步把vim也安装了吧, 憋不住了): pacman -S grub vim. 根据 GRUB 的 Arch Wiki 页面, 找到 BIOS System 的第二条 Master Boot Record (MBR) (我怎么在 UEFI 这里兜兜转转好久). 使用命令: grub-install --target=i386-pc /dev/sda. 这里 --target=i386-pc 是固定的, 而后面的 /dev/sda 是指的硬盘而非分区.\n安装好这一步之后就需要对 GRUB 进行配置了. 使用命令: grub-mkconfig -o /boot/grub/grub.cfg. 貌似这样就已经配置好了. 感觉还是挺简单的. 怎么心里毛毛的. 好, 重启吧! 希望一切顺利.\n成功辣! 好耶! 但是迎接我的并不是美丽的图形化界面, 而是简洁的 tty1, 甚至要我输入账户名来登录. 好吧, 看来起码安装是成功了, 现在要做的就是后处理了.\n安装后的配置 其实要是较真地讲, 现在已经把 Arch Linux 安装好了. 但是我决定送佛送到西, 配置一个能日常使用 (玩耍) 的系统出来. 按照安装教程的说明, 现在跳转到了 general recommendations 的页面. 这也算是教程吧, 就按着这个来吧.\n系统管理: 添加用户和其他 首先是要学习两个概念, 系统管理 (system administration) 和包管理 (package management). 这两个里第一个对任何的 Linux 系统而言都应该是重要的, 而第二个应该是出于 Arch Linux 独特的滚动更新模式, 所以要特别强调.\n第一点就是讲明 root 账户应该只应用于系统管理的情况, 平时应该使用未经提权 (提高权限) 的普通用户. 使用命令: useradd -m amoment 便可创建一个名为 amoment 的用户, 并初始化这个账户对应的 /home/amoment 文件夹. 随后使用 passwd amoment 来给这个账户一个密码. 具体操作中, 因为要先登入 root 账户进行操作, 所以可以在执行完之后 logout 然后重新以新创建的 amoment 账户登录.\n接下来是安全问题. 看不了一点儿, 越看越觉得自己在互联网上裸奔 (其实应该已经是了). 感觉自己的网络安全意识还有待提高. 这一部分的文档很长, 以后再细看吧. 随后是服务管理, 主要是说 systemd 的使用. 也许以后会有需要用 systemd 来搞一些自动化的服务. 最后是 Arch 滚动版本带来的系统维护的需要. 由于是玩具系统, 这步也暂时免了吧.\n包管理: pacman, 但是…… Arch Linux 默认使用 pacman 作为包管理器. 用包管理器可以安装东西, 前提是有网络. 然而…… 好消息是, 我新安装的 Arch Linux 莫名其妙没有网了. 所以, 包管理章节先暂停一下, 先跳转至 网络设置 部分.\n有网络再说安装吧! 问题的症状很奇怪, 使用命令 ip link 之后显示的网络适配器都是未启动的状态, 而使用 ip a 之后显示的内容都是没有 ipv4 地址的.\n猜测1: 虚拟机设置有问题 捣鼓了半天的 NAT 网络设置, 但是感觉问题应该不是出现在了这里, 因为之前就是使用的 NAT, 不然我的 vim 都安装不上去的 猜测2: ip 设置有问题 可是 ip 我也不懂啊, 互联网 (物理) 小白是真的搞不懂这些网络协议之类的. 回去翻看安装说明, 也没有讲到这里呀. 回忆: 安装的时候是有网络的, 安装完好像没碰过网络环境. 猜测3: 该不会是我自己系统上没有装驱动吧 坏了, 网上一通搜, 真的是没有装网络服务 dhcpcd 和 networkmanager. 乖乖回去用安装镜像进入, mount 根分区 /dev/sda2 到安装镜像的 /mnt 然后 arch-chroot /mnt, 开始老实安装 dhcpcd 和 networkmanager. 这里要感谢讨论串和一篇博文. 回看安装指引, 这时才明白, 条目 1.7 最底下的 Note 是什么意思了: 网络服务在新装的系统上面是通通没有滴! Okay, 安装完毕, 继续回到 pacman 上. pacman: 没错, 孩子, 又是我 首先, 为了能让我以普通用户身份提权然后使用 pacman, 先在 root 账户下安装好 sudo 吧: pacman -S sudo. 然后安装结束后会发现一个很尴尬的事情: 我的普通账户不在 sudoers 文件中. 查看指南, 指出需要使用 visudo 来修改 /etc/sudoers 文件, 但是 visudo 需要 vi. 我安装了 vim, 但是这个不默认安装 vi. 网上的解决方法看起来有点麻烦, 所以干脆直接 pacman -S vi 安装. 之后 visudo /etc/sudoers, 在某处 (我在 root 开头那行的底下) 插入 amoment ALL=(ALL:ALL) ALL , 即可在需要时提权我的个人账户.\n太棒了, 但是这是否已经解释了如何使用 pacman? 好像还不够. 查阅指南, 指南中指出在安装软件包时, 不要使用 pacman -Sy, 这样会造成部分更新, 容易搞崩系统 (俗称 \u0026ldquo;滚挂\u0026rdquo;). 安装软件包使用 pacman -S \u0026lt;pack name\u0026gt;; 升级系统使用 pacman -Syu. 这里再解释一下 pacman 的命令行的意思吧, -S 代表的是 Sync, 是同步的意思, 意即使用该命令是从 Arch Linux 的软件源服务器上把对应的软件包同步到本地. 实在是很新颖的做法, 起码概念已经甩开传统的安装了. -Syu 中的 y 是指 refresh, 从服务器上下载最新的包数据库, 而 u 则代表 sysupgrade, 更新系统上的所有软件包. 所以 -Syu 的意义就很明显了, 不希望拉到了最新的软件包数据, 却又没有实际更新软件. 所以这两者放在一起最合适是有道理的.\n看一下删除包吧. 我发现 networkmanager 好像是不必要的, Arch Linux 使用的 systemd 自带一个 systemd-networkd. 删除软件包使用命令 pacman -R 即可删除包, 但是这种情况下会留下这个跟着这个包一起下载到本地的依赖们. 要顺带删掉空闲的依赖 (可能有些依赖别的软件包也在用), 使用 pacman -Rs 即可. 其中 s 代表的是 \u0026ldquo;recursive\u0026rdquo;. R 的意义就很明显了, 就是删除 (Remove). 所以为了删掉 networkmanager 且不影响到别的软件包依赖, 使用命令 sudo pacman -Rs networkmanager 即可.\n最后了解一下如何列出安装好的软件包吧. 使用命令 pacman -Q 即可列出所有已经安装好了的软件包 (非常多, 因为在安装系统的时候就已经在使用 pacman 了). 其他的设置可以通过 pacman -h -Q 来查看 (-h 即为帮助的意思咯).\n桌面环境: KDE 很好, 先在这个系统距离可以让我谜之自信地喊出 \u0026ldquo;By the way, I use Arch\u0026rdquo; 感觉只剩下最后的一步: 安装桌面环境. 经过不细致的选择, 我决定使用 KDE Plasma 作为桌面环境 (Gnome 的拟物图标感觉不是很喜欢呀, 虽然左侧栏的设计很喜欢, 不过好像 Plasma 也可以搞?).\n通过 pacman -S plasma-meta 安装 plasma. 中间有几处需要选择一些诸如字体, 解码器之类的供应源, 网上没有多少讨论这个的, 所以就基本全部默认了. 然后顺手安装上 zsh, noto-fonts-cjk/emoji/extra, bluez-utils kitty, konsole 和 alacritty. 这里 kitty, konsole, alacritty 三个重复了, 因为我想都试试.\n首先打开蓝牙: sudo systemctl enable --now bluetooth, 然后通过 sudo systemctl enable --now sddm 即可进入 KDE Plasma 桌面. 剩下的就是点点点了, 点点点, 爽! 我必须立刻把任务栏 (这里叫 panel) 移至左边!\n安装别的工具…… 我中文输入法呢! 为了实现中文输入法, 我安装了 fcitx 大礼包: fcitx5, fcitx5-configtool, fcitx5-chinese-addons, fcitx-gtk. 然而莫名其妙地遇到了几个奇怪的坑:\n教程讲要把一些内容加入到文件 /etc/environment/ 里面, 然而我用 vim 打开之后发现是只读的. 虽然可以覆盖, 但是总是感觉不对. 经过网上的搜索才得知: 没错, 这就是权限控制. 使用 ls -l /etc/environment 命令可以看到最左边的权限控制符, 指明了这个文件是只有拥有者才可以读写, 同组或其他人只能读, 而这个文件的创建者正是 root. 所以乖乖使用 sudo vim /etc/envirnment 就可以了, 其实很简单. 为了配置中文输入法, 我找到 KDE Plasma 的设置里面的 Input Method 部分, 并且在右下角的 Add Input Method... 中选择了 Keyboard - Chinese. 然而什么都没有发生. 即便左下角的输入法显示的是 zh, 可依旧不是中文输出. 很怪! 然而解决方法出乎意料的简单: 在仔细观察各路大佬博客之后, 我发现中文输入法不叫这个名字, 而是应该直接搜索 pinyin. 无语了, 心态有点小爆炸. 根据 fcitx 的官网教程, 为了使 fcitx5生效, 应该在路径 ~/.config/environment.d/ 下创建文件 im.conf, 并在其中输入： 1XMODIFIERS=@im=fcitx 2SDL_IM_MODULE=fcitx 这样一来, 重启之后就可以使用中文输入了\n还是想要用 fcitx5-rime 安装 fcitx5-rime 我是直接按照说明来的. 直接用 pacman 就好: sudo pacman -S fcitx5-rime 即可. 然后在输入法中直接搜索 rime 选中应用就好. 但是这个时候的词库啊配置啊什么的都不太合意. 然而我 Windows 端也用 的是 Rime 家族的输入法 (具体来讲是小狼毫 weasel) 而且有一套调教过的配置 (使用 oh-my-rime, 也叫薄荷输入方案). 所以, 干脆把配置从 Windows 上导入到虚拟机里好了.\n为了能把我在 Windows 上的配置文件直接导入到 Arch 里, 需要在 Arch Linux 里面下载: virtualbox-guest-utils (不支持 X 的话要安装带个 -nox 后缀的版本), 然后把它加入到 systemd 的服务中去: sudo systemctl enable --now vboxservice.service. 然后再在虚拟机上打开 Drag and Drop 以及 Shared Folders. 我将我用的 Rime 配置文件打包成 tar 之后放在了 Shared Folder里, 然后就可以从虚拟机上的指定位置取出来然后解压缩到需要的路径了. 其实期间有考虑过使用 ssh 或者是其他的方式来传输这个压缩包, 后面还是放弃了. 反正能完成目标就好, ssh? 不用也罢! ()\n不能科学上网吗？ 虽然是虚拟机, 还是想试试安装一些科学上网的工具. 目前 Windows 上有在用的工具, 但是貌似在 Linux 上并不是很好用呀 \u0026hellip; 经过一通搜索之后锁定到了 V2rayA, 使用 yay 就能很简单的安装 (? 代理? Github?).\n实际尝试过后, 发现这个工具好像和我目前在用的有点八字不合? 在 Windows 上也尝试同款工具之后, 发现确实是不太好用, 唉. 那就算了吧. 不科学上网, 那又能怎么样呢?\n终端字体怎么怪怪的? Alacritty? 听闻 Alacritty 使用 Rust, 性能十分优异, 然而在我满心欢喜地调整系统字体为中文之后, Alacritty 的字体变得惨不忍睹了 \u0026hellip;\n这究竟是怎么回事? 在热心群友的帮助下, 我查阅了 Alacritty 的 Arch Wiki, 得到了令人震惊的事实: 我竟然没有配置字体文件. 直接下载安装 ttf-cascadia-mono-nerd (其实不下载也可以), 然后在家文件夹下创建新文件夹和文件: .config/alacritty/alacritty.toml 并使用 vim 修改内容. 格式如下:\n保存的时候便会直接应用. 其中 family 是可以从设置的字体管理部分看到字体族的名字, 输入即可. 这里字体族主要是需要等宽字体族才能正常显示, 选择这款字体是因为我 Windows 上的终端字体也是用的这套 Cascadia, 很喜欢所以就干脆保持一致了.\n试试 Zsh! ","date":"2024-11-10T22:34:55+08:00","image":"https://a-moment096.github.io/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84-arch-linux-%E5%AE%89%E8%A3%85/imgs/Reimu_Water_hu_c0311f6b5f3ea112.jpg","permalink":"https://a-moment096.github.io/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84-arch-linux-%E5%AE%89%E8%A3%85/","title":"从零开始的 Arch Linux 安装"},{"content":"本文写于9月22日，因为这是我读完的第一本数学专业的书，故而感觉很有必要记下来点什么，于是就有了这么一篇流水账。作为 Mathematics 部分的 第一篇博文正是再好不过\nPrinciples of Mathematical Analysis, Walter Rudin (May 2, 1921 – May 20, 2010) 所写的一本“ 适合于高年级本科生或数学系一年级学生 ” 的数学分析 教材, 因其作为 Rudin 所著的三本分析学教材 (另外两本为 Real and ComplexAnalysis 与 Functional Analysis) 中最“小”的一本，故而得名 Baby Rudin (另外 两本也被分别称为 Papa/Big Rudin 与 Grandpa Rudin), 作为我在课外自己读完 (但几乎什么题都没写) 的第一本数学专业书, 在断断续续读了一年多以后终 于读完了. 说来惭愧, 本来是适合本科生的数学书, 却是拖到了研二才读完, 还 好我不是数学专业的. 本人作为一个门外汉, 抱着喜悦的心情, 简单分享下自 己读后的感想.\n即便从大三以后随着兴趣瞎读了很多数学书, 在我看来我“认真读过”的 数学书也许也只有微积分学教程 (菲赫金哥尔茨著), Algebra: Chapter 0 (Paolo Aluffi 著) , An Introduction to Manifolds (Loring W. Tu 著) 以及这本Baby Rudin. 除此之外的书几乎都是简单翻阅过, 并没有细看. Thomas W. Hungerford 所写 的大名鼎鼎的 GTM 73 我虽然想过仔细阅读, 但是还是没有坚持下来. 到头来 唯有这本 Baby Rudin 是从头到尾几乎处处的看完了 (这里指除了至多可数个 的习题). 不过这些翻阅过的书也算是给了我一些勇气和底气, 让我去对一本 数学专业教材评头论足.\n这本书处处体现着“惜墨如金”四个字, 而且不似其他很多作者那般喜欢 使用比较形式化的语言 (比如, 用一些记号, 如$\\left( X, A, \\mu \\right)$三元组来表示度量空 间), 反而对符号的使用相当克制. 最令我惊讶的是, 直到最后一章的第三小 节, Rudin 才引入了用代表元来表示集合的记号 $\\\\{ x \\vert P \\\\}$ . 虽然分析学也许并不 会像代数学那样大量使用元素性质各异的各类集合, 但能把这么常用的符号 放到这么后面才介绍, 也许的确称得上是“惜字如金”. 不过换个角度来讲, 也 许也正是不过多借助符号, 反而更多采用文字描述的方式介绍数学概念, 这 本 Baby Rudin 才会有其独特的魅力.\n这本书的内容编排上, 在我看来也与众不同. 这本书在构造实数的过程 中, 捎带手把复数一并处理了, 甚至还在第一章末尾专门单开了一个部分用 来从头到尾地叙述实数的构造. 随后第二章也并没有急于引入数列或者极限, 而是这时才引入函数这一概念, 再在集合和函数的基础上讲起点集拓扑, 而 且 “limit” 一词也是作为点集拓扑中的 “极限点 (limit points)” 出现的, 而非传 统的序列极限引入. 这里还要提一嘴, “Topology” 这个词全文中只在标题和 两处提到拓扑学的三角剖分的句子中出现了, 而在主讲拓扑的第二章正文中 更是一次也没有出现过. 第二章中没有拓扑一词, 但却通过引入距离 (度量) 而切实地讨论了对分析学而言更有意义的拓扑空间, 实在是很新奇的阅读体 验. 拓扑概念的引入对后续的内容有极大的影响. 提前引入拓扑语言的好处 在于能更细致地刻画拓扑与分析学之间的关系. 如后面函数的连续性一章, 就积极地引入了 “开集的原像是开集” 这个与传统连续性定义等价的描述.\n在做完数域, 拓扑等概念的铺垫后, 迎接读者的不仅是数列这一常见的 用以引入函数极限的概念, 还顺势加入了级数的介绍. 这与许多教材将级数 等内容放置于教材内容偏后位置的做法不同, 不仅更早引入收敛, 而且更好 地联系起了“序列极限”与 “无穷级数”两者, 并立刻用到上一章所介绍的拓扑 概念, 给出了完备性与序列之间的关系.\n在微积分的三大部分(微分, 积分, 函数序列/级数)中, 最具特色的地方 当属函数积分在简单引入黎曼积分后, 更广泛地讨论黎曼-斯蒂尔切斯积分 (Riemann-Stieltjes Integration), 以及由于拓扑, 完备等内容的引入而讨论的完 备函数空间等. 常见教材经常会更多地讨论黎曼积分的性质, 并在靠后的内 容中直接引入勒贝格积分. 而本书则在定义了黎曼积分后直接给出了更加广 泛的黎曼-斯蒂尔切斯积分, 并更多地讨论它的性质. 而且归功于度量, 完备性 等的引入, 函数序列/极限部分还讨论了函数空间的拓扑性质, 且这一部分最 后的 Stone-Weierstrass 定理更是提出了从多项式逼近函数, 从一些代数的角 度研究了多项式空间和函数空间, 这些特点无不令我大开眼界.\n而在讨论完这些微积分的常见内容后, Rudin终于决定讲一些常见的, 比 较特殊的函数 (不是特殊函数论的特殊函数). 最有趣的应该是三角函数的定 义并没有采用常见的定义方式, 而是积极使用了本书中早早提到的复数/复变 函数, 采用复指数函数的方式定义了三角函数, 用意想不到的方式给出了𝜋的 定义, 然后告诉读者我们现在处在一个可以简单证明复数域代数完备性的位 置上, 并用约一页的篇幅证明了这个著名的定理.\n多变量函数部分最让我印象深刻的是解决了我一个长久以来的疑问: 多 变量函数的导数(非偏导数)到底是什么? Rudin 在引入线性映射这一和微积 分看似联系不大的概念后, 给出了多变量函数求导的结果: 一个 $\\mathbb{R}^n$ 到 $\\mathbb{R}^n$ 的 线性映射! 这一结果让我对数学概念推广的认知更进了一步. 除了这点令我 如醍醐灌顶的部分外, 其余部分就显得有点晦涩难懂了. 特别是在隐函数定 理和秩定理两部分, Rudin的证法在我看来无疑是天书. 最后还是在互联网的 帮助下似懂非懂, 逃离了这部分.\n最后两章算是一般数学分析教材的 One More Thing 部分, 微分形式上的 积分以及勒贝格积分. 微分形式上的积分在没有流形工具的辅助下显得有点 苍白, 但作为对多变量函数和向量值函数积分的补充部分, Stokes’ 定理给出 的结论还是一如既往的优美. 而勒贝格积分 (Lebesgue Integration) 的内容总 算是让我知道了鼎鼎大名的勒贝格积分与黎曼积分之间的异同. 勒贝格积分 部分的最后引入的 $\\mathcal{L}^2$ 空间部分也解答了我的疑问: 为什么调和分析要从 $\\mathcal{L}^2$ 空间讲起, 它究竟有何优越性. $\\mathcal{L}^2$ 空间下的函数总是在给定一组基底(正交函 数类)后有一个平方收敛级数与之一一对应, 或者说, $\\mathcal{L}^2$ 是一个无穷维的, 元 素为函数的线性空间, 并配备有 $L^2$ 范数.\n总的来讲, Baby Rudin 是一本从各个方面都让我大开眼界的书. 毫无疑 问, 它带我从一个新的角度去审视分析, 无论是拓扑的引入, 多元函数求导, 还 是微分形式上的积分, 勒贝格积分, 这本书带给我的新概念和该年间的新联 系都丰富了我的视野. 不过, 这本书即便是正文, 有一些内容依然是比较难以 理解的, 特别是对符号使用的克制, 有时觉得有些古色古香, 有时又让我感到 有些找不着北. 而且, 据说本文最精华的是每章最后的习题, 这些部分我都是 扫了一眼, 大概看看几个可能会提出较新概念新定义的问题, 并没有深入去 做. 也许我就是所谓的名词党吧, 不怎么做题, 应该是学不到什么真材实料的. 不过作为一个爱好者, 感觉也没有什么太大的问题吧. 下一本书可能是读完 回国前正在看的 Intro to Manifolds, 也可能是还在国外的时候看的 Chap 0, 但 是最有可能的应该是暂时放下数学.\n最后, 我想对沃兹基德讨论组的小顾同学表达感谢, 没有他组织的倒霉 蛋抽奖环节, 我不可能有机会一览这本经典分析学教材的风采. 希望后来的 倒霉蛋抽奖能帮助到更多人, 也祝愿沃兹基德讨论组越来越好.\n","date":"2024-11-01T00:00:00+08:00","image":"https://a-moment096.github.io/p/baby-rudin-%E8%AF%BB%E5%90%8E%E6%84%9F/yoyoko_hu_d99a4a8eb201b23a.jpeg","permalink":"https://a-moment096.github.io/p/baby-rudin-%E8%AF%BB%E5%90%8E%E6%84%9F/","title":"Baby Rudin 读后感"},{"content":"简单记录一下自己搭建博客的经历。\nBegin: 好想搭博客 网上高强度冲浪的过程中，发现很多人都有自己的博客，特别是在读过几篇博文之后，对会搭建博客的大佬的艳羡之情愈发激烈，同时也很想在网上 搭一个自己的小窝，记录一下自己的学习和生活（以便于跻身大佬的行列（在心理上））。 于是，在若干的纠结与选择之后，决定尝试用 Hexo + GitHub pages 的方式 搭建一个自己的博客。\nTry：初试 Hexo 其实在10月份左右的时候，我就已经尝试开始搭建博客了。但是网上教程纷繁复杂，Hexo的文档貌似也很久没有更新了，在写完 About 之后 便陷入了各种方面的自定义，然后失败循环，结果便是迟迟没有推进博客搭建。期间找到过一个很喜欢的主题，结果因为中英文混排导致字符间距过大的问题， 一怒之下怒删文件。结果便是把搭建博客的计划一拖再拖。（其实还是没有找到合适的喜欢的主题:P ）\n不过10月份失败的经历也算是一点点积累，给了我一点关于 YAML 和 TOML 的知识储备，以及让我（也许）学会了如何高效地搜索教程。不算太亏。\nAgain：再试 Hexo 转眼到了10月底，准确来讲就是昨天，10月31日。心血来潮的我再次向Hexo博客发起冲击。然而拦住我的不只是又没有找到好看的主题（这次是按照Github 的Star数选的，也许是我审美太小众？），还有烦人的网络问题。一会儿是用 npm 拉取不到内容，一会儿又是 git 连接不到仓库。虽然后面网上搜索到 是我科学上网姿势不对，需要跑全局，并且 npm 换成淘宝源(https://npmmirror.com/)就可以轻松解决，然而接连的 Error 还是耗尽了我的耐心。\n对吗？真的要搭博客吗？师兄这晚告诉我，可以考虑搞个微信公众号，要吗？\n?: 受不了，Hugo吧 还是不想搞公众号，感觉太公众了。虽然也有博客的功能，但是我的主题这块儿谁来给我补呀（？）。是时，我又想起昨晚网上冲浪时发现的另一个构建框架： Hugo。于是当机立断，立刻冲向 Github 看看有什么好的主题，最后便相中了这款 stack。简约界面深得我意的同时，又满足了我对页面版式的需求（好怪哦）。 最重要的时，这个主题的模板目录结构很清晰！我也是摸索着添加了几个icon后配置出了令我满意的结果。感谢你，Jimmy Cai!\nEnd: 好耶 第一次搭建博客，踩的坑自己觉得不算少。不过大部分的坑都是因为不熟悉前端造成的。啊，要是我是一个搞计科软工前端XXX的学生那该多好啊，可惜，改不得。 而且另一个角度来讲，踩坑也是一种学习过程嘛。日后也许会往博客上加点新的玩意儿，搞得更花哨一些~\n还有一件事让我背后直冒冷汗，在部署页面的时候犯蠢把github上的所有我自己的改动全给删了，差点以为全都找不回来了……好在 GitHub Desktop 在 Discard Stash 的时候是把改动文件全都删除到回收站，这才找回来这些配置。Git 操作还是要小心呀。\n也许会有人问我为什么花了大把时间在纠结主题上，说博客最重要的是内容。我也很同意内容为王的观点，但是用着不满意的主题，总感觉写起来不得劲儿。 我比较相信 “工欲善其事，必先利其器”，反正是第一次搭博客，对主题的试错成本几乎是无限低 (不需要考虑迁移问题)，那么为何不多尝试不同的主题， 一次配好一劳永逸呢？\nSo, that\u0026rsquo;s it. Thanks for reading~!\n","date":"2024-11-01T00:00:00+08:00","image":"https://a-moment096.github.io/p/first-blog-%E6%90%AD%E5%BB%BA%E8%BF%99%E4%B8%AA%E5%8D%9A%E5%AE%A2/Reimu_hu_cdb6f8e227e141e1.png","permalink":"https://a-moment096.github.io/p/first-blog-%E6%90%AD%E5%BB%BA%E8%BF%99%E4%B8%AA%E5%8D%9A%E5%AE%A2/","title":"First Blog: 搭建这个博客"},{"content":"这学期开了相场模拟培训, 故尝试将相场培训笔记性质的内容记录下来, 期望观感应该是目录式的笔记, 外带可有可无的说明文字.那么就开始吧\nPhase Field Method 是什么？ Phase Field Method, 直译为相场法, 是一种材料模拟方法, 其通过宽界面(平滑界面)的特点, 克服了另一个模拟方法: Stefan 法的窄界面无法计算的缺点, 实现了对材料中的相的演化的模拟.\n基本概念解析 Phase Field: 所谓的相场, 可以理解为模拟域, 给每个点赋予一个值来表示不同的相以及相界面 Order Parameter: 序参量, 即上一条中用来表示不同相的变量.一般0代表没有这个相, 1代表完全占据这个相, 介于0到1之间的即为相界面. Free Energy Functional: 自由能泛函, 相场背后的热力学机理, 通过系统对自由能最低构型方向的移动来演化出模拟域中每个点的值的变化. Governing Equations: 演化方程, 用来加工上述自由能泛函的方程.对不同特性的变量, 需要选择不同的演化方程以进行演化: AC: Allen-Cahn方程, 用来演化非保守场的方程(即变量之和可以不为某一定值, 比如相序参量), 可以认为是有源CH方程； CH: Cahn-Hilliard方程, 用来演化保守场的方程(即变量值和为某个定值, 比如浓度). AC 和 CH 方程 AC方程的形式如下: $$\r\\frac{\\partial \\eta_p}{\\partial t} = -L_{pq}\\frac{\\delta F}{\\delta\\eta_q\\left( r,t \\right)} $$CH方程形式如下: $$\r\\frac{\\partial c_i}{\\partial t} = \\nabla \\cdot M_{ij} \\nabla \\frac{\\delta F}{\\delta c_j \\left( r,t \\right)}\r$$解两个方程需要的工具有: 解ODE/PDE(有限差分法, FDM), 求自由能的变分导数(欧拉-拉格朗日方程, E-L方程), 向量微积分($\\nabla$与$\\nabla^2$)\nNov 05 更新: 解ODE: 有限差分法 数值方法解ODE有很多种不同的方法, 比如傅里叶谱 (Fourier Spectrum) 方法, 有限元法 (Finite Element Method, FEM), 以及这里讲到的有限差分法 (Finite Difference Method, FDM).\n有限差分法应该是最方便的一种求解方法, 其基本思想便是简单地把\u0026quot;求导\u0026quot;过程中的\u0026quot;求极限\u0026quot;的步骤省略掉, 用极小的区间上的商来替代导数. 这样一来, 复杂的求导运算即可通过简单的乘法和加法完成, 而微分方程也就可以通过上一步(临近的上一个点)的值进行迭代来获得下一个点的结果, 从而实现微分方程的求解.\n有限差分法相比与其他算法, 其优势不仅在于求解逻辑简单, 还在于该解法对于求解的区域的限制较小, 对于多种边界条件下的微分方程都可以作出求解, 因此是一种比较通用的解法.\n下面给出有限差分法的基本公式以及部分代码实现:\n对于如下的常微分方程初值问题: $$ \\dfrac{\\mathrm{d}\\,y}{\\mathrm{d}\\,x} = f(x,y);$$ $$ y(x_0) = y(a) = y_0, $$ 其中 $x \\in \\left[ a,b \\right] \\subseteq \\mathbb{R} $, $y(x) \\in \\mathbb{R} \\to \\mathbb{R}$ 由此可以选定一大整数 $ N $, 记 $h = \\dfrac{b-a}{N}$, $ x_0 = a, x_i = x_0 + ih, x_N = b, y_i = y(x_i).$ 则由有限差分, 该初值问题方程可以改写为: $$ \\dfrac{y_i - y_{i-1}}{h} = f(x_{i-1},y_{i-1}); \\tag{显式欧拉法}$$ $$ \\dfrac{y_i - y_{i-1}}{h} = f(x_{i},y_{i}). \\tag{隐式欧拉法}$$ 其中显式方法可以直接求得: $$ y_i = h f(x_{i-1},y_{i-1}) + y_{i-1}. $$这里使用 Python 实现显式欧拉法：\n1\u0026#39;\u0026#39;\u0026#39; 2Explicit Euler Method 3list x and y should have an initial value. 4\u0026#39;\u0026#39;\u0026#39; 5from typing import Callable 6def explicit_euler( 7 x:list[float],y:list[float],h:float,N:int,f:Callable[[float,float],float] 8): 9 for i in range(N): 10 x.append(x[i]+h) 11 y.append(f(x[i],y[i])*h+y[i]) 对于隐式欧拉法, 在给出$f(x,y)$的具体表达式的情况下, 可以显式给出非递归的算法, 否则由于等式右侧存在待求量, 无法显式逐步解出. 除了两种欧拉法, 还有梯形公式 (算术平均 $ f(x_i,y_i) $ 与 $f(x_{i-1},y_{i-1})$), 通过预估-校正技术实现的改进欧拉公式, 以及精度较高的 Runge-Kutta 方法. 这里给出四阶 Runge-Kutta 法的 Python 实现:\n1\u0026#34;\u0026#34;\u0026#34; 2Runge-Kutta Method 3\u0026#34;\u0026#34;\u0026#34; 4def runge_kutta( 5 x: list[float], y: list[float], h: float, N: int, f: Callable[[float, float], float] 6): 7 for i in range(N): 8 x.append(x[i] + h) 9 k_1: float = f(x[i], y[i]) 10 k_2: float = f(x[i] + h / 2, y[i] + h / 2 * k_1) 11 k_3: float = f(x[i] + h / 2, y[i] + h / 2 * k_2) 12 k_4: float = f(x[i] + h, y[i] + h * k_3) 13 y.append(y[i] + h / 6 * (k_1 + 2 * k_2 + 2 * k_3 + k_4)) Nov 06 更新: 自由能泛函与变分导数: Euler-Lagrange 方程 自由能: 引导体系演化的主趋力 先谈谈自由能. 相场中使用的自由能主要是亥姆霍兹自由能. 不过无论是亥姆霍兹自由能, 还是吉布斯自由能, 其作为自由能, 都表明了一个体系的状态, 且在自由能梯度的驱使下, 体系将朝着体系自由能最低的方向发展. 而这即为相场法背后的主要热力学依据.\n相场中所用的自由能通常具有以下的形式:\n$$ F(c, \\eta, \\nabla c, \\nabla \\eta) = \\int_{\\Omega} f(c, \\eta) + \\kappa_c (\\nabla c)^2 + \\kappa_\\eta (\\nabla \\eta)^2 + S\\; \\mathrm{d}\\omega.$$其中, $c$ 为浓度, $\\eta$ 为序参量 (标示某个相区域的变量), $f(c,\\eta)$ 部分是体系的体自由能, 可以认为是体系平衡时的自由能; 两个梯度项 $\\kappa_c (\\nabla c)^2 $, $ \\kappa_\\eta (\\nabla \\eta)^2$ 为描述并控制相界面宽度与迁移速率的项, 可以认为是界面能对总能量的贡献. 最后的 $S$ 则是其余部分对体系自由能的贡献, 如磁场, 电场, 温度场等等. 这几个部分相互作用, 共同指明了体系的演化方向, 并标示了平衡状态.\n泛函: 函数的函数 上面的自由能表达式实际上是一种泛函, 其中的浓度和序参量均为模拟域位置的函数. 除此之外, 且是一类经典泛函: $$\rJ\\left[ y \\right]=\\int_{\\Omega} L(x,y(x),y'(x)) \\,\\mathrm{d}\\omega.\r$$ 的空间形式 (即替换一般导数为梯度). 其中 $\\Omega$ 是函数 $y$ 的定义域, 函数 $y$ 在泛函中充当自变量的作用. 这类泛函通常带有物理背景, 因此得到了广泛研究, 对其极限函数的研究 (即能使 $J$ 取到极值的函数 $u$)也已经有一套成熟的方法.\nEuler-Lagrange 方程 所谓 Euler-Lagrange 方程, 是指对上述类型的泛函的方程: $$\r\\frac{\\partial L}{\\partial f}-\\frac{\\mathrm{d} }{\\mathrm{d} x}\\frac{\\partial L}{\\partial f'} = 0. \\tag{1}\r$$ 该方程的作用与一般函数 $y = \\phi(x)$的极值判断方程 $$ \\phi'(\\xi) = 0 \\tag{2}\r$$ 类似, 都是指明了极值点出现的条件: (1) 指出极限函数 $f$ 应满足 E-L 方程, 而 (2) 则指出极值点 $\\xi$ 应满足导数在该点处取值为0. 由此也不难理解泛函导数 (或者叫变分导数) 的形式应为方程(1)的左半部分: $$\r\\frac{\\delta J[y]}{\\delta y} = \\frac{\\partial L}{\\partial y}-\\frac{\\mathrm{d} }{\\mathrm{d} x}\\frac{\\partial L}{\\partial y'}.\r$$ 当然, 这里只给出了一阶导参与泛函定义的情况. 对于更一般的情况 $$\rJ\\left[ y \\right]=\\int_{\\Omega} L(x,y(x),y'(x),\\dots,y^{(n)}(x)) \\,\\mathrm{d}\\omega,\r$$ 有如下表达式: $$\r\\frac{\\delta J[y]}{\\delta y} = \\frac{\\partial L}{\\partial y}-\\frac{\\mathrm{d} }{\\mathrm{d} x}\\frac{\\partial L}{\\partial y'} + \\dots + (-1)^n \\frac{\\mathrm{d}^n }{\\mathrm{d} x^n}\\frac{\\partial L}{\\partial y^{(n)}}.\r$$向量微积分: $\\nabla$ 这里主要讨论 $\\nabla$ 算符运算法则, 以及该算符与不同函数之间的作用结果. $\\nabla$ 算符定义如下:\n设一三维线性欧式空间 $\\mathbb{R}^3$ 的三个基向量分别为 $\\mathbf{x_1}$, $\\mathbf{x_2}$, $\\mathbf{x_3}$, 则其上定义的 $\\nabla$ 算符为: $$ \\nabla = \\frac{\\partial}{\\partial x_1}\\mathbf{x_1}+ \\frac{\\partial}{\\partial x_2}\\mathbf{x_2}+\\frac{\\partial}{\\partial x_3}\\mathbf{x_3},$$ 写作向量形式则为: $$ \\nabla = \\left[ \\frac{\\partial}{\\partial x_1}, \\frac{\\partial}{\\partial x_2}, \\frac{\\partial}{\\partial x_3}\\right]^{\\mathsf{T}}.$$ 因此, $\\nabla$ 算符在直接作用于标量值函数 (如 $f: \\mathbb{R}^3 \\to \\mathbb{R}$) 时, 结果为 $\\nabla f : \\mathbb{R}^3 \\to \\mathbb{R}^3$, 得到该函数的梯度; 当其与向量值函数 (如 $\\phi:\\mathbb{R}^3 \\to \\mathbb{R}^3 $ ) 点乘时, 结果为一标量值函数 $\\nabla \\cdot \\phi :\\mathbb{R}^3 \\to \\mathbb{R} $, 得到该向量场 (即为定义域每个点赋予一个向量而非标量值) 的散度; 而当该算符与向量值函数叉乘时, 得到的结果则为一向量值函数 $\\nabla \\times \\phi : \\mathbb{R}^3 \\to \\mathbb{R}^3$, 是该向量场的旋度.\n如何考虑这样的算符运算结果呢? 注意到不论如何作用, 函数的定义域都是没有变化的, 亦即: 都是把一个向量映射到了某个值. 既然如此, 可以仅考虑其作用到的函数的定义域的影响, 即: 给每个坐标一个值, 则形成一个向量; 向量点乘给出一个标量; 向量叉乘给出一个向量. 也可以把三种运算看作三种不同的\u0026quot;函数\u0026quot;: $$\\nabla:\\mathbb{R} \\to \\mathbb{R}^3 ;$$ $$\\nabla\\cdot: \\mathbb{R}^3 \\to \\mathbb{R}; $$ $$\\nabla\\times :\\mathbb{R}^3 \\to \\mathbb{R}^3$$与原函数相复合的结果.\n下面给出三种作用方式的具体表达式: $$\\nabla f = \\mathbf{x}_1 \\frac{\\partial f}{\\partial x_1} + \\mathbf{x}_2\\frac{\\partial f}{\\partial x_2}+\\mathbf{x}_3\\frac{\\partial f}{\\partial x_3};$$ $$\\nabla \\cdot \\mathbf{f} = \\frac{\\partial f_1}{\\partial x_1} + \\frac{\\partial f_2}{\\partial x_2}+\\frac{\\partial f_3}{\\partial x_3};$$ $$\\nabla \\times \\mathbf{f} = \\begin{vmatrix}\r\\mathbf{x}_1 \u0026 \\mathbf{x}_2 \u0026 \\mathbf{x}_3 \\\\\r\\frac{\\partial }{\\partial x_1} \u0026 \\frac{\\partial }{\\partial x_2} \u0026 \\frac{\\partial }{\\partial x_3} \\\\\rf_1 \u0026 f_2 \u0026 f_3\r\\end{vmatrix},\r$$ 其中 $f_i$ 表示 $\\mathbf{f}$ 的分量函数. 下来再考察 $\\nabla$ 算符的运算性质. 设 $a,b\\in\\mathbb{R}$ 为标量, $f,g : \\mathbb{R}^3 \\to \\mathbb{R}$ 为标量函数, $\\phi,\\psi : \\mathbb{R}^3 \\to \\mathbb{R}^3$ 为向量值函数.\n直接作用 (梯度):\n线性性: $\\nabla(a f+bg) = a\\nabla{f} + b\\nabla g$ 莱布尼兹律: $\\nabla(fg) = f\\nabla{g} + g\\nabla{f}$ 点乘 (散度):\n线性性: $\\nabla\\cdot(a\\phi+b\\psi) = a\\nabla\\cdot{\\phi} + b\\nabla\\cdot{\\psi}$ 乘法律: $\\nabla\\cdot(f\\phi) = f\\nabla\\cdot{\\phi} + \\phi\\cdot\\nabla{f}$ 叉乘 (旋度):\n线性性: $\\nabla\\times(a\\phi+b\\psi) = a\\nabla\\times{\\phi} + b\\nabla\\times{\\psi} $ 乘法律: $\\nabla\\times(f\\phi) = f\\nabla\\times{\\phi} + \\phi\\times\\nabla{f}$ 其他:\n梯度无旋: $\\nabla\\times(\\nabla{f}) = 0$ 旋度无散: $\\nabla\\cdot(\\nabla\\times{f}) = 0$ 拉普拉斯算符 (先梯后散): $\\nabla\\cdot\\nabla{f} = \\nabla^2{f} = \\Delta{f}$ 以上是比较常用的 $\\nabla$ 算符性质. 实际上三种算符的组合恒等式非常多, 而实际上常用的等式则为以上所列.\n总结 相场法作为一种材料模拟方法, 其内容涉及范围广, 包括材料学(热力学, 动力学), 数值方法, 计算机编程等等相关内容. 解决上述列出的若干问题是开始相场模拟所必须的数学方法基础. 下一部分计划通过 Python 代码实现本文中的若干算法, 包括数值解ODE, 向量微积分的实现, 以及数值积分方法.\n","date":"2024-11-01T00:00:00+08:00","image":"https://a-moment096.github.io/p/phase-field-%E7%9B%B8%E5%9C%BA%E6%A8%A1%E6%8B%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-i/Skadi_hu_21f59ab02598ae65.png","permalink":"https://a-moment096.github.io/p/phase-field-%E7%9B%B8%E5%9C%BA%E6%A8%A1%E6%8B%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-i/","title":"Phase Field: 相场模拟学习笔记 I"},{"content":"这是一篇写给初学 Python 的同学的教程，帮助使用 VS Code 快速配置好 Python 的开发环境，写于今年9月14日， 先搬运至此并改为 Markdown，作为 Programming部分的第一篇博文\n简介 Python, 一门伟大的语言. 简易的, 贴合人类语言的语法, 丰富的生态, 强 大的功能让Python近几年来几乎稳坐最受欢迎编程语言的宝座. 然而, 对于 刚开始接触编程语言的初学者而言, 最麻烦的可能并非学习语法或者处理报 错, 而是搭建一个简单易用的开发环境. 本文将尽笔者所能, 介绍如何配置出 一套使用 VSCode+Python 的新手或轻度使用者适用的编程环境, 以供新手平 稳度过前期繁琐的边角料过程, 尽快开始主菜.\n然而需要提醒各位读者的是, 笔者本人并非Python主力用户, Python于笔 者而言仅为日常处理数据之用. 因此如有不正之处, 请与笔者联系修改, 如有 遗漏或不妥之处, 欢迎联系笔者. 在本文写作过程中, 笔者并没有将自己搭 建的环境删除后重新搭建以完成本文, 因此可能会有很多与实际不相符之处. 笔者的新电脑很快就到了, 届时会根据本文对照搭建对应环境以检测本文内 容是否合适, 还请读者朋友包容. 本文也假设读者您使用的是Windows10或以 上的系统. 如果您是Linux或其他系统的用户, 我相信您不需要本文也可以快 速搭建好环境.\nPython 解释器的下载 Python语言的运行依靠Python解释器对编写好的Python脚本进行逐行解 释, 也可以通过交互式的方法, 在解释器读取到输入内容后立即执行. 因 此, Python的语言解释器对学习Python是必要的. 下载Python解释器请前往 Python官网 . 初学者可以不用太过在意语言版本的问题 (语言版本过新可 能会导致某些未进行适配的库无法正常使用), 只需要保证您下载的版本 是Python3即可(版本号以3开头). Python3与Python2有着很多基础语法上的 区别, 且很多库目前不怎么支持Python2. 当然, 为了省事, 直接下载最新版也 是没有任何问题的, 在后续遇到实际需要时再进行版本修改也是没有问题的.\n在下载好Python解释器后, 便可以进行安装.请注意勾选添加到 PATH(ADD TO PATH)以避免后续复杂的手动添加环境变量的过程! 当然, 如果不幸, 您已 经在没有勾选此选项的情况下安装了Python解释器, 您可以考虑卸载后重装 或者考虑手动添加Python路径到环境变量中. 这里不再赘述.\n其余选项都可以一路默认. 有个选项会提示您是否为所有用户安装, 如 果读者您使用的计算机内仅有一个账户(或者通俗而言, 仅有您一人使用该计 算机), 那么是否选择此选项一般而言是无关紧要的. 如果您使用公共电脑或 者服务器, 请不要勾选此选项, 亦即仅为自己安装.\n最后, 请检查您是否成功安装了Python解释器. 您可以在键盘上按下 Win+R 键 打开运行对话框, 在对话框中输入 cmd 后确认, 您将会进入一个 “黑框”(命令 提示符)中. 此时在其中输入 python -V (请注意是大写的V)或者 python \u0026ndash;version , 如果成功安装了Python并添加到了环境变量中, 则界面中将会出现您所安装 的Python解释器的版本. 否则, 如果您看到类似于找不到Python定义之类的报 错, 那么有可能您的安装失败或者安装过程中没有将Python添加到环境变量 中.\n以上便是安装Python解释器的过程.\nVSCode 的安装与配置 这一步与上一步是平行的, 没有先后顺序一说, 您可以自由选择先进 行哪个部分. 但建议您先进行上一部分, 在本部分结束后您将可以直接 在VSCode中开始Python编程.\nVSCode是一个强大的文本编辑器. 其最大的特点是其优秀的插件生 态以及众多的语言支持(也是通过插件实现的). 通过VSCode与插件之间的 配合, 可以实现媲美IDE的开发环境搭建. 笔者推荐由VSCode官方出品的 在VSCode中使用Python的引导文档: Python in Visual Studio Code , 该文档详 细介绍了如何从0开始在VSCode上使用Python, 除了是英文内容外几乎没有 缺点(当然, 您可以选择网页翻译). 下面笔者将自行介绍如何安装VSCode与 相关插件.\n点击 此处 即可打开 VSCode 官网. VSCode的安装可以全部选择默认安 装, 如此便可使用VSCode的基础功能. 安装插件可以在侧边栏选择或者使用 快捷键 Ctrl+Shift+X 打开插件市场, 在页面上方框中输入相应关键词即可 检索相关插件. 如要进行Python开发, 请安装如下插件.\nChinese (Simplified)(简体中文) Language Pack for Visual Studio Code: 可 以使VSCode的语言显示变为中文显示. Python Extension Pack: VSCode上的Python插件全家桶. 安装这个比较 省事. Python 脚本试运行 在以上所述的步骤完成后, 您便可以开始编写您的第一个Python脚本以 检测您的环境是否搭建完成. 下面是一些简单的步骤:\n新建一个文件, 将之按照自己喜欢的名字命名, 并修改其后缀为 .py .\n右键该文件, 选择用VSCode打开. 打开VSCode界面后, 此时VSCode可 能会询问您是否信任该文件夹. 请选择”信任”以使您安装的插件正常 运行, 否则插件可能会被VSCode所屏蔽.\n现在您可以编辑该文件了. 输入一些Python代码, 下面是一个简单的测试代码:\n1print(\u0026#34;Hello Python!\u0026#34;) 请写好并保存该文件.\n现在请尝试运行该脚本. 如果您成功安装Python插件, 该文件界面的 右上角应该会出现一个小的向右的箭头. 点击该箭头即可开始运行. 由于您很有可能是第一次在VSCode中运行Python脚本, 因此右下角会 弹出一个通知框, 通知您还未选择Python解释器. 此时界面上方会出 现一个对话框, 让您选择您需要的Python解释器. 您可能会看到多个 解释器(如您下载了多个解释器版本)或者 创建虚拟环境(Create Virtual Environment). 您可以先暂时不考虑设置虚拟环境, 先使用已有的全局 生效的Python解释器.\n选择好后, 请再次重复上一步, 按下小箭头. 这是, VSCode界面下方会出 现一个新的窗口界面, 显示的便是您程序运行的结果. 此时您便已经成 功运行了该Python脚本, 也说明您的Python运行环境已经搭建成功了.\nPython Debug, Pip, Jupyter Notebook 本节将简要介绍有关Python与VSCode的其他方面.\n调试 (Debug) 调试是用以排查程序运行错漏的操作. 代码一次写成, 运行良好固然很 好, 但这种情况在实际开发中很难遇到. 实际开发中常会遇到各种各样的问 题阻碍开发进展. 这些程序中或逻辑或语法的错误就被称为Bug, 在程序中排 查Bug并修正以使程序得以正常运行的过程即是调试, 亦即所谓的Debug.\n最简单的调试方法即将程序在某一步的数据通过 cout(C++), printf(C) 或 print(Python) 输 出到控制台上. 但这种方法毕竟还是比较繁琐, 特别是遇到难以输出到 屏幕上的数据, 此时输出的方式便会失灵. 现代程序开发过程中, 经常使 用调试器(Debugger)来逐步运行程序, 以此尝试发现程序中隐藏的问题. 虽 然Python本身已经是解释型语言, 逐行运行已有的程序, 但是通过调试器的诸 多功能, 仍可以为寻找程序漏洞问题提供帮助.\n首先介绍断点, 程序在运行至断点后将会停在该处之前, 等待用户的下 一步命令. 断点的插入在代码编辑器中一般处于左侧的行号附近 (VSCode在 行号的左侧), 插入成功后会出现一个小红点. 当程序停在断点处时, 您可以查 看变量的值, 函数调用栈等多种信息, 随后您可以逐步向下运行程序, 中断调 试或者向步入函数内部(VSCode通过右上角小框控制).\n要进入VSCode的Debug模式, 请在运行Python脚本时, 在右上角的代表运 行的箭头旁找到一个向下的箭头, 点击展开菜单后选择 Python调试器: 调 试Python文件(Python Debugger: Debug Python File), 随后便可进入调试模式. 请注意此选项不仅会启动调试, 也会改变右上角的默认启动模式为调试. 调 试模式下, 该三角旁会出现一个小虫子, 代表此时处于调试模式.\n请善用调试模式与调试器.\nPip Pip(Package Installer for Python)是Python的包管理器. 所谓的“包”指的 是Python运行过程中需要调用的函数库, 类库等等. Python的优点很大一部分 来自于Python活跃的生态, 指的便是丰富的第三方库, 或者, 第三方包. 甚至 于有人说, Python是一门胶水语言, 其就是用来将各种库粘合在一起以发挥作 用. 无论如何, 包对于Python的意义是毋庸置疑的, 而作为Python自带的默认 包管理器, Pip的基础操作也是值得简单学习的. 下面介绍Pip的一些简单命令, 并以安装Python下著名的科学运算库Numpy为例演示Pip的使用方法. Pip的常用命令和参数有:\nhelp : 弹出帮助信息, 会提示您命令的功能. install :指示Pip进入下载模式. 在Pip后附加包名称即可下载该包. 如 果需要更新某个包, 请在包名前加上 \u0026ndash;upgrade 以提示Pip更新此包而 非安装. uninstall : 卸载某个Python包. 在该命令后附加包名即可. list : 列出所有您已安装的Python包. 接下来介绍如何安装Numpy:\n请打开命令提示符, 并输入 pip 以检查Pip是否正常可用. 如果可用则 会弹出部分帮助文本, 不会有报错信息,\n您可能会看到您的Pip有可用的更新. 若在使用 pip 命令后, Pip提示您 可以更新到最新的版本, 您可以选择根据提示输入命令进行更新.\n输入 pip install numpy 以安装Numpy. 稍等片刻您便可以安装好Numpy以 供全局使用. 注意, 您在全局环境下下载的Numpy将对全局生效.\nJupyter Notebook Python脚本经常需要写好后一次性从头执行到尾, 而使用交互模式(在 命令提示符中打开Python( python )将会进入交互模式)时Python会执行每次 用户所输入的命令. 前者不够灵活, 而后者容易丧失上下文. 是否有一种 更加具有交互性的, 但又不丧失上下文环境的Python使用方法呢? Jupyter Notebook提供了这样的方法.\nJupyter Notebook集成了Python环境和Markdown, 可以使您在代码框中 使用并运行Python脚本, 并在Markdown框中使用Markdown语法编辑文字. 两 种框的位置十分灵活, 且Notebook可以打开在浏览器中直接使用, 省去专门 的编辑器的麻烦, 也可以选择在VSCode中使用. 下面将介绍如何安装和使 用Jupyter Notebook.\n请使用Pip安装Jupyter: pip install jupyter 并等待安装完成.\n输入 jupyter notebook 并回车. 请注意不要关闭该窗口, 该窗口将作 为服务器运行, 若关闭将会导致Jupyter Notebook无法使用.\n稍等片刻, 此时您的默认浏览器将会弹出一个窗口, 左上角显示着Jupyter, 而下方主页面则是您的用户文件夹. 您可以双击已有的以 .ipynb 后 缀结尾的文件以打开一个已有的Jupyter Notebook文件, 或者请点击右 侧的新建(New)→Notebook, 便会在当前文件夹下新建一个Jupyter Note- book 并打开在您的浏览器的新页面中.\n此时新页面会请求选择一个Python内核. 采用默认设置即可, 此时您便 已经新建了一个Jupyter Notebook了. 默认的第一个框将是程序输入框, 点击页面中央的框进入输入模式, 输入Python代码后 Ctrl + Enter 以 运行代码, 结果将展现在该代码框的下方.\n您可以通过上方的工具栏新建, 插入, 删除, 运行代码框或者Markdown框. 更多功能请自行探索.\n以上, 您便成功安装并试运行了Jupyter Notebook.\n除了在浏览器中使用原生的JupyterNotebook以外, 您还可以在安装好Jupyter后 在VSCode中启动. 请安装好Jupyter的插件后, 在VSCode中使用快捷键 Ctrl + Shift + P , 或点击VSCode最上侧的搜索框后输入 \u0026gt; 以进入命令模式, 然后输入 jupyter , 此时对话框会提示您所有的可用命令, 点击创建: 新Jupyter Notebook(Create: New Jupyter Notebook)即可创建新的Jupyter Notebook. 后续操作类似于网页 端操作. 该方法不需要自行打开一个Jupyter服务器, VSCode中安装的Jupyter插 件将在VSCode的后台自行启动一个Jupyter 服务器.\n后记 笔者希望通过该文章将笔者自认为好的且简单方便的Python使用开发环 境介绍给本文的读者. 然而作为一个非Python主力的用户, 本文的内容纰漏\n在所难免, 且 $\\LaTeX$ 的插图体验并不优秀, 笔者没有向文章中插入图片而是采 用语言描述的方法, 希望读者能谅解. 感谢您能读到这里. 如果您对本文的内容有何看法或意见, 欢迎联系笔 者. 最后, 希望本文能真的实现, 并帮助您实现Python的那句名言:\n人生苦短, 我用Python. Life is short, I use Python.\n祝您生活愉快.\n","date":"2024-11-01T00:00:00+08:00","image":"https://a-moment096.github.io/p/python--vscode-%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE/%E5%A6%B9%E7%BA%A2_hu_abdd645045347242.jpeg","permalink":"https://a-moment096.github.io/p/python--vscode-%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE/","title":"Python + VSCode 快速配置"}]